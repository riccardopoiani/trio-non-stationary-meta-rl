{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from task.TaskGenerator import GaussianTaskGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task setting\n",
    "Define the task family and the possible priors on the parameters for meta-training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem param\n",
    "z_dim = 2\n",
    "n_tasks = 1000\n",
    "\n",
    "# Input space range\n",
    "x_min = -100\n",
    "x_max = 100\n",
    "\n",
    "# Training task latent space range\n",
    "min_mean = -40\n",
    "max_mean = 40\n",
    "\n",
    "min_std = 15\n",
    "max_std = 35\n",
    "\n",
    "# Prior on the offset task range\n",
    "mu_min = -10\n",
    "mu_max = 10\n",
    "\n",
    "var_min = 0.1\n",
    "var_max = 5\n",
    "\n",
    "# Task generator creation\n",
    "task_gen = GaussianTaskGenerator(x_min=x_min, x_max=x_max)\n",
    "\n",
    "# Data creation\n",
    "def sample_task(n_batches=10, test_perc=0, batch_size=128):\n",
    "    #a = (min_a - max_a) * torch.rand(1) + max_a\n",
    "    a = 1\n",
    "    m = (min_mean - max_mean) * torch.rand(1) + max_mean\n",
    "    s = (min_std - max_std) * torch.rand(1) + max_std\n",
    "    \n",
    "    data = task_gen.get_mixed_data_loader(amplitude=a, \n",
    "                                    mean=m,\n",
    "                                    std=s,\n",
    "                                    num_batches=n_batches,\n",
    "                                    test_perc=test_perc, \n",
    "                                    batch_size=batch_size)\n",
    "    return data, m, s\n",
    "\n",
    "def sample_prior_dist(dim):\n",
    "    mu_l = []\n",
    "    var_l = []\n",
    "    for i in range(dim):\n",
    "        mu = (mu_min - mu_max) * torch.rand(1) + mu_max\n",
    "        var = (var_min - var_max) * torch.rand(1) + var_max\n",
    "        \n",
    "        mu_l.append(mu)\n",
    "        var_l.append(var)\n",
    "    \n",
    "    return mu_l, var_l\n",
    "    \n",
    "# Dataset creation\n",
    "data_set = []\n",
    "a_set = []\n",
    "mean_set = []\n",
    "std_set = []\n",
    "param = []\n",
    "for _ in range(n_tasks):\n",
    "    data, mean, std = sample_task(n_batches=1, test_perc=0, batch_size=180)\n",
    "    data_set.append(data)\n",
    "    mean_set.append(mean)\n",
    "    std_set.append(std)\n",
    "    param.append((mean.item(), std.item()))\n",
    "    \n",
    "# Prior distribution on the next task\n",
    "prior_dist = []\n",
    "for _ in range(n_tasks):\n",
    "    prior_dist.append(torch.Tensor(sample_prior_dist(z_dim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.9926)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = 0\n",
    "for i in range(n_tasks):\n",
    "    t = torch.abs(prior_dist[i][0]).max()\n",
    "    if t > m:\n",
    "        m = t\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offset tensor([-10.9185,   9.5991]) || Offset - mu tensor([-7.6972, -1.5370]) || Prior tensor([4.1347, 2.8275])\n",
      "Offset tensor([1.9161, 3.9975]) || Offset - mu tensor([0.9649, 1.8080]) || Prior tensor([1.5667, 3.1941])\n",
      "Offset tensor([ 6.2699, -4.1125]) || Offset - mu tensor([-3.9101,  0.0651]) || Prior tensor([1.9943, 2.4546])\n",
      "Offset tensor([-9.4966, -9.7642]) || Offset - mu tensor([ 4.0148, -0.0294]) || Prior tensor([3.8986, 0.1956])\n",
      "Offset tensor([-8.4305, -1.0425]) || Offset - mu tensor([1.0025, 2.8100]) || Prior tensor([1.7328, 4.6978])\n",
      "Offset tensor([-7.8104,  2.6887]) || Offset - mu tensor([ 1.8622, -0.5784]) || Prior tensor([4.5679, 1.5789])\n",
      "Offset tensor([ 8.7084, -2.3953]) || Offset - mu tensor([0.3101, 0.4836]) || Prior tensor([2.2389, 1.2614])\n",
      "Offset tensor([8.9754, 1.0343]) || Offset - mu tensor([2.7203, 0.7696]) || Prior tensor([4.3161, 4.2136])\n",
      "Offset tensor([0.6334, 8.5774]) || Offset - mu tensor([-0.1942,  9.4305]) || Prior tensor([0.8271, 4.5812])\n",
      "Offset tensor([ -7.4268, -11.2863]) || Offset - mu tensor([-1.2343, -1.0143]) || Prior tensor([2.0771, 3.6415])\n"
     ]
    }
   ],
   "source": [
    "# Print some offset according to this procedure\n",
    "for _ in range(10):\n",
    "    t_idx = torch.randint(0, 1000, size=(1,))\n",
    "    mu = prior_dist[t_idx][0]\n",
    "    var = prior_dist[t_idx][1]\n",
    "    print(\"Offset {} || Offset - mu {} || Prior {}\".format(torch.normal(mu, var), \n",
    "                                               (torch.normal(mu, var)-prior_dist[t_idx][0]),\n",
    "                                                          prior_dist[t_idx][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.053610373\n",
      "0.20893787\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "t = []\n",
    "t2 = []\n",
    "for i in range(n_tasks):\n",
    "    t.append(prior_dist[i][0][0])\n",
    "    t2.append(prior_dist[i][0][1])\n",
    "print(np.mean(t))\n",
    "print(np.mean(t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network for inference on the latent space\n",
    "class InferenceNetwork(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        Previous latent space \n",
    "        sequence of data from the current task and old task at that point\n",
    "        prior over the current task (expressed as vector mu and c)\n",
    "    \n",
    "    Output:\n",
    "        - sample from the probability distribution over the latent space\n",
    "        - mu and logvar from the posterior distribution\n",
    "    \"\"\"\n",
    "    def __init__(self, n_in, z_dim):\n",
    "        super(InferenceNetwork, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.n_in = n_in\n",
    "        \n",
    "        self.enc1 = torch.nn.Linear(n_in, 32) # 3 input: x, f_t(x), f_(t-1)(x)\n",
    "        self.enc2 = torch.nn.GRU(input_size=32, hidden_size=32, num_layers=2, batch_first=True)\n",
    "        self.enc3 = torch.nn.Linear(32, 16)\n",
    "        self.enc41 = torch.nn.Linear(16, z_dim)\n",
    "        self.enc42 = torch.nn.Linear(16, z_dim)\n",
    "        \n",
    "    def encode(self, context, prev_z, prior, use_prev_state):\n",
    "        # Compute batch number and lenght of the sequence\n",
    "        n_batch = context.shape[0]\n",
    "        seq_len = context.shape[1]\n",
    "        \n",
    "        # Data preparation\n",
    "        prev_z = prev_z.reshape(n_batch, 1, 2)\n",
    "        prev_z = prev_z.repeat(1, seq_len, 1)\n",
    "        \n",
    "        prior = prior.reshape(n_batch, 1, 4)\n",
    "        prior = prior.repeat(1, seq_len, 1)\n",
    "        \n",
    "        context = torch.cat([context, prev_z, prior], dim=2) \n",
    "        \n",
    "        # Data processing\n",
    "        t = F.elu(self.enc1(context)).view(n_batch, seq_len, 32)\n",
    "        if use_prev_state:\n",
    "            t, self.h = self.enc2(t, self.h)\n",
    "        else:\n",
    "            t, self.h = self.enc2(t)\n",
    "        t = t[:, -1, :] # we are interested only in the last output of the sequence\n",
    "        t = F.elu(t)\n",
    "        t = F.elu(self.enc3(t))\n",
    "        \n",
    "        # Return encoded mu and logvar\n",
    "        return  self.enc41(t), self.enc42(t)\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        # Re-parametrization trick\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "    \n",
    "    def forward(self, context, prev_z, prior, use_prev_state=False):\n",
    "        mu, logvar = self.encode(context, prev_z, prior, use_prev_state)\n",
    "        z = self.reparameterize(mu=mu, logvar=logvar)\n",
    "        return z, mu, logvar\n",
    "\n",
    "    \n",
    "    \n",
    "# Define the network for inference on the latent space\n",
    "class InferenceNetwork2(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        Previous latent space \n",
    "        sequence of data from the current task and old task at that point\n",
    "        prior over the current task (expressed as vector mu and c)\n",
    "    \n",
    "    Output:\n",
    "        - sample from the probability distribution over the latent space\n",
    "        - mu and logvar from the posterior distribution\n",
    "    \"\"\"\n",
    "    def __init__(self, n_in, z_dim):\n",
    "        super(InferenceNetwork2, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.n_in = n_in\n",
    "        \n",
    "        self.enc1 = torch.nn.Linear(n_in, 32) # 3 input: x, f_t(x), f_(t-1)(x)\n",
    "        self.enc2 = torch.nn.GRU(input_size=32, hidden_size=32, num_layers=2, batch_first=True)\n",
    "        self.enc3 = torch.nn.Linear(32+z_dim*2+1, 16) # hidden + the prior + seq_len \n",
    "        self.enc41 = torch.nn.Linear(16, z_dim)\n",
    "        self.enc42 = torch.nn.Linear(16, z_dim)\n",
    "        \n",
    "        self.h = None\n",
    "        self.seq_len = 0\n",
    "        \n",
    "    def encode(self, context, prev_z, prior, use_prev_state):\n",
    "        # Compute batch number and lenght of the sequence\n",
    "        n_batch = context.shape[0]\n",
    "        seq_len = context.shape[1]\n",
    "        \n",
    "        # Data preparation\n",
    "        prev_z = prev_z.reshape(n_batch, 1, 2)\n",
    "        prev_z = prev_z.repeat(1, seq_len, 1)\n",
    "        \n",
    "        original_prior = prior\n",
    "        if len(original_prior.shape) == 1:\n",
    "            original_prior = original_prior.unsqueeze(0)\n",
    "        prior = prior.reshape(n_batch, 1, 4)\n",
    "        prior = prior.repeat(1, seq_len, 1)\n",
    "        \n",
    "        context = torch.cat([context, prev_z, prior], dim=2) \n",
    "        \n",
    "        # Data processing\n",
    "        t = F.elu(self.enc1(context)).view(n_batch, seq_len, 32)\n",
    "        if use_prev_state and self.h is not None:\n",
    "            t, self.h = self.enc2(t, self.h)\n",
    "        else:\n",
    "            t, self.h = self.enc2(t)\n",
    "        t = t[:, -1, :] # we are interested only in the last output of the sequence\n",
    "        t = F.elu(t)\n",
    "\n",
    "        self.seq_len += seq_len \n",
    "        trust = torch.tensor([self.seq_len], dtype=t.dtype).repeat(n_batch, 1)\n",
    "        t = torch.cat([t, original_prior, trust], 1)\n",
    "        t = F.elu(self.enc3(t))\n",
    "        \n",
    "        \n",
    "        # Return encoded mu and logvar\n",
    "        return  self.enc41(t), self.enc42(t)\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        # Re-parametrization trick\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "    \n",
    "    def forward(self, context, prev_z, prior, use_prev_state=False):\n",
    "        if not use_prev_state:\n",
    "            self.h = None\n",
    "            self.seq_len = 0\n",
    "        \n",
    "        mu, logvar = self.encode(context, prev_z, prior, use_prev_state)\n",
    "        z = self.reparameterize(mu=mu, logvar=logvar)\n",
    "        return z, mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function \n",
    "kld_list = []\n",
    "mse_list = []\n",
    "\n",
    "def loss_inference_closed_form(z, mu_hat, logvar_hat, mu_prior, logvar_prior, epoch):\n",
    "    MSE = torch.mean(torch.sum(logvar_hat.exp(), 1)) + F.mse_loss(mu_hat, z)\n",
    "    \n",
    "    KLD_1 = (torch.log(torch.prod(logvar_prior.exp(), 1) / torch.prod(logvar_hat.exp(), 1)))\n",
    "    KLD_2 = (torch.sum(-1+(mu_hat - mu_prior).pow(2) * (1/logvar_prior.exp()) + (logvar_hat.exp()*(1/logvar_prior.exp())), 1))\n",
    "    \n",
    "    KLD = (1/2) * torch.mean(KLD_1 + KLD_2)\n",
    "    \n",
    "    kld_list.append(KLD.item())\n",
    "    mse_list.append(MSE.item())\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"MSE {}\".format(MSE.item()))\n",
    "        print(\"KLD {}\".format(KLD.item()))\n",
    "    \n",
    "    return MSE + KLD\n",
    "    \n",
    "def loss_inference_sampling(z_hat, z, mu_hat, logvar_hat, mu_prior, logvar_prior, epoch):\n",
    "    # KLD derived from two multivariate gaussian exploiting diagonal properties\n",
    "    MSE = F.mse_loss(z_hat, z)\n",
    "    \n",
    "    KLD_1 = (torch.log(torch.prod(logvar_prior.exp(), 1) / torch.prod(logvar_hat.exp(), 1)))\n",
    "    KLD_2 = (torch.sum(-1+(mu_hat - mu_prior).pow(2) * (1/logvar_prior.exp()) + (logvar_hat.exp()*(1/logvar_prior.exp())), 1))\n",
    "    \n",
    "    KLD = (1/2) * torch.mean(KLD_1 + KLD_2)\n",
    "    \n",
    "    kld_list.append(KLD.item())\n",
    "    mse_list.append(MSE.item())\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"MSE {}\".format(MSE.item()))\n",
    "        print(\"KLD {}\".format(KLD.item()))\n",
    "    \n",
    "    return MSE + KLD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training procedure\n",
    "min_seq_len = 1\n",
    "max_seq_len = 150\n",
    "\n",
    "def train_inference_network(epoch, batch_per_task=1, n_batch=32):\n",
    "    train_loss = 0\n",
    "    \n",
    "    # Choose pair of init task and distribution for the next task\n",
    "    task_idx = torch.randint(low=0, high=n_tasks, size=(n_batch,))\n",
    "    task_loader = [data_set[i] for i in task_idx]\n",
    "    target = torch.tensor([param[i] for i in task_idx])\n",
    "    \n",
    "    prev_task_param = torch.randint(low=0, high=n_tasks, size=(n_batch,))\n",
    "    \n",
    "    prior = torch.empty(n_batch, 4)\n",
    "    mu_prior = torch.empty(n_batch, 2)\n",
    "    logvar_prior = torch.empty(n_batch, 2)\n",
    "    for t_idx in range(n_batch):\n",
    "        prior[t_idx] = prior_dist[prev_task_param[t_idx]].reshape(1, 4).squeeze(0).clone().detach()\n",
    "        mu_prior[t_idx] = prior_dist[prev_task_param[t_idx]][0].clone().detach()\n",
    "        logvar_prior[t_idx] = prior_dist[prev_task_param[t_idx]][1].clone().detach().log()\n",
    "    \n",
    "    for k in range(batch_per_task):\n",
    "        num_data_context = torch.randint(low=min_seq_len, high=max_seq_len, size=(1,)).item()\n",
    "        idx = torch.randperm(max_seq_len)\n",
    "        ctx_idx = idx[0:num_data_context]\n",
    "        \n",
    "        context = torch.empty(n_batch, num_data_context, 2)\n",
    "        prev_task = torch.empty(n_batch, 2)\n",
    "\n",
    "        # Retrieving data to be fed to the network \n",
    "        i = 0\n",
    "        for t_idx, task in enumerate(task_loader):\n",
    "            # Creating new task\n",
    "            mu = prior_dist[prev_task_param[t_idx]][0].clone().detach()\n",
    "            var = prior_dist[prev_task_param[t_idx]][1].clone().detach()\n",
    "            \n",
    "            offset_param = torch.normal(mu, var)\n",
    "            prev_task[i] = target[i] - offset_param \n",
    "            prior[i][0:2] = prev_task[i] + prior[i][0:2].clone().detach()\n",
    "            mu_prior[i] = prev_task[i] + mu_prior[i].clone().detach()\n",
    "            \n",
    "            # Creating context to be fed to the network \n",
    "            batch = task[k]['train']\n",
    "            batch = torch.cat([batch[0], batch[1]], dim=1)\n",
    "            batch[ctx_idx]\n",
    "            context[i] = batch[ctx_idx]\n",
    "            i+=1\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        z_hat, mu_hat, logvar_hat = inference_net(context, prev_task, prior)\n",
    "\n",
    "        # Compute reconstruction\n",
    "        loss = loss_inference_closed_form(target, mu_hat, logvar_hat, mu_prior, logvar_prior, epoch)\n",
    "        loss.backward()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return train_loss / (batch_per_task)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_net = InferenceNetwork2(n_in=8,z_dim=2)\n",
    "optimizer = torch.optim.Adam(inference_net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4811,  1.2372],\n",
      "        [-0.0064,  1.5069],\n",
      "        [-0.9446, -0.4740],\n",
      "        [ 1.3835,  0.2613],\n",
      "        [ 1.3520,  0.2849],\n",
      "        [ 0.6717, -1.6588],\n",
      "        [ 0.2607,  0.9075],\n",
      "        [ 0.8153,  1.5107],\n",
      "        [ 1.2165, -1.0403],\n",
      "        [ 0.5820, -0.0695],\n",
      "        [-1.2962,  1.4516],\n",
      "        [ 1.3493,  1.2623],\n",
      "        [ 0.4963,  0.9370],\n",
      "        [ 0.8002,  1.5454],\n",
      "        [ 1.5916,  0.4590],\n",
      "        [ 1.0075,  1.3770],\n",
      "        [ 0.7750,  1.2710],\n",
      "        [ 0.7446, -0.8435],\n",
      "        [ 0.7494,  1.5665],\n",
      "        [ 1.1520,  0.6196],\n",
      "        [ 0.1663,  1.3797],\n",
      "        [ 0.8722, -0.4882],\n",
      "        [ 0.1720,  1.1032],\n",
      "        [ 1.2540,  1.1848],\n",
      "        [ 1.2065,  0.0027],\n",
      "        [ 0.1065,  1.2421],\n",
      "        [-0.0436,  0.8036],\n",
      "        [ 1.4619,  1.2089],\n",
      "        [ 0.7750,  1.2710],\n",
      "        [ 0.9234,  1.2109],\n",
      "        [ 0.8265,  0.3820],\n",
      "        [ 0.8722, -0.4882]])\n",
      "MSE 762.54052734375\n",
      "KLD 548.392578125\n",
      "====> Epoch: 0 Average loss: 1310.9331\n",
      "tensor([[ 1.3552e+00,  7.4370e-01],\n",
      "        [-1.6064e+00,  6.4176e-01],\n",
      "        [ 1.5257e+00,  6.1946e-01],\n",
      "        [ 1.3731e+00, -4.7104e-01],\n",
      "        [-1.1537e+00,  4.3543e-01],\n",
      "        [ 1.5042e+00,  5.6315e-01],\n",
      "        [ 9.1374e-01,  8.9058e-01],\n",
      "        [-7.0375e-02,  1.5540e+00],\n",
      "        [ 1.5674e+00,  3.7481e-01],\n",
      "        [-5.1438e-02,  1.3805e+00],\n",
      "        [-4.5243e-01, -9.5093e-01],\n",
      "        [ 3.6306e-01,  7.0471e-01],\n",
      "        [ 1.5903e+00,  1.4878e+00],\n",
      "        [ 1.1603e+00,  4.1007e-01],\n",
      "        [ 1.3382e+00,  1.0506e+00],\n",
      "        [ 1.1573e+00, -7.6635e-02],\n",
      "        [ 9.7149e-01,  6.2154e-01],\n",
      "        [ 9.9920e-01,  1.4945e+00],\n",
      "        [ 1.6630e-01,  1.3797e+00],\n",
      "        [ 8.8820e-01,  9.0226e-01],\n",
      "        [ 3.5669e-01,  1.1477e+00],\n",
      "        [ 1.4894e+00,  1.4183e+00],\n",
      "        [ 1.5075e+00,  9.6808e-01],\n",
      "        [-2.2450e+00,  1.2686e+00],\n",
      "        [ 9.1796e-01,  1.0517e+00],\n",
      "        [ 4.7111e-01,  1.5848e+00],\n",
      "        [-6.6971e-01,  6.7034e-01],\n",
      "        [ 4.6662e-01,  9.3242e-01],\n",
      "        [ 9.3050e-01, -1.6780e-01],\n",
      "        [ 1.2567e+00, -2.4220e-01],\n",
      "        [ 1.9319e-01,  5.4037e-01],\n",
      "        [ 7.3644e-04,  1.4011e+00]])\n",
      "tensor([[ 1.2396,  0.4670],\n",
      "        [-1.0705, -1.5542],\n",
      "        [ 1.3319,  0.9607],\n",
      "        [-0.6362,  1.5806],\n",
      "        [ 1.3878,  1.4815],\n",
      "        [ 1.0825, -2.1115],\n",
      "        [ 0.3505,  0.6842],\n",
      "        [ 0.2191,  1.4165],\n",
      "        [ 1.4697, -1.2891],\n",
      "        [ 0.3023,  1.0311],\n",
      "        [ 1.3184,  1.1016],\n",
      "        [ 0.3740, -1.9097],\n",
      "        [ 1.1279,  1.5276],\n",
      "        [ 1.4337, -1.4531],\n",
      "        [ 1.0002,  1.4509],\n",
      "        [ 1.2993,  1.1671],\n",
      "        [ 1.5635,  1.2438],\n",
      "        [ 0.9660,  0.2827],\n",
      "        [ 1.5824,  1.3840],\n",
      "        [ 0.8725,  1.0480],\n",
      "        [ 0.6877,  1.5223],\n",
      "        [-0.4671,  0.7215],\n",
      "        [ 0.5371,  1.4648],\n",
      "        [ 1.0564,  1.1107],\n",
      "        [-1.3484,  0.3414],\n",
      "        [ 0.5754, -0.0127],\n",
      "        [ 0.9137,  0.8906],\n",
      "        [ 0.8533,  1.5265],\n",
      "        [ 0.4089, -0.2256],\n",
      "        [ 1.2579, -0.4962],\n",
      "        [ 1.4499,  1.2437],\n",
      "        [-0.2387,  0.9178]])\n",
      "tensor([[ 0.5298, -0.9998],\n",
      "        [ 0.5091,  0.0739],\n",
      "        [ 1.0526,  0.9096],\n",
      "        [-1.5670,  1.4388],\n",
      "        [ 1.1879,  0.3676],\n",
      "        [ 1.0861,  1.4534],\n",
      "        [ 1.3264,  1.4487],\n",
      "        [ 0.5490,  1.1980],\n",
      "        [ 1.3825,  0.5325],\n",
      "        [ 0.9711,  1.1689],\n",
      "        [ 1.3070,  0.7360],\n",
      "        [-0.4168,  0.1474],\n",
      "        [ 1.5576,  0.6399],\n",
      "        [-0.7492,  1.2464],\n",
      "        [ 0.5457,  1.3773],\n",
      "        [ 1.5126,  0.9224],\n",
      "        [ 0.4720,  1.3237],\n",
      "        [ 1.1260,  0.5859],\n",
      "        [ 1.5970,  1.1400],\n",
      "        [ 1.2761, -0.2461],\n",
      "        [ 0.7484, -1.9077],\n",
      "        [ 0.9715,  0.6215],\n",
      "        [ 0.2154,  0.0685],\n",
      "        [ 0.3567,  1.1477],\n",
      "        [-0.6711,  1.3921],\n",
      "        [ 1.2781,  1.2867],\n",
      "        [-1.2067,  0.4735],\n",
      "        [ 0.1569,  1.3591],\n",
      "        [ 0.0549, -0.8884],\n",
      "        [ 1.1852,  0.2901],\n",
      "        [ 1.4238,  0.8042],\n",
      "        [ 1.5535,  1.5326]])\n",
      "tensor([[ 1.2830,  0.7341],\n",
      "        [ 0.9165,  0.6497],\n",
      "        [ 1.1526,  1.5518],\n",
      "        [-0.7074,  1.5705],\n",
      "        [ 0.5616, -0.3838],\n",
      "        [ 1.2185,  1.0271],\n",
      "        [ 1.5900,  1.5072],\n",
      "        [-0.0076,  1.0688],\n",
      "        [ 0.4711,  1.3709],\n",
      "        [ 0.9126,  1.1492],\n",
      "        [ 1.3379, -2.0231],\n",
      "        [-1.1742,  0.9831],\n",
      "        [ 0.9137,  0.8906],\n",
      "        [ 0.6210, -0.4434],\n",
      "        [ 1.5900,  1.5072],\n",
      "        [ 1.0596,  1.5906],\n",
      "        [ 1.5662,  0.7902],\n",
      "        [ 0.9394, -1.5469],\n",
      "        [-1.1742,  0.9831],\n",
      "        [ 1.4857, -0.7896],\n",
      "        [ 0.6094,  0.3444],\n",
      "        [ 0.5628,  1.3690],\n",
      "        [ 1.0886,  0.5933],\n",
      "        [ 1.0558,  1.4565],\n",
      "        [ 0.9742,  0.8824],\n",
      "        [ 1.1530,  1.5157],\n",
      "        [ 1.5149,  0.8012],\n",
      "        [ 1.2781,  1.2867],\n",
      "        [ 0.8665,  1.5805],\n",
      "        [ 0.7974, -0.5354],\n",
      "        [ 1.3599,  1.5039],\n",
      "        [ 0.0821,  0.7108]])\n",
      "tensor([[ 1.5375,  0.7006],\n",
      "        [ 1.0260, -1.2875],\n",
      "        [ 0.9219,  1.3694],\n",
      "        [-0.6697,  0.6703],\n",
      "        [ 1.1304,  0.7884],\n",
      "        [ 1.3511,  0.9086],\n",
      "        [ 1.5393,  1.4387],\n",
      "        [ 1.0976, -1.4356],\n",
      "        [ 1.0342,  1.3918],\n",
      "        [-1.5286, -0.4794],\n",
      "        [ 1.2185,  1.0271],\n",
      "        [ 0.3970,  1.2531],\n",
      "        [ 1.2177,  0.0213],\n",
      "        [ 0.9394, -1.5469],\n",
      "        [ 1.5042,  0.5631],\n",
      "        [-0.5630, -0.8932],\n",
      "        [ 0.4149, -0.4413],\n",
      "        [ 1.5920,  1.0765],\n",
      "        [ 0.7942,  1.2549],\n",
      "        [ 0.7357,  1.1364],\n",
      "        [ 0.5628,  1.3690],\n",
      "        [ 0.9114,  0.5026],\n",
      "        [ 0.3874,  0.6382],\n",
      "        [ 1.5303, -0.1221],\n",
      "        [ 0.7304, -0.3402],\n",
      "        [ 1.4011,  1.2062],\n",
      "        [ 1.3669,  1.3960],\n",
      "        [-0.6163,  1.4351],\n",
      "        [ 1.4912,  1.5109],\n",
      "        [ 0.1932,  0.5404],\n",
      "        [ 0.9332, -0.3791],\n",
      "        [ 0.8475,  1.4868]])\n",
      "tensor([[ 1.3649e+00, -2.4927e-01],\n",
      "        [ 5.3473e-01, -1.0375e+00],\n",
      "        [ 1.5257e+00,  6.1946e-01],\n",
      "        [ 1.0787e+00, -6.5985e-02],\n",
      "        [ 9.7763e-02,  1.2413e+00],\n",
      "        [ 8.8746e-01,  1.1233e+00],\n",
      "        [ 1.3315e+00,  1.4808e+00],\n",
      "        [ 6.9982e-01,  1.5765e+00],\n",
      "        [ 1.3953e+00,  1.3418e+00],\n",
      "        [ 1.2499e+00,  1.4042e+00],\n",
      "        [ 5.6574e-01,  1.4052e+00],\n",
      "        [ 1.5392e+00,  8.6965e-01],\n",
      "        [ 1.5981e+00, -6.2132e-01],\n",
      "        [ 9.3952e-01,  1.1747e+00],\n",
      "        [ 1.4965e+00, -5.9760e-01],\n",
      "        [ 6.3839e-01,  3.9524e-01],\n",
      "        [ 9.9307e-01,  1.5145e-01],\n",
      "        [ 7.4766e-01,  1.1021e+00],\n",
      "        [ 7.3644e-04,  1.4011e+00],\n",
      "        [ 1.4238e+00,  8.0418e-01],\n",
      "        [-3.9051e-01,  1.2071e+00],\n",
      "        [ 9.1374e-01,  8.9058e-01],\n",
      "        [ 4.7111e-01,  1.5848e+00],\n",
      "        [ 1.5590e+00,  1.4760e+00],\n",
      "        [-1.9174e-02,  1.4775e+00],\n",
      "        [ 1.5412e+00,  1.5623e+00],\n",
      "        [ 9.8631e-01,  1.4072e+00],\n",
      "        [ 4.4108e-01, -1.4156e-01],\n",
      "        [-8.1116e-01,  1.0864e+00],\n",
      "        [ 1.2528e+00,  1.5972e+00],\n",
      "        [ 1.0354e+00,  1.4201e+00],\n",
      "        [ 5.2981e-01, -9.9975e-01]])\n",
      "tensor([[ 1.4965e+00, -5.9760e-01],\n",
      "        [ 1.4016e+00,  1.4997e+00],\n",
      "        [ 8.3664e-02,  8.8617e-01],\n",
      "        [ 5.7369e-01,  1.0805e+00],\n",
      "        [ 5.8198e-01, -6.9517e-02],\n",
      "        [ 1.0342e+00,  1.3918e+00],\n",
      "        [ 3.7044e-01,  9.5444e-01],\n",
      "        [ 1.5393e+00,  1.4387e+00],\n",
      "        [ 8.0353e-02,  1.2665e+00],\n",
      "        [ 1.3229e+00,  1.3135e+00],\n",
      "        [-1.4758e+00,  1.5529e+00],\n",
      "        [-1.5762e-02,  4.8428e-01],\n",
      "        [ 1.6781e-01,  1.5155e+00],\n",
      "        [ 3.7396e-01, -1.9097e+00],\n",
      "        [ 3.7396e-01, -1.9097e+00],\n",
      "        [-5.0097e-02,  1.6063e+00],\n",
      "        [ 1.5903e+00,  1.4878e+00],\n",
      "        [ 7.6881e-01,  1.0324e+00],\n",
      "        [ 1.1587e+00, -5.6798e-02],\n",
      "        [ 1.5273e+00, -1.5455e+00],\n",
      "        [ 5.4572e-01,  1.3773e+00],\n",
      "        [-1.0418e+00,  1.5961e+00],\n",
      "        [ 2.9344e-01,  1.0729e+00],\n",
      "        [ 5.6922e-01,  6.8732e-01],\n",
      "        [ 9.8309e-01,  1.0962e+00],\n",
      "        [ 9.7115e-01,  1.1689e+00],\n",
      "        [ 1.4341e+00,  1.4528e+00],\n",
      "        [ 1.4611e+00,  9.1653e-01],\n",
      "        [ 1.0021e+00,  1.0172e+00],\n",
      "        [ 1.6036e+00,  1.1341e-02],\n",
      "        [ 4.0907e-01,  3.4479e-01],\n",
      "        [ 1.2242e+00, -1.2267e-03]])\n",
      "tensor([[-1.0329e+00, -9.0234e-02],\n",
      "        [ 7.3517e-01,  7.6672e-01],\n",
      "        [ 1.0659e+00,  9.5176e-01],\n",
      "        [ 2.6074e-01,  9.0751e-01],\n",
      "        [ 1.3819e+00, -1.2127e+00],\n",
      "        [ 2.9344e-01,  1.0729e+00],\n",
      "        [ 1.2642e+00,  1.1690e+00],\n",
      "        [ 7.3644e-04,  1.4011e+00],\n",
      "        [ 1.5635e+00,  1.2438e+00],\n",
      "        [ 1.3774e+00,  1.5344e+00],\n",
      "        [ 8.7253e-01,  1.0480e+00],\n",
      "        [ 1.4779e+00,  1.5087e+00],\n",
      "        [ 1.2859e+00,  9.8883e-01],\n",
      "        [ 8.1537e-01,  8.0612e-01],\n",
      "        [ 1.2025e+00,  1.5731e+00],\n",
      "        [ 1.0861e+00,  1.4534e+00],\n",
      "        [ 1.4725e+00,  1.4408e+00],\n",
      "        [ 1.4814e+00,  7.7550e-01],\n",
      "        [ 9.8570e-01,  1.5676e+00],\n",
      "        [ 8.7768e-01, -1.1358e+00],\n",
      "        [ 4.1493e-01, -4.4129e-01],\n",
      "        [ 5.2312e-01, -1.3790e+00],\n",
      "        [ 1.1279e+00,  1.5276e+00],\n",
      "        [-1.0387e+00,  1.4713e+00],\n",
      "        [ 8.4266e-02,  4.8775e-01],\n",
      "        [ 1.0979e+00, -6.5645e-01],\n",
      "        [ 1.5781e+00,  1.3166e+00],\n",
      "        [ 1.2520e+00, -8.6961e-02],\n",
      "        [ 1.9253e-01,  9.8158e-01],\n",
      "        [ 6.7175e-01, -1.6588e+00],\n",
      "        [ 1.4054e+00,  1.1754e+00],\n",
      "        [-6.6971e-01,  6.7034e-01]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0535,  0.3598],\n",
      "        [ 0.2861, -2.1470],\n",
      "        [ 0.6621,  1.5113],\n",
      "        [ 0.8158,  0.3396],\n",
      "        [ 0.7974, -0.5354],\n",
      "        [ 1.1768, -0.2274],\n",
      "        [ 0.8855,  1.0964],\n",
      "        [ 0.9137,  0.8906],\n",
      "        [-0.2696,  1.2181],\n",
      "        [ 1.0487,  0.9466],\n",
      "        [ 1.0260, -1.2875],\n",
      "        [ 0.5737,  1.0805],\n",
      "        [ 0.9612, -0.2088],\n",
      "        [ 1.0342,  1.3918],\n",
      "        [ 1.1530,  1.5157],\n",
      "        [ 1.5419,  1.5316],\n",
      "        [ 0.9286,  0.2146],\n",
      "        [ 1.5829,  0.8980],\n",
      "        [ 0.9647,  0.6328],\n",
      "        [ 1.4768, -0.1290],\n",
      "        [ 0.9677,  1.1054],\n",
      "        [ 1.4929,  1.5802],\n",
      "        [ 1.5182,  1.4680],\n",
      "        [ 1.4505,  1.3753],\n",
      "        [-1.5180,  1.1165],\n",
      "        [ 0.4036,  0.7956],\n",
      "        [-1.5286, -0.4794],\n",
      "        [-0.1924, -0.0630],\n",
      "        [ 1.3263,  0.4206],\n",
      "        [-1.1573, -0.2944],\n",
      "        [ 0.6066, -0.2189],\n",
      "        [ 1.2813,  1.4224]])\n",
      "tensor([[ 4.1561e-01,  1.4704e-03],\n",
      "        [-3.6497e-03,  1.1956e+00],\n",
      "        [ 9.8858e-01,  1.2120e+00],\n",
      "        [ 3.1444e-01,  1.1053e+00],\n",
      "        [ 9.7763e-02,  1.2413e+00],\n",
      "        [ 7.9979e-01,  7.4125e-01],\n",
      "        [ 1.1052e+00,  5.1769e-01],\n",
      "        [ 1.2103e+00,  6.5924e-01],\n",
      "        [ 5.3528e-02,  1.0433e+00],\n",
      "        [ 1.4999e+00, -1.2714e+00],\n",
      "        [-1.2641e-01,  1.3513e+00],\n",
      "        [-3.2341e-01,  1.4996e+00],\n",
      "        [-1.2906e+00, -1.2755e+00],\n",
      "        [-1.2962e+00,  1.4516e+00],\n",
      "        [ 7.9424e-01,  1.2549e+00],\n",
      "        [-6.4092e-03,  1.5069e+00],\n",
      "        [-1.7775e-01,  6.3932e-01],\n",
      "        [ 1.3284e+00,  1.5744e+00],\n",
      "        [ 9.7654e-01,  1.2214e+00],\n",
      "        [ 1.0558e+00,  1.4565e+00],\n",
      "        [ 1.5000e+00,  1.5767e+00],\n",
      "        [ 1.1526e+00,  1.5518e+00],\n",
      "        [ 1.6036e+00,  1.1341e-02],\n",
      "        [-1.2050e+00, -5.8217e-01],\n",
      "        [-1.8300e+00,  1.2896e+00],\n",
      "        [ 5.0909e-01,  7.3855e-02],\n",
      "        [ 1.2947e+00, -5.5700e-01],\n",
      "        [-1.2641e-01,  1.3513e+00],\n",
      "        [ 1.4214e+00,  1.2209e+00],\n",
      "        [ 1.4697e+00, -1.2891e+00],\n",
      "        [-1.3044e+00,  3.4853e-01],\n",
      "        [ 2.4003e-01,  7.4002e-01]])\n",
      "tensor([[-1.0705, -1.5542],\n",
      "        [-0.0814,  0.1444],\n",
      "        [ 1.4337, -1.4531],\n",
      "        [ 1.3012,  1.5735],\n",
      "        [ 0.4516,  1.1963],\n",
      "        [ 1.4696,  0.9725],\n",
      "        [ 0.8158,  0.3396],\n",
      "        [ 0.2388,  1.1381],\n",
      "        [-0.7074,  1.5705],\n",
      "        [-0.1712,  1.2990],\n",
      "        [ 1.4396, -0.0577],\n",
      "        [-0.1178,  0.1651],\n",
      "        [ 1.2185,  1.0271],\n",
      "        [-0.6518,  1.2415],\n",
      "        [ 1.4027,  1.1118],\n",
      "        [ 1.5257,  0.6195],\n",
      "        [-0.0436,  0.8036],\n",
      "        [ 0.9911,  1.4681],\n",
      "        [ 0.5653, -1.3044],\n",
      "        [ 0.9880,  0.5161],\n",
      "        [ 1.2861,  0.7252],\n",
      "        [ 0.6909,  1.3078],\n",
      "        [ 0.3181,  1.0343],\n",
      "        [ 1.1170,  1.4657],\n",
      "        [ 0.9086, -1.7454],\n",
      "        [ 0.3240,  0.6617],\n",
      "        [ 0.3240,  0.6617],\n",
      "        [ 0.6717, -1.6588],\n",
      "        [-0.6697,  0.6703],\n",
      "        [-0.0514,  1.3805],\n",
      "        [-0.5943,  1.1587],\n",
      "        [ 1.2593,  0.4926]])\n",
      "tensor([[ 0.8153,  1.5107],\n",
      "        [ 1.4811,  1.2372],\n",
      "        [ 0.6784,  1.3124],\n",
      "        [-1.9328,  1.3253],\n",
      "        [ 1.0861,  1.4534],\n",
      "        [-2.2450,  1.2686],\n",
      "        [ 1.1911,  0.6767],\n",
      "        [ 1.3264,  1.4487],\n",
      "        [-0.0192,  1.4775],\n",
      "        [ 1.5149,  0.8012],\n",
      "        [ 0.9277,  1.0563],\n",
      "        [ 1.2396,  0.4670],\n",
      "        [ 1.0281,  1.4165],\n",
      "        [ 1.4111,  0.1364],\n",
      "        [-0.1777,  0.6393],\n",
      "        [ 0.9180,  1.0517],\n",
      "        [ 1.3243, -2.1136],\n",
      "        [ 1.5824,  1.3840],\n",
      "        [ 0.5181,  1.2967],\n",
      "        [-1.0404,  1.3015],\n",
      "        [ 1.1965, -0.7438],\n",
      "        [ 0.8387,  0.8303],\n",
      "        [ 1.0861,  1.4534],\n",
      "        [ 1.4499,  1.2437],\n",
      "        [ 1.4811,  1.2372],\n",
      "        [ 1.5042,  0.5631],\n",
      "        [ 1.3148,  1.3440],\n",
      "        [ 1.4114, -1.3538],\n",
      "        [ 1.3828,  0.7233],\n",
      "        [ 1.4814,  0.7755],\n",
      "        [ 1.0137,  1.5335],\n",
      "        [ 0.0256,  1.2209]])\n",
      "tensor([[ 1.5678,  0.3205],\n",
      "        [ 0.7307,  0.3600],\n",
      "        [ 1.1072,  1.2289],\n",
      "        [ 0.5181,  1.2967],\n",
      "        [-1.6779,  1.1351],\n",
      "        [-0.3152, -1.0940],\n",
      "        [ 1.2993,  1.1671],\n",
      "        [ 0.1004,  0.8575],\n",
      "        [-0.8884,  1.3275],\n",
      "        [ 0.9660,  0.2827],\n",
      "        [ 0.4681,  1.2710],\n",
      "        [ 1.5166, -1.8125],\n",
      "        [ 1.0987,  1.4249],\n",
      "        [ 0.8260,  0.4543],\n",
      "        [ 1.3554,  0.8106],\n",
      "        [ 0.9137,  0.8906],\n",
      "        [ 0.4543,  1.1008],\n",
      "        [ 1.4965, -0.5976],\n",
      "        [ 1.0326,  0.0118],\n",
      "        [ 0.7777,  1.6001],\n",
      "        [ 0.1932,  0.5404],\n",
      "        [ 1.1562,  1.4317],\n",
      "        [ 1.1247,  1.2532],\n",
      "        [-0.6711,  1.3921],\n",
      "        [ 0.6195, -1.4112],\n",
      "        [ 1.3554,  0.8106],\n",
      "        [ 0.6191,  0.6974],\n",
      "        [-0.0799,  1.4686],\n",
      "        [ 0.5371,  1.4648],\n",
      "        [-1.9967,  1.0665],\n",
      "        [ 1.4810,  0.3242],\n",
      "        [ 1.2800, -1.0043]])\n",
      "tensor([[ 1.3835,  0.2613],\n",
      "        [ 1.5674,  0.3748],\n",
      "        [ 0.4521,  0.4769],\n",
      "        [ 0.8163,  1.0305],\n",
      "        [-1.3555,  0.3848],\n",
      "        [ 1.3435,  0.9089],\n",
      "        [-0.6468,  1.4146],\n",
      "        [ 0.0535,  1.0433],\n",
      "        [ 0.3874,  0.6382],\n",
      "        [ 0.6129,  0.8569],\n",
      "        [ 1.1530,  1.5157],\n",
      "        [ 1.0558,  1.4565],\n",
      "        [-1.4951,  0.6789],\n",
      "        [ 1.4929,  1.5802],\n",
      "        [-0.6801,  1.1522],\n",
      "        [ 0.9934, -0.6507],\n",
      "        [ 0.7859,  0.0891],\n",
      "        [ 1.4965, -0.5976],\n",
      "        [ 0.1097,  0.2982],\n",
      "        [-0.0037,  0.0369],\n",
      "        [ 0.8153,  1.5107],\n",
      "        [ 0.0894,  1.5788],\n",
      "        [ 1.2882,  1.4415],\n",
      "        [ 0.3613,  0.9683],\n",
      "        [ 1.2103,  0.6592],\n",
      "        [ 1.0096,  1.5168],\n",
      "        [-0.3832,  0.0699],\n",
      "        [ 1.1852,  0.2901],\n",
      "        [ 1.0895,  1.3531],\n",
      "        [ 0.3392,  0.9152],\n",
      "        [ 1.4245,  1.4439],\n",
      "        [-0.4168,  0.1474]])\n",
      "tensor([[-0.5883,  1.1682],\n",
      "        [ 0.4266,  0.7615],\n",
      "        [ 1.3828,  1.3726],\n",
      "        [ 1.1587, -0.0568],\n",
      "        [ 0.8492,  1.5582],\n",
      "        [ 0.8123, -0.4216],\n",
      "        [ 1.5042,  0.5631],\n",
      "        [ 1.4438,  1.5189],\n",
      "        [ 0.2454,  1.0679],\n",
      "        [ 1.2982,  1.1072],\n",
      "        [ 1.4857,  0.9867],\n",
      "        [ 0.2835,  0.8537],\n",
      "        [ 0.3121,  0.6587],\n",
      "        [ 1.5149,  0.8012],\n",
      "        [ 1.0858,  1.1390],\n",
      "        [-1.8189,  1.4170],\n",
      "        [ 0.9286,  0.2146],\n",
      "        [ 1.6043,  1.4477],\n",
      "        [ 1.3731, -0.4710],\n",
      "        [ 0.5820, -0.0695],\n",
      "        [ 1.5523,  1.1804],\n",
      "        [ 1.2224, -0.0793],\n",
      "        [ 1.1471,  0.2704],\n",
      "        [ 0.3173,  0.7638],\n",
      "        [ 0.2861, -2.1470],\n",
      "        [ 1.0659,  0.9518],\n",
      "        [-1.2962,  1.4516],\n",
      "        [ 0.7898,  1.3905],\n",
      "        [ 1.4730,  0.8355],\n",
      "        [ 1.0564,  1.1733],\n",
      "        [ 1.4717,  0.1171],\n",
      "        [ 1.1915,  0.4304]])\n",
      "tensor([[ 1.3511e+00,  9.0860e-01],\n",
      "        [-4.2107e-01,  3.9204e-01],\n",
      "        [ 1.5433e+00,  1.5769e+00],\n",
      "        [ 8.2648e-01,  3.8201e-01],\n",
      "        [ 2.8962e-01, -1.0522e+00],\n",
      "        [ 1.5289e+00,  1.5079e+00],\n",
      "        [-2.2450e+00,  1.2686e+00],\n",
      "        [-1.5590e+00, -1.1826e+00],\n",
      "        [-4.6711e-01,  7.2151e-01],\n",
      "        [ 6.0234e-01,  3.9297e-01],\n",
      "        [ 4.0282e-01,  6.3487e-01],\n",
      "        [-1.9933e+00,  4.2426e-01],\n",
      "        [ 6.7843e-01,  1.3124e+00],\n",
      "        [ 1.0837e+00,  1.3025e+00],\n",
      "        [ 1.5624e+00,  1.3255e+00],\n",
      "        [ 1.2167e+00,  1.5568e+00],\n",
      "        [-1.1949e-01,  3.1482e-01],\n",
      "        [ 1.5438e+00, -1.4783e-04],\n",
      "        [ 1.1879e+00,  3.6759e-01],\n",
      "        [ 8.4257e-01,  2.1292e-01],\n",
      "        [ 4.4255e-01,  1.4631e+00],\n",
      "        [ 3.0099e-01, -1.2005e+00],\n",
      "        [ 6.7843e-01,  1.3124e+00],\n",
      "        [ 1.2637e+00,  5.6393e-01],\n",
      "        [ 1.0496e+00,  1.6067e+00],\n",
      "        [ 8.6331e-02,  3.6481e-01],\n",
      "        [ 1.1965e+00, -5.9098e-01],\n",
      "        [ 1.3369e+00, -6.8982e-01],\n",
      "        [-7.9917e-02,  1.4686e+00],\n",
      "        [ 8.4257e-01,  2.1292e-01],\n",
      "        [ 9.7267e-01,  1.4612e+00],\n",
      "        [ 1.0987e+00,  1.4249e+00]])\n",
      "tensor([[-1.8189e+00,  1.4170e+00],\n",
      "        [ 1.2933e-01,  9.5777e-01],\n",
      "        [ 1.2389e+00,  1.0890e+00],\n",
      "        [ 1.1906e+00,  1.3809e+00],\n",
      "        [ 1.2074e+00, -7.4785e-02],\n",
      "        [ 1.5239e+00,  1.0163e+00],\n",
      "        [ 4.7854e-01,  1.1866e+00],\n",
      "        [ 1.0194e+00,  1.5678e+00],\n",
      "        [ 1.5282e+00,  1.2354e+00],\n",
      "        [-1.9328e+00,  1.3253e+00],\n",
      "        [ 8.4350e-01,  1.4848e+00],\n",
      "        [ 9.4119e-01,  5.4555e-01],\n",
      "        [ 8.7907e-01, -6.1331e-01],\n",
      "        [ 1.0496e+00,  1.6067e+00],\n",
      "        [ 1.2042e+00,  1.4407e+00],\n",
      "        [ 1.1474e+00,  1.0788e+00],\n",
      "        [ 1.1965e+00, -7.4381e-01],\n",
      "        [-1.3484e+00,  3.4140e-01],\n",
      "        [ 1.3901e+00, -1.1926e+00],\n",
      "        [ 1.0223e+00,  1.5205e+00],\n",
      "        [ 1.1879e+00,  3.6759e-01],\n",
      "        [-4.0834e-01,  1.5617e+00],\n",
      "        [ 7.9743e-01, -5.3542e-01],\n",
      "        [ 5.3707e-01,  1.4648e+00],\n",
      "        [ 1.4181e+00, -1.5310e-01],\n",
      "        [ 1.0204e+00,  9.7921e-01],\n",
      "        [ 1.5320e+00, -2.9451e-01],\n",
      "        [ 1.2242e+00, -1.2267e-03],\n",
      "        [-4.6413e-01,  1.1458e+00],\n",
      "        [ 6.1293e-01,  8.5689e-01],\n",
      "        [ 1.5981e+00, -6.2132e-01],\n",
      "        [ 1.4459e+00,  7.6685e-01]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3184,  1.1016],\n",
      "        [ 1.5643,  1.1404],\n",
      "        [ 0.7304, -0.3402],\n",
      "        [ 1.3835,  0.2613],\n",
      "        [-1.9967,  1.0665],\n",
      "        [ 0.1004,  0.8575],\n",
      "        [ 1.1052,  0.5177],\n",
      "        [ 0.9857,  1.5676],\n",
      "        [ 1.4829,  1.5842],\n",
      "        [ 0.6132,  1.2209],\n",
      "        [ 1.2904,  1.2284],\n",
      "        [ 1.0081,  1.5577],\n",
      "        [-0.0064,  1.5069],\n",
      "        [ 0.5298, -0.9998],\n",
      "        [ 1.5541, -0.0216],\n",
      "        [-1.1434, -0.6706],\n",
      "        [ 0.8898,  1.6085],\n",
      "        [ 0.8791, -0.6133],\n",
      "        [ 0.1097,  0.2982],\n",
      "        [ 0.7304, -0.3402],\n",
      "        [ 1.2776,  1.1742],\n",
      "        [-0.8112,  1.0864],\n",
      "        [ 1.5846,  1.4890],\n",
      "        [ 1.2593,  0.4926],\n",
      "        [ 0.9346,  0.9819],\n",
      "        [-0.0421,  0.1352],\n",
      "        [ 1.4195,  0.8918],\n",
      "        [-0.2690,  1.4455],\n",
      "        [ 1.5781,  1.3166],\n",
      "        [ 1.4756,  0.4316],\n",
      "        [ 0.5742,  1.5061],\n",
      "        [ 1.2882,  1.4415]])\n",
      "tensor([[ 1.0002,  1.4509],\n",
      "        [-0.0814,  0.1444],\n",
      "        [ 0.4711,  1.3709],\n",
      "        [ 1.0137,  1.5335],\n",
      "        [ 1.2065,  0.0027],\n",
      "        [ 1.3559, -1.2347],\n",
      "        [-0.5630, -0.8932],\n",
      "        [ 0.7617,  1.4483],\n",
      "        [ 0.8882,  0.9023],\n",
      "        [ 1.3732,  0.9313],\n",
      "        [ 0.1663,  1.3797],\n",
      "        [ 0.2454,  1.0679],\n",
      "        [ 0.8742,  1.0692],\n",
      "        [ 0.4582, -1.3660],\n",
      "        [-0.0514,  1.3805],\n",
      "        [ 0.6195, -1.4112],\n",
      "        [-1.8300,  1.2896],\n",
      "        [-1.6779,  1.1351],\n",
      "        [ 1.5957,  1.3181],\n",
      "        [ 1.3070,  0.7360],\n",
      "        [ 0.1953, -0.5296],\n",
      "        [-0.4263,  0.6370],\n",
      "        [ 0.7649,  0.6875],\n",
      "        [ 0.9175,  0.5308],\n",
      "        [ 1.2884,  0.9109],\n",
      "        [ 0.8742,  1.0692],\n",
      "        [-0.0129,  0.8467],\n",
      "        [ 1.5184,  0.5012],\n",
      "        [ 0.9332, -0.3791],\n",
      "        [ 1.1052,  0.5177],\n",
      "        [ 0.3970,  1.2531],\n",
      "        [ 0.9647,  0.6328]])\n",
      "tensor([[ 0.4426,  1.4631],\n",
      "        [ 1.2931, -0.9273],\n",
      "        [ 1.4990,  1.5847],\n",
      "        [ 1.4214,  1.2209],\n",
      "        [ 1.2528,  1.5972],\n",
      "        [ 0.5777, -0.5021],\n",
      "        [ 0.8492,  1.5582],\n",
      "        [ 0.8780,  1.0088],\n",
      "        [ 1.5535,  1.5326],\n",
      "        [ 1.4832,  0.9720],\n",
      "        [ 0.1529, -1.5680],\n",
      "        [ 0.9175,  0.5308],\n",
      "        [ 0.7974, -0.1288],\n",
      "        [-0.5495,  1.2518],\n",
      "        [-0.1712,  1.2990],\n",
      "        [ 1.5422,  0.4651],\n",
      "        [ 1.1389,  1.3739],\n",
      "        [ 1.1526,  1.5518],\n",
      "        [ 1.4160, -0.7153],\n",
      "        [ 1.5422,  0.4651],\n",
      "        [ 0.5657,  1.4052],\n",
      "        [ 0.6210, -0.4434],\n",
      "        [-2.1427,  0.8990],\n",
      "        [ 0.6132,  1.2209],\n",
      "        [ 1.5982, -0.7212],\n",
      "        [-0.4168,  0.1474],\n",
      "        [ 0.5766,  1.0372],\n",
      "        [-1.0705, -1.5542],\n",
      "        [ 1.2869,  1.3897],\n",
      "        [-0.9446, -0.4740],\n",
      "        [ 1.4717,  0.1171],\n",
      "        [ 1.1168,  1.5291]])\n",
      "tensor([[ 7.7155e-01,  1.5404e+00],\n",
      "        [ 4.7201e-01,  1.3237e+00],\n",
      "        [ 5.2981e-01, -9.9975e-01],\n",
      "        [-1.2067e+00,  4.7353e-01],\n",
      "        [ 1.3243e+00, -2.1136e+00],\n",
      "        [ 7.4462e-01, -8.4354e-01],\n",
      "        [-4.3377e-01,  8.0542e-02],\n",
      "        [ 6.2301e-01,  2.4133e-01],\n",
      "        [ 4.4156e-01,  5.8389e-01],\n",
      "        [ 4.6231e-01,  1.2064e+00],\n",
      "        [ 1.3729e+00,  1.6057e+00],\n",
      "        [ 1.0326e+00,  1.1831e-02],\n",
      "        [ 8.9678e-01,  1.4215e+00],\n",
      "        [ 3.7044e-01,  9.5444e-01],\n",
      "        [-3.3642e-01,  8.6840e-01],\n",
      "        [ 1.1735e+00,  1.2721e+00],\n",
      "        [ 4.1561e-01,  1.4704e-03],\n",
      "        [ 1.4236e+00,  4.9744e-01],\n",
      "        [ 8.7802e-01,  1.0088e+00],\n",
      "        [ 1.5303e+00, -1.2215e-01],\n",
      "        [ 9.7086e-01, -1.5003e-02],\n",
      "        [ 1.1534e+00,  9.0863e-01],\n",
      "        [ 8.0353e-02,  1.2665e+00],\n",
      "        [ 5.0385e-01,  1.5259e+00],\n",
      "        [ 7.7767e-01,  1.6001e+00],\n",
      "        [ 1.0659e+00,  9.5176e-01],\n",
      "        [-1.9174e-02,  1.4775e+00],\n",
      "        [ 1.2593e+00,  4.9259e-01],\n",
      "        [ 9.2856e-01,  2.1460e-01],\n",
      "        [ 1.2595e+00,  6.6112e-01],\n",
      "        [ 1.3413e+00, -2.5426e-02],\n",
      "        [ 5.4895e-01,  1.1980e+00]])\n",
      "tensor([[ 0.3181,  1.0343],\n",
      "        [ 0.7431,  0.7010],\n",
      "        [ 0.1132,  1.1168],\n",
      "        [ 1.1895, -0.2431],\n",
      "        [ 1.3826,  0.5137],\n",
      "        [ 0.2861, -2.1470],\n",
      "        [ 0.9114,  0.5026],\n",
      "        [ 1.2567, -0.2422],\n",
      "        [ 1.4180,  1.4416],\n",
      "        [ 1.1968,  1.4525],\n",
      "        [ 0.9863,  1.4072],\n",
      "        [ 0.1932,  0.5404],\n",
      "        [ 0.7942,  1.2549],\n",
      "        [ 1.1329,  1.3260],\n",
      "        [ 1.1852,  0.2901],\n",
      "        [ 0.6384,  0.3952],\n",
      "        [ 1.3344,  1.2030],\n",
      "        [ 0.0814,  1.3335],\n",
      "        [ 0.3567,  1.1477],\n",
      "        [-0.5223, -0.3551],\n",
      "        [ 0.7522, -1.5367],\n",
      "        [ 0.6649,  1.5619],\n",
      "        [ 1.4696,  0.9725],\n",
      "        [-0.6468,  1.4146],\n",
      "        [ 1.3785,  1.2512],\n",
      "        [ 1.4010,  1.0577],\n",
      "        [ 0.5371,  1.4648],\n",
      "        [ 1.3785,  1.2512],\n",
      "        [ 1.0320,  0.5885],\n",
      "        [ 1.5523,  1.1804],\n",
      "        [ 1.1780,  1.5780],\n",
      "        [ 1.4829,  1.5842]])\n",
      "tensor([[ 1.2147, -0.8520],\n",
      "        [ 0.9015,  1.3456],\n",
      "        [ 0.2861, -2.1470],\n",
      "        [ 0.3567,  1.1477],\n",
      "        [ 0.9965,  1.4442],\n",
      "        [ 0.4028,  0.6349],\n",
      "        [-1.2067,  0.4735],\n",
      "        [-0.2334,  1.4874],\n",
      "        [ 1.3387,  0.2658],\n",
      "        [-0.6163,  1.4351],\n",
      "        [ 0.5742,  1.5061],\n",
      "        [ 0.8450,  1.1781],\n",
      "        [ 0.5742,  1.5061],\n",
      "        [ 1.0886,  0.5933],\n",
      "        [ 1.5438,  1.4986],\n",
      "        [-0.5943,  1.1587],\n",
      "        [ 1.2436,  1.2586],\n",
      "        [ 0.7902, -0.8012],\n",
      "        [-1.7273,  1.3724],\n",
      "        [ 0.3357,  1.1828],\n",
      "        [ 0.1720,  1.1032],\n",
      "        [ 1.4843,  1.0352],\n",
      "        [ 1.2567, -0.2422],\n",
      "        [ 1.0487,  0.9466],\n",
      "        [-0.1712,  1.2990],\n",
      "        [-1.1742,  0.9831],\n",
      "        [ 1.3737,  1.1799],\n",
      "        [ 0.9014, -0.1929],\n",
      "        [-0.6195,  1.2133],\n",
      "        [ 0.9157,  1.4597],\n",
      "        [ 1.3493,  1.2623],\n",
      "        [ 1.3209,  0.9072]])\n",
      "tensor([[ 0.8856, -1.6127],\n",
      "        [ 1.3229,  1.3135],\n",
      "        [ 1.5590,  0.3255],\n",
      "        [-2.2450,  1.2686],\n",
      "        [-0.2387,  0.9178],\n",
      "        [ 0.5357,  1.5875],\n",
      "        [ 0.9863,  1.4072],\n",
      "        [ 1.4607,  0.7322],\n",
      "        [-2.0454,  1.0281],\n",
      "        [ 1.3148,  1.3440],\n",
      "        [ 1.1768, -0.2274],\n",
      "        [ 1.4708,  1.5819],\n",
      "        [ 0.5657,  1.4052],\n",
      "        [ 1.3387,  0.2658],\n",
      "        [-0.8112,  1.0864],\n",
      "        [-1.7273,  1.3724],\n",
      "        [ 0.3505,  0.6842],\n",
      "        [-0.0403,  1.4553],\n",
      "        [ 1.2675, -0.1330],\n",
      "        [ 1.2149, -0.0330],\n",
      "        [ 0.3023,  1.0311],\n",
      "        [ 0.0555,  1.5645],\n",
      "        [ 1.5303, -0.1221],\n",
      "        [ 1.4733,  1.5125],\n",
      "        [ 0.8898,  1.6085],\n",
      "        [ 1.5414, -1.8302],\n",
      "        [ 0.8665,  1.5805],\n",
      "        [ 1.2065,  0.0027],\n",
      "        [ 1.5393,  1.4387],\n",
      "        [ 0.3490, -1.1872],\n",
      "        [ 0.4622,  0.4871],\n",
      "        [ 1.5968,  1.3816]])\n",
      "tensor([[-0.0152,  1.5360],\n",
      "        [ 0.9464,  1.4687],\n",
      "        [ 0.5989,  1.5335],\n",
      "        [ 1.5016,  1.1596],\n",
      "        [ 1.1530,  1.5157],\n",
      "        [ 0.8780,  1.0088],\n",
      "        [ 0.8426,  0.2129],\n",
      "        [ 1.1978,  1.4760],\n",
      "        [ 0.8063,  0.2631],\n",
      "        [ 1.5627,  0.1326],\n",
      "        [ 1.1113,  0.7663],\n",
      "        [ 1.3827,  1.4714],\n",
      "        [ 1.2257,  1.3866],\n",
      "        [ 1.2964, -0.8225],\n",
      "        [ 1.4675,  1.4290],\n",
      "        [ 1.3520,  0.2849],\n",
      "        [ 1.5375,  0.7006],\n",
      "        [ 1.1965, -0.5910],\n",
      "        [ 1.2430,  1.2163],\n",
      "        [ 1.3953,  1.3418],\n",
      "        [ 1.0244,  0.0916],\n",
      "        [ 1.5438,  1.4986],\n",
      "        [ 1.5744,  0.8225],\n",
      "        [ 1.5282,  1.2354],\n",
      "        [ 1.0701,  1.0744],\n",
      "        [ 0.2631,  0.2077],\n",
      "        [ 0.9709, -0.0150],\n",
      "        [ 1.4894,  1.4183],\n",
      "        [ 1.3600,  0.8417],\n",
      "        [ 0.8780,  1.0088],\n",
      "        [ 1.2993,  1.1671],\n",
      "        [ 0.0978,  1.2413]])\n",
      "tensor([[ 1.1852,  0.2901],\n",
      "        [ 0.7998,  0.7412],\n",
      "        [ 1.2896,  1.1830],\n",
      "        [ 0.7230, -1.0826],\n",
      "        [-0.1777,  0.6393],\n",
      "        [ 0.9992,  1.4945],\n",
      "        [ 1.2177,  0.0213],\n",
      "        [ 1.3236,  1.2957],\n",
      "        [ 1.2436,  1.2586],\n",
      "        [ 1.4810,  0.3242],\n",
      "        [ 1.4306,  1.5024],\n",
      "        [ 1.2147, -0.8520],\n",
      "        [ 0.7691, -1.1269],\n",
      "        [ 0.0978,  1.2413],\n",
      "        [ 0.0874,  1.3646],\n",
      "        [ 1.4859,  0.3220],\n",
      "        [ 0.2454,  1.0679],\n",
      "        [ 1.0409, -0.0659],\n",
      "        [-0.3731,  0.3127],\n",
      "        [ 1.2567, -0.2422],\n",
      "        [ 1.4950,  1.4266],\n",
      "        [ 1.3243, -2.1136],\n",
      "        [ 1.4011,  1.2062],\n",
      "        [ 0.5196,  1.5803],\n",
      "        [ 1.1471,  0.2704],\n",
      "        [ 0.6094,  0.3444],\n",
      "        [ 1.1527,  0.9927],\n",
      "        [ 1.0846, -1.0266],\n",
      "        [ 1.4245,  1.4439],\n",
      "        [ 1.4623,  0.4965],\n",
      "        [ 1.2130,  1.4384],\n",
      "        [-0.1906,  1.2519]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4666,  0.9324],\n",
      "        [ 0.6849,  1.5222],\n",
      "        [ 1.1085,  1.4093],\n",
      "        [ 1.5236,  1.1808],\n",
      "        [-1.4179,  1.0577],\n",
      "        [-1.7273,  1.3724],\n",
      "        [ 0.4089, -0.2256],\n",
      "        [ 1.4913,  0.2225],\n",
      "        [ 1.1534,  0.9086],\n",
      "        [ 0.6732,  1.1375],\n",
      "        [ 1.3148,  1.3440],\n",
      "        [ 0.9165,  0.6497],\n",
      "        [-0.1064,  1.5406],\n",
      "        [ 0.7688,  1.0324],\n",
      "        [ 0.8846,  1.2746],\n",
      "        [ 1.1052,  0.5177],\n",
      "        [ 1.3520,  0.2849],\n",
      "        [ 1.4160, -0.7153],\n",
      "        [ 1.4195,  0.8918],\n",
      "        [-1.1434, -0.6706],\n",
      "        [ 1.5825, -0.1278],\n",
      "        [-0.5630, -0.8932],\n",
      "        [-0.0799,  1.4686],\n",
      "        [ 0.6195, -1.4112],\n",
      "        [ 0.3740, -1.9097],\n",
      "        [ 0.0814,  1.3335],\n",
      "        [ 0.4785,  1.1866],\n",
      "        [ 1.3600,  0.8417],\n",
      "        [ 1.0236,  1.0576],\n",
      "        [-0.9675,  1.6092],\n",
      "        [ 1.5082,  1.2116],\n",
      "        [ 0.2687,  1.5418]])\n",
      "tensor([[-0.4632,  0.8927],\n",
      "        [ 1.2776,  1.1742],\n",
      "        [ 0.2782,  1.3346],\n",
      "        [ 1.4733,  1.5125],\n",
      "        [ 0.8875,  1.1233],\n",
      "        [ 1.5137,  1.5340],\n",
      "        [ 1.0701,  1.0744],\n",
      "        [ 0.9630,  1.3831],\n",
      "        [-0.5554, -1.4605],\n",
      "        [ 0.6191,  0.6974],\n",
      "        [ 0.5754, -0.0127],\n",
      "        [ 0.6248,  0.6197],\n",
      "        [ 1.3554,  0.8106],\n",
      "        [ 1.3511,  0.9086],\n",
      "        [-0.0192,  1.4775],\n",
      "        [-0.8884,  1.3275],\n",
      "        [ 1.4043,  0.9680],\n",
      "        [ 1.2710,  1.4310],\n",
      "        [ 1.4392,  1.2035],\n",
      "        [ 1.0354,  1.4201],\n",
      "        [ 1.4697, -1.2891],\n",
      "        [ 1.5957,  1.3181],\n",
      "        [ 1.4571,  0.3741],\n",
      "        [-0.3364,  0.8684],\n",
      "        [ 1.0846, -1.0266],\n",
      "        [ 1.4167,  0.6707],\n",
      "        [ 1.5419,  1.5316],\n",
      "        [ 0.5754, -0.0127],\n",
      "        [ 1.1534,  0.9086],\n",
      "        [-1.2050, -0.5822],\n",
      "        [ 1.5576,  0.6399],\n",
      "        [ 1.0229,  0.6049]])\n",
      "tensor([[ 0.9647,  0.6328],\n",
      "        [ 0.5754, -0.0127],\n",
      "        [ 1.5184,  0.5012],\n",
      "        [ 0.5199,  0.7917],\n",
      "        [ 0.8533,  1.5265],\n",
      "        [ 1.2436,  1.2586],\n",
      "        [ 1.5744,  0.8225],\n",
      "        [-0.4571, -0.0205],\n",
      "        [-0.2690,  1.4455],\n",
      "        [ 1.4195,  0.8918],\n",
      "        [ 1.0787, -0.0660],\n",
      "        [ 1.4244,  1.2654],\n",
      "        [ 0.8035,  1.0922],\n",
      "        [ 1.5674,  0.3748],\n",
      "        [ 1.3387,  0.2658],\n",
      "        [ 1.1603,  0.4101],\n",
      "        [ 0.3137,  1.5483],\n",
      "        [ 0.6894,  1.5603],\n",
      "        [ 1.1531, -0.5827],\n",
      "        [ 1.1530,  1.5157],\n",
      "        [ 0.9886,  1.2120],\n",
      "        [ 0.3392,  0.9152],\n",
      "        [ 0.6124,  0.6547],\n",
      "        [ 0.3181,  1.0343],\n",
      "        [ 0.7323,  1.1284],\n",
      "        [-1.2906, -1.2755],\n",
      "        [-1.0535,  0.3598],\n",
      "        [ 1.0326,  0.0118],\n",
      "        [ 1.2904,  1.2284],\n",
      "        [ 0.5777, -0.5021],\n",
      "        [ 1.2103,  0.6592],\n",
      "        [ 0.8158,  0.3396]])\n",
      "tensor([[ 0.6671,  1.6001],\n",
      "        [ 1.2138,  0.8934],\n",
      "        [ 1.1196,  0.8969],\n",
      "        [ 1.2908,  1.4982],\n",
      "        [-1.1742,  0.9831],\n",
      "        [ 1.4756,  0.4316],\n",
      "        [ 1.2993,  1.1671],\n",
      "        [ 1.4337, -1.4531],\n",
      "        [ 1.3930,  1.1589],\n",
      "        [ 1.4016,  1.4997],\n",
      "        [ 1.2784,  0.2784],\n",
      "        [ 0.9911,  1.4681],\n",
      "        [ 1.4237,  1.4177],\n",
      "        [ 0.4411, -0.1416],\n",
      "        [ 1.5825, -0.1278],\n",
      "        [-0.0441,  1.4681],\n",
      "        [ 1.3878,  1.4815],\n",
      "        [-0.8540,  1.2441],\n",
      "        [ 0.2131,  1.0568],\n",
      "        [ 0.2896, -1.0522],\n",
      "        [ 1.4784,  1.2177],\n",
      "        [ 0.9277,  1.0563],\n",
      "        [ 1.0813, -0.5248],\n",
      "        [ 0.0843,  0.4877],\n",
      "        [ 0.8898,  1.6085],\n",
      "        [-1.2962,  1.4516],\n",
      "        [ 0.3069, -1.3531],\n",
      "        [ 0.5820, -0.0695],\n",
      "        [ 0.6877,  1.5223],\n",
      "        [ 1.2593,  0.4926],\n",
      "        [ 1.2540,  1.1848],\n",
      "        [-1.0404,  1.0885]])\n",
      "tensor([[ 1.3209e+00,  9.0723e-01],\n",
      "        [-5.9427e-01,  1.1587e+00],\n",
      "        [ 1.0236e+00,  1.0576e+00],\n",
      "        [ 1.4990e+00,  1.5847e+00],\n",
      "        [ 5.3575e-01,  1.5875e+00],\n",
      "        [-4.0892e-02, -3.6817e-01],\n",
      "        [ 3.3600e-01,  1.1792e+00],\n",
      "        [-1.0404e+00,  1.3015e+00],\n",
      "        [ 1.6781e-01,  1.5155e+00],\n",
      "        [ 1.3148e+00,  1.3440e+00],\n",
      "        [-1.5180e+00,  1.1165e+00],\n",
      "        [-8.2332e-01,  9.0472e-01],\n",
      "        [ 1.3787e+00, -8.3144e-01],\n",
      "        [ 3.3572e-01,  1.1828e+00],\n",
      "        [ 1.3034e+00,  1.4562e+00],\n",
      "        [ 1.0924e+00, -9.3979e-01],\n",
      "        [ 6.2859e-01, -1.4511e-01],\n",
      "        [ 9.8802e-01,  5.1609e-01],\n",
      "        [ 7.3644e-04,  1.4011e+00],\n",
      "        [ 1.1520e+00,  6.1959e-01],\n",
      "        [ 2.4541e-01,  1.0679e+00],\n",
      "        [ 7.5218e-01, -1.5367e+00],\n",
      "        [ 1.2861e+00,  7.2517e-01],\n",
      "        [-5.6302e-01, -8.9323e-01],\n",
      "        [ 3.2768e-01, -4.0064e-01],\n",
      "        [ 1.5982e+00, -7.2117e-01],\n",
      "        [ 7.9235e-01,  1.5881e+00],\n",
      "        [ 6.8910e-01,  9.4170e-01],\n",
      "        [ 5.1813e-01,  1.2967e+00],\n",
      "        [ 4.0887e-01, -2.2562e-01],\n",
      "        [ 8.7395e-02,  1.3646e+00],\n",
      "        [-1.0404e+00,  1.0885e+00]])\n",
      "tensor([[ 1.5273, -1.5455],\n",
      "        [ 1.5467,  1.5829],\n",
      "        [ 1.5903,  1.4878],\n",
      "        [ 0.9727,  1.4612],\n",
      "        [ 0.6262, -1.7281],\n",
      "        [ 0.8846,  1.2746],\n",
      "        [ 1.5825, -0.1278],\n",
      "        [ 0.1932,  0.5404],\n",
      "        [ 1.1260,  0.5859],\n",
      "        [ 1.4692,  1.3999],\n",
      "        [ 1.0526,  0.9096],\n",
      "        [ 0.3461,  1.4630],\n",
      "        [ 1.0550,  1.4094],\n",
      "        [-0.1499,  1.1483],\n",
      "        [ 0.3740, -1.9097],\n",
      "        [ 1.2830,  0.7341],\n",
      "        [ 1.3379, -2.0231],\n",
      "        [ 0.3277, -0.4006],\n",
      "        [ 1.4214,  1.2209],\n",
      "        [-0.1064,  1.5406],\n",
      "        [ 0.8260,  0.4543],\n",
      "        [ 1.1914,  0.4305],\n",
      "        [ 0.0837,  0.8862],\n",
      "        [ 1.1557,  1.4288],\n",
      "        [ 1.1732, -0.1812],\n",
      "        [ 1.2743, -0.9936],\n",
      "        [-0.4083,  1.5617],\n",
      "        [ 0.8806,  1.5774],\n",
      "        [ 1.2743, -0.9936],\n",
      "        [ 1.0659,  0.9518],\n",
      "        [-1.1835,  1.5787],\n",
      "        [ 0.6683,  0.7112]])\n",
      "tensor([[ 1.5041,  1.4809],\n",
      "        [-0.1621,  1.5464],\n",
      "        [ 1.1610, -1.1960],\n",
      "        [ 1.3552,  0.7437],\n",
      "        [-2.1155, -0.4073],\n",
      "        [-0.5616,  1.1246],\n",
      "        [ 1.5172,  1.3145],\n",
      "        [ 0.6838,  1.3820],\n",
      "        [ 1.4743,  0.6416],\n",
      "        [ 0.0555,  1.5645],\n",
      "        [-0.3524,  0.9085],\n",
      "        [ 0.6195, -1.4112],\n",
      "        [-1.8300,  1.2896],\n",
      "        [ 1.1520,  0.6196],\n",
      "        [ 1.4555,  1.5014],\n",
      "        [ 0.1199,  1.1664],\n",
      "        [-0.8233,  0.9047],\n",
      "        [ 0.5091,  0.0739],\n",
      "        [ 0.1529, -1.5680],\n",
      "        [ 0.7932, -0.7354],\n",
      "        [ 1.0701,  1.0744],\n",
      "        [ 1.0021,  1.0172],\n",
      "        [ 0.9395,  1.1747],\n",
      "        [ 1.5794,  0.3987],\n",
      "        [-0.7587,  0.8943],\n",
      "        [ 0.1529, -1.5680],\n",
      "        [-0.5616,  1.1246],\n",
      "        [ 1.5900,  1.5072],\n",
      "        [ 1.5581,  1.0514],\n",
      "        [-1.0535,  0.3598],\n",
      "        [ 1.2674,  1.4192],\n",
      "        [ 0.3392,  0.9152]])\n",
      "tensor([[ 1.4829,  1.5842],\n",
      "        [ 1.4260,  0.3860],\n",
      "        [ 0.2934,  1.0729],\n",
      "        [ 0.7357,  1.1364],\n",
      "        [ 0.5357,  1.5875],\n",
      "        [ 1.3729,  1.6057],\n",
      "        [ 1.4396, -0.0577],\n",
      "        [ 1.4160, -0.7153],\n",
      "        [-0.6468,  1.4146],\n",
      "        [ 0.3490, -1.1872],\n",
      "        [-0.7492,  1.2464],\n",
      "        [ 1.3012,  1.5735],\n",
      "        [ 0.5766,  1.0372],\n",
      "        [ 0.5644,  0.7974],\n",
      "        [ 1.3809,  1.3171],\n",
      "        [ 1.3738,  1.5858],\n",
      "        [-0.7170,  1.3608],\n",
      "        [ 0.5196,  1.5803],\n",
      "        [ 0.8875,  1.1233],\n",
      "        [ 0.2175,  1.5666],\n",
      "        [ 0.9219,  1.3694],\n",
      "        [ 0.7815,  1.4670],\n",
      "        [ 0.4411, -0.1416],\n",
      "        [ 0.8163,  1.0305],\n",
      "        [ 0.1132,  1.1168],\n",
      "        [ 1.3599,  1.5039],\n",
      "        [ 1.0837,  1.3025],\n",
      "        [ 1.4675,  1.4290],\n",
      "        [ 1.0021,  1.0172],\n",
      "        [-0.5752,  1.0264],\n",
      "        [ 1.1911,  1.0276],\n",
      "        [ 1.4089,  1.3356]])\n",
      "tensor([[ 1.2861,  0.7252],\n",
      "        [ 1.1527,  0.9927],\n",
      "        [ 1.4675,  1.4290],\n",
      "        [ 0.9180,  1.0517],\n",
      "        [ 1.3559, -1.2347],\n",
      "        [ 1.4836,  1.4990],\n",
      "        [ 1.5433,  1.5769],\n",
      "        [ 1.2396,  0.4670],\n",
      "        [ 0.9346,  0.9819],\n",
      "        [ 1.0229,  0.6049],\n",
      "        [ 1.5946, -0.3394],\n",
      "        [ 1.1527,  0.9927],\n",
      "        [ 0.8665,  1.5805],\n",
      "        [ 1.2904,  1.2284],\n",
      "        [ 0.9934, -0.6507],\n",
      "        [ 1.4306,  1.5024],\n",
      "        [ 0.3121,  0.6587],\n",
      "        [-1.1835,  1.5787],\n",
      "        [ 1.0648,  0.7846],\n",
      "        [-1.5670,  1.4388],\n",
      "        [ 1.5541, -0.0216],\n",
      "        [ 0.7649,  0.6875],\n",
      "        [ 1.0813, -0.5248],\n",
      "        [ 0.7716,  1.5404],\n",
      "        [ 1.5781,  1.3166],\n",
      "        [ 0.2154,  0.0685],\n",
      "        [ 1.5781,  1.3166],\n",
      "        [ 1.5414, -1.8302],\n",
      "        [ 1.1279,  1.5276],\n",
      "        [ 1.4836,  1.4990],\n",
      "        [ 1.2129, -0.5588],\n",
      "        [ 0.8682,  1.0676]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9574, -1.4086],\n",
      "        [ 0.9394, -1.5469],\n",
      "        [ 0.8002,  1.5454],\n",
      "        [-1.0329, -0.0902],\n",
      "        [ 0.8715,  1.0650],\n",
      "        [-1.4179,  1.0577],\n",
      "        [ 1.2025,  1.5731],\n",
      "        [ 1.2816,  1.5973],\n",
      "        [-0.2690,  1.4455],\n",
      "        [ 1.3835,  0.2613],\n",
      "        [ 1.5153,  0.2697],\n",
      "        [ 1.1085,  1.4093],\n",
      "        [ 1.4181, -0.1531],\n",
      "        [ 1.5236,  1.1808],\n",
      "        [ 0.6248,  0.6197],\n",
      "        [ 1.4832,  0.9720],\n",
      "        [-0.4641,  1.1458],\n",
      "        [ 1.1846,  1.0896],\n",
      "        [-0.2883,  1.0789],\n",
      "        [ 1.1279,  1.5276],\n",
      "        [ 1.4798, -1.0361],\n",
      "        [-1.9132,  1.5829],\n",
      "        [-0.2918,  0.6516],\n",
      "        [ 0.2704,  1.2737],\n",
      "        [ 0.3740, -1.9097],\n",
      "        [ 0.6717, -1.6588],\n",
      "        [ 0.3277, -0.4006],\n",
      "        [ 1.6043,  1.4477],\n",
      "        [ 0.1953, -0.5296],\n",
      "        [ 0.4149, -0.4413],\n",
      "        [ 0.5754, -0.0127],\n",
      "        [ 1.3785,  1.2512]])\n",
      "tensor([[-0.3524,  0.9085],\n",
      "        [-0.4110,  1.0032],\n",
      "        [ 0.6732,  1.1375],\n",
      "        [ 1.4089,  1.3356],\n",
      "        [ 1.4696,  0.9725],\n",
      "        [-1.6064,  0.6418],\n",
      "        [ 1.4555,  1.5014],\n",
      "        [ 1.4717,  0.1171],\n",
      "        [-0.5515,  1.1802],\n",
      "        [ 1.2205, -0.3631],\n",
      "        [ 1.3782, -0.6658],\n",
      "        [ 0.7082,  1.0059],\n",
      "        [ 1.5426,  1.2635],\n",
      "        [ 1.4692,  1.3999],\n",
      "        [ 1.5981, -0.6213],\n",
      "        [ 0.8898,  1.6085],\n",
      "        [ 1.4505,  1.3753],\n",
      "        [ 0.8400,  1.2858],\n",
      "        [ 1.2650, -0.0822],\n",
      "        [ 1.4630, -1.8156],\n",
      "        [ 1.2074, -0.0748],\n",
      "        [ 1.5075,  0.9681],\n",
      "        [ 1.5562,  0.7951],\n",
      "        [ 1.5236,  1.1808],\n",
      "        [ 0.2470,  0.2295],\n",
      "        [ 1.3731, -0.4710],\n",
      "        [ 1.1978,  1.4760],\n",
      "        [ 1.1085,  1.4093],\n",
      "        [ 1.2074, -0.0748],\n",
      "        [ 1.1260,  0.5859],\n",
      "        [ 0.8815,  1.5139],\n",
      "        [-1.8189,  1.4170]])\n",
      "tensor([[ 0.2470,  0.2295],\n",
      "        [ 0.8715,  1.0650],\n",
      "        [ 1.0787, -0.0660],\n",
      "        [-0.0436,  0.8036],\n",
      "        [ 0.2470,  0.2295],\n",
      "        [ 0.7522, -1.5367],\n",
      "        [ 1.4708,  1.5819],\n",
      "        [ 0.6327,  0.7719],\n",
      "        [ 0.6124,  0.6547],\n",
      "        [-1.1742,  0.9831],\n",
      "        [ 1.4499,  1.2437],\n",
      "        [ 1.0260, -1.2875],\n",
      "        [ 1.5627,  0.1326],\n",
      "        [ 0.2563,  1.3442],\n",
      "        [ 1.5846,  1.4890],\n",
      "        [ 1.4725,  1.4408],\n",
      "        [ 0.4139, -0.4940],\n",
      "        [ 0.7984,  1.2112],\n",
      "        [-0.5943,  1.1587],\n",
      "        [ 0.3631,  0.7047],\n",
      "        [ 1.1534,  0.9086],\n",
      "        [-0.8884,  1.3275],\n",
      "        [ 1.4144, -0.2451],\n",
      "        [ 0.3357,  1.1828],\n",
      "        [ 0.2934,  1.0729],\n",
      "        [ 0.4623,  1.2064],\n",
      "        [ 0.7357,  1.1364],\n",
      "        [-0.3511,  0.3088],\n",
      "        [ 1.4505,  1.3753],\n",
      "        [-0.8112,  1.0864],\n",
      "        [ 1.3930,  1.1589],\n",
      "        [ 1.0244,  0.0916]])\n",
      "tensor([[ 1.0476e+00,  1.2228e+00],\n",
      "        [ 5.8178e-01, -8.6966e-03],\n",
      "        [ 5.1193e-01,  6.3772e-01],\n",
      "        [-4.9469e-01,  2.5911e-01],\n",
      "        [ 1.1017e+00,  1.8547e-01],\n",
      "        [ 1.0596e+00,  1.5906e+00],\n",
      "        [ 1.3235e+00, -4.6178e-01],\n",
      "        [ 1.4784e+00,  1.2177e+00],\n",
      "        [ 1.1316e+00,  2.6328e-02],\n",
      "        [ 1.2177e+00,  2.1292e-02],\n",
      "        [ 1.1279e+00,  1.5276e+00],\n",
      "        [ 1.5289e+00,  1.5079e+00],\n",
      "        [ 1.0449e-01,  4.9430e-01],\n",
      "        [ 1.5982e+00, -7.2117e-01],\n",
      "        [ 1.5744e+00,  8.2249e-01],\n",
      "        [ 9.0138e-01, -1.9287e-01],\n",
      "        [-1.4995e-01,  1.1483e+00],\n",
      "        [ 8.6816e-01,  1.0676e+00],\n",
      "        [ 1.4936e+00,  1.4206e+00],\n",
      "        [ 1.5678e+00,  3.2048e-01],\n",
      "        [-7.9917e-02,  1.4686e+00],\n",
      "        [ 4.1561e-01,  1.4704e-03],\n",
      "        [ 1.5184e+00,  5.0122e-01],\n",
      "        [ 5.0385e-01,  1.5259e+00],\n",
      "        [ 1.4016e+00,  1.4997e+00],\n",
      "        [ 1.1873e+00, -5.5434e-01],\n",
      "        [-4.9469e-01,  2.5911e-01],\n",
      "        [ 5.9335e-01, -2.4409e-02],\n",
      "        [-5.0097e-02,  1.6063e+00],\n",
      "        [ 1.0236e+00, -2.5068e-01],\n",
      "        [ 1.5151e+00,  1.0852e+00],\n",
      "        [ 5.3994e-01,  1.1755e+00]])\n",
      "tensor([[ 1.1610, -1.1960],\n",
      "        [ 1.2637,  0.5639],\n",
      "        [ 0.2278,  0.3050],\n",
      "        [ 0.0804,  1.2665],\n",
      "        [ 0.6030, -0.9526],\n",
      "        [ 1.0825, -2.1115],\n",
      "        [ 0.2400,  0.7400],\n",
      "        [-0.5752,  1.0264],\n",
      "        [ 1.3552,  0.7437],\n",
      "        [ 1.4725,  1.4408],\n",
      "        [ 0.1925,  0.9816],\n",
      "        [ 0.8163,  1.0305],\n",
      "        [ 1.0558,  1.4565],\n",
      "        [ 0.6909,  1.3078],\n",
      "        [ 1.0476,  1.2228],\n",
      "        [ 1.3435,  0.9089],\n",
      "        [ 0.4613, -1.3067],\n",
      "        [ 1.4815,  1.5059],\n",
      "        [ 0.4028,  0.6349],\n",
      "        [-0.4947,  0.2591],\n",
      "        [ 1.4768, -0.1290],\n",
      "        [ 0.8163,  1.0305],\n",
      "        [ 0.7898,  1.3905],\n",
      "        [ 0.9180,  1.0517],\n",
      "        [-1.4758,  1.5529],\n",
      "        [-0.6362,  1.5806],\n",
      "        [ 1.5414, -1.8302],\n",
      "        [ 1.0550,  1.4094],\n",
      "        [ 1.0002,  1.4509],\n",
      "        [-0.2930,  1.0470],\n",
      "        [ 0.7469,  1.2879],\n",
      "        [ 1.2800, -1.0043]])\n",
      "tensor([[ 0.3522,  0.9539],\n",
      "        [ 1.5982, -0.7212],\n",
      "        [ 1.0496,  1.6067],\n",
      "        [ 1.1879,  0.3676],\n",
      "        [ 1.3395,  1.1431],\n",
      "        [ 0.6030, -0.9526],\n",
      "        [-0.5223, -0.3551],\n",
      "        [ 0.9015,  1.3456],\n",
      "        [-0.0403,  1.4553],\n",
      "        [ 1.2884,  0.9109],\n",
      "        [ 1.2190,  0.7338],\n",
      "        [-0.6362,  1.5806],\n",
      "        [-1.6064,  0.6418],\n",
      "        [-0.0303,  0.1120],\n",
      "        [-0.0133,  1.1680],\n",
      "        [ 0.7142,  0.8431],\n",
      "        [ 0.4057,  0.1161],\n",
      "        [-1.1537,  0.4354],\n",
      "        [ 0.9831,  1.0962],\n",
      "        [ 0.7469,  1.2879],\n",
      "        [ 0.3137,  1.5483],\n",
      "        [ 1.0858,  1.1390],\n",
      "        [ 0.7984,  1.2112],\n",
      "        [ 1.3738,  1.5858],\n",
      "        [ 1.4965, -0.5976],\n",
      "        [ 1.5303, -0.1221],\n",
      "        [ 0.2861, -2.1470],\n",
      "        [ 0.2704,  1.2737],\n",
      "        [ 0.2916, -0.0025],\n",
      "        [ 1.1052,  0.5177],\n",
      "        [ 1.5422,  0.4651],\n",
      "        [ 0.8791, -0.6133]])\n",
      "tensor([[-0.4632,  0.8927],\n",
      "        [ 1.2185,  1.0271],\n",
      "        [ 1.2931, -0.9273],\n",
      "        [ 0.2563,  1.3442],\n",
      "        [ 1.4027,  1.1118],\n",
      "        [ 0.5119,  0.6377],\n",
      "        [ 0.6673, -1.1550],\n",
      "        [ 1.2904,  1.2284],\n",
      "        [ 1.5957,  1.3181],\n",
      "        [ 0.7942,  1.2549],\n",
      "        [ 0.9165,  1.5520],\n",
      "        [ 1.3148,  1.3440],\n",
      "        [ 1.4657,  0.5812],\n",
      "        [-0.0036,  1.1956],\n",
      "        [ 1.2908,  1.4982],\n",
      "        [ 0.7815,  1.4670],\n",
      "        [ 0.1932,  0.5404],\n",
      "        [ 0.9180,  1.0517],\n",
      "        [ 1.5744,  0.8225],\n",
      "        [ 1.4396, -0.0577],\n",
      "        [ 0.3445, -1.4919],\n",
      "        [ 0.2235,  1.2676],\n",
      "        [-1.2962,  1.4516],\n",
      "        [ 0.5038,  1.5259],\n",
      "        [ 1.0813, -0.5248],\n",
      "        [-0.2696,  1.2181],\n",
      "        [ 1.4010,  1.0577],\n",
      "        [ 0.9404,  1.1994],\n",
      "        [ 1.4727,  1.5974],\n",
      "        [ 1.5296,  1.2808],\n",
      "        [ 0.9880,  0.5161],\n",
      "        [ 0.8968,  1.4215]])\n",
      "tensor([[ 1.4859e+00,  3.2200e-01],\n",
      "        [-2.1550e+00,  1.5184e+00],\n",
      "        [ 1.2065e+00,  2.6570e-03],\n",
      "        [ 1.2242e+00, -1.2267e-03],\n",
      "        [ 5.1956e-01,  1.5803e+00],\n",
      "        [ 1.2517e+00, -8.0917e-01],\n",
      "        [ 5.7002e-01,  1.5046e+00],\n",
      "        [-2.2988e+00,  9.8810e-01],\n",
      "        [ 3.5217e-01,  9.5388e-01],\n",
      "        [-4.2627e-01,  6.3701e-01],\n",
      "        [-1.3555e+00,  3.8481e-01],\n",
      "        [-1.0705e+00, -1.5542e+00],\n",
      "        [ 9.6601e-01,  2.8265e-01],\n",
      "        [-1.4951e+00,  6.7888e-01],\n",
      "        [ 1.4902e+00, -3.7696e-01],\n",
      "        [ 1.0526e+00,  9.0964e-01],\n",
      "        [ 3.8955e-01,  1.3646e+00],\n",
      "        [-3.8317e-01,  6.9873e-02],\n",
      "        [ 1.5412e+00,  1.5623e+00],\n",
      "        [ 8.6135e-01,  8.2315e-01],\n",
      "        [ 8.7253e-01,  1.0480e+00],\n",
      "        [ 9.7149e-01,  6.2154e-01],\n",
      "        [ 1.4950e+00,  1.4266e+00],\n",
      "        [ 6.1048e-02,  1.4700e+00],\n",
      "        [-1.0644e-01,  1.5406e+00],\n",
      "        [-1.1434e+00, -6.7064e-01],\n",
      "        [ 1.5590e+00,  3.2554e-01],\n",
      "        [-1.1949e-01,  3.1482e-01],\n",
      "        [ 1.3414e+00,  6.1276e-01],\n",
      "        [ 1.5642e+00,  9.1945e-01],\n",
      "        [ 6.1912e-01,  6.9736e-01],\n",
      "        [ 1.5153e+00,  2.6973e-01]])\n",
      "tensor([[-1.7273,  1.3724],\n",
      "        [-0.0514,  1.3805],\n",
      "        [ 0.4752,  1.4789],\n",
      "        [-0.9446, -0.4740],\n",
      "        [-0.2696,  1.2181],\n",
      "        [ 0.9647,  0.6328],\n",
      "        [ 1.5824,  1.3840],\n",
      "        [ 0.8815,  1.5139],\n",
      "        [ 0.8123, -0.4216],\n",
      "        [ 1.3284,  1.5744],\n",
      "        [-0.7587,  0.8943],\n",
      "        [ 1.4396, -0.0577],\n",
      "        [ 1.0409, -0.0659],\n",
      "        [ 1.0021,  1.0172],\n",
      "        [ 1.3782, -0.6658],\n",
      "        [ 0.3173,  0.7638],\n",
      "        [ 1.5151,  1.0852],\n",
      "        [-1.6339,  0.8105],\n",
      "        [-0.4263,  0.6370],\n",
      "        [ 1.1914,  0.4305],\n",
      "        [ 1.5016,  1.1596],\n",
      "        [ 1.0081,  1.5577],\n",
      "        [ 1.2761, -0.2461],\n",
      "        [ 1.3670,  1.0488],\n",
      "        [ 0.9015,  1.3456],\n",
      "        [-1.8166,  0.9821],\n",
      "        [-0.5495,  1.2518],\n",
      "        [ 1.3729,  1.6057],\n",
      "        [ 1.5041,  1.4809],\n",
      "        [ 1.3785,  1.2512],\n",
      "        [ 1.5824,  1.3840],\n",
      "        [ 1.5257,  0.6195]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-9.3441e-01,  7.5411e-01],\n",
      "        [ 1.4036e+00,  9.9759e-01],\n",
      "        [ 1.5678e+00,  3.2048e-01],\n",
      "        [ 1.4692e+00,  1.3999e+00],\n",
      "        [ 8.2597e-01,  4.5431e-01],\n",
      "        [ 1.4499e+00,  1.2437e+00],\n",
      "        [-4.0297e-02,  1.4553e+00],\n",
      "        [ 1.5438e+00, -1.4783e-04],\n",
      "        [ 1.1520e+00,  6.1959e-01],\n",
      "        [ 1.4071e+00, -1.0142e-01],\n",
      "        [ 1.4499e+00,  1.2437e+00],\n",
      "        [ 1.5576e+00,  6.3993e-01],\n",
      "        [ 1.0096e+00,  1.5168e+00],\n",
      "        [ 1.5981e+00, -6.2132e-01],\n",
      "        [ 1.2205e+00, -3.6307e-01],\n",
      "        [ 4.0282e-01,  6.3487e-01],\n",
      "        [ 1.3737e+00,  1.1799e+00],\n",
      "        [ 1.5348e+00,  1.4368e+00],\n",
      "        [ 1.3953e+00,  1.3418e+00],\n",
      "        [-2.3870e-01,  9.1780e-01],\n",
      "        [ 1.3559e+00, -1.2347e+00],\n",
      "        [ 1.4011e+00,  1.2062e+00],\n",
      "        [ 1.4725e+00,  1.4408e+00],\n",
      "        [ 1.2248e+00, -1.3209e+00],\n",
      "        [ 4.1493e-01, -4.4129e-01],\n",
      "        [ 1.5781e+00,  1.3166e+00],\n",
      "        [ 1.4306e+00,  1.5024e+00],\n",
      "        [ 9.1144e-01,  5.0256e-01],\n",
      "        [ 1.4811e+00,  1.2372e+00],\n",
      "        [ 2.7820e-01,  1.3346e+00],\n",
      "        [ 1.2815e+00,  1.2477e+00],\n",
      "        [-2.8825e-01,  1.0789e+00]])\n",
      "tensor([[ 0.2131,  1.0568],\n",
      "        [ 0.0610,  1.4700],\n",
      "        [-1.8300,  1.2896],\n",
      "        [ 0.9931,  0.1514],\n",
      "        [ 0.8814,  1.6054],\n",
      "        [ 0.9612, -0.2088],\n",
      "        [ 1.4111,  0.1364],\n",
      "        [ 1.2830,  0.7341],\n",
      "        [ 1.5149,  0.8012],\n",
      "        [ 0.1293,  0.9578],\n",
      "        [ 0.6671,  1.6001],\n",
      "        [ 1.5624,  1.3255],\n",
      "        [ 0.4057,  0.1161],\n",
      "        [ 0.6210, -0.4434],\n",
      "        [ 0.6132,  1.2209],\n",
      "        [ 1.4011,  0.4949],\n",
      "        [ 1.4438,  1.5189],\n",
      "        [ 1.4181, -0.1531],\n",
      "        [ 0.6132,  1.2209],\n",
      "        [ 1.4230,  0.5366],\n",
      "        [ 0.6894,  1.5603],\n",
      "        [ 0.7688,  1.0324],\n",
      "        [ 0.9630,  1.3831],\n",
      "        [-0.6186, -1.8092],\n",
      "        [ 0.4711,  1.3709],\n",
      "        [ 1.1526,  1.5518],\n",
      "        [ 0.7781,  1.0415],\n",
      "        [ 0.3392,  0.9152],\n",
      "        [ 1.4623,  0.4965],\n",
      "        [ 1.5135,  0.4391],\n",
      "        [ 1.1573, -0.0766],\n",
      "        [-0.3832,  0.0699]])\n",
      "tensor([[-1.4993e-01,  1.0982e+00],\n",
      "        [ 1.4397e+00,  1.0622e+00],\n",
      "        [ 6.1954e-01, -1.4112e+00],\n",
      "        [-5.6302e-01, -8.9323e-01],\n",
      "        [ 8.9678e-01,  1.4215e+00],\n",
      "        [ 2.5637e-02,  1.2209e+00],\n",
      "        [ 9.8309e-01,  1.0962e+00],\n",
      "        [ 1.0182e+00,  2.6291e-01],\n",
      "        [ 1.5151e+00,  1.0852e+00],\n",
      "        [ 8.4266e-02,  4.8775e-01],\n",
      "        [ 1.5827e+00,  1.4347e+00],\n",
      "        [-4.3377e-01,  8.0542e-02],\n",
      "        [ 1.3047e+00,  3.5464e-01],\n",
      "        [ 1.3825e+00,  5.3253e-01],\n",
      "        [ 1.2399e+00,  1.5191e+00],\n",
      "        [ 1.4459e+00,  7.6685e-01],\n",
      "        [ 1.4054e+00,  1.1754e+00],\n",
      "        [ 1.1868e+00,  1.0074e+00],\n",
      "        [ 1.2396e+00,  4.6701e-01],\n",
      "        [ 1.2499e+00,  1.4042e+00],\n",
      "        [ 9.1651e-01,  6.4972e-01],\n",
      "        [ 3.6590e-01, -9.5356e-01],\n",
      "        [ 6.7179e-01,  1.2939e+00],\n",
      "        [ 5.1480e-01,  3.2865e-01],\n",
      "        [ 1.4999e+00, -1.2714e+00],\n",
      "        [ 6.6715e-01,  1.6001e+00],\n",
      "        [-2.1638e+00,  1.0922e+00],\n",
      "        [ 2.4703e-01,  2.2950e-01],\n",
      "        [ 7.3644e-04,  1.4011e+00],\n",
      "        [ 1.1978e+00,  1.4760e+00],\n",
      "        [-5.5538e-01, -1.4605e+00],\n",
      "        [-3.6497e-03,  1.1956e+00]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-621-c4caa422b979>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0ml_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_inference_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0ml_sum\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-620-58e0394bf01d>\u001b[0m in \u001b[0;36mtrain_inference_network\u001b[1;34m(epoch, batch_per_task, n_batch)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogvar_prior\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_inference_closed_form\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu_prior\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar_prior\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Riccardo\\Anaconda3\\envs\\sequential-transfer-rl\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Riccardo\\Anaconda3\\envs\\sequential-transfer-rl\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 100000\n",
    "losses = []\n",
    "l_sum = 0\n",
    "for i in range(n_epochs):\n",
    "    l = train_inference_network(i)\n",
    "    l_sum += l\n",
    "    losses.append(l)\n",
    "    if i % 100 == 0:\n",
    "        print('====> Epoch: {} Average loss: {:.4f}'.format(i, l_sum/(i+1)))\n",
    "        \n",
    "#torch.save(inference_net, \"inference_mixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "y = np.array(mse_list)\n",
    "x = np.arange(len(y))\n",
    "yhat = savgol_filter(y,501, 3) \n",
    "\n",
    "plt.plot(x[10000:], yhat[10000:], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAc+klEQVR4nO3df5QV5X0/8PebZVFsElFYgYAK9tik1cZfGwKHNDFEDSpHbQ+nYmK0xoT6o6kmxjQay7eatKf5tiUmoQWJqUoM4s8vcgiYEJCqSZDs8ksRMVCQn7IrBpYFRJb9fP945npn7sz9ufdy9xner3PmzMwzz8x87o/93GefZ+5cmhlERMR/feodgIiIVIcSuohISiihi4ikhBK6iEhKKKGLiKRE33qdeNCgQTZixIh6nV5ExEutra1vm1lT0ra6JfQRI0agpaWlXqcXEfESyTfzbVOXi4hISiihi4ikhBK6iEhKKKGLiKSEErqISEoooYuIpIQSuohISviX0F99FfjHfwTa2uodiYhIr+JfQn/tNeC73wXa2+sdiYhIr+JfQu8ThKwf5hARiSg5oZNsILmS5PyEbReS3EtyVTBNqW6YkZO5eXd3zU4hIuKjcu7lchuAdQA+lGf7i2Y2oechFZFJ6Gqhi4hElNRCJzkcwOUAHqxtOCVQQhcRSVRql8v9AL4JoFA/xxiSq0kuJHlWz0PLQwldRCRR0YROcgKANjNrLVBtBYDTzewcAD8CMDfPsSaTbCHZ0l7pVSoaFBURSVRKC30sgCtIbgYwB8A4ko+GK5hZh5l1BssLADSSHJR7IDObaWbNZtbc1JR4f/biNCgqIpKoaEI3s7vMbLiZjQAwCcASM7s2XIfkENJlWpKjguPurkG86nIREcmj4l8sInkTAJjZDAATAdxMsgvAQQCTzGqUcZXQRUQSlZXQzWwpgKXB8oxQ+TQA06oZWF5K6CIiifRNURGRlPAvoWtQVEQkkb8JXS10EZEIJXQRkZRQQhcRSQn/EroGRUVEEvmX0DUoKiKSyN+Erha6iEiEErqISEoooYuIpIR/CV2DoiIiifxL6BoUFRFJ5G9CVwtdRCRCCV1EJCWU0EVEUsK/hK5BURGRRP4ldA2Kiogk8jehq4UuIhKhhC4ikhJK6CIiKeFfQtegqIhIIv8SugZFRUQS+ZvQ1UIXEYlQQhcRSYmSEzrJBpIrSc5P2EaSPyS5geQakudXN8zIydxcCV1EJKKcFvptANbl2XYpgDODaTKA6T2MKz8NioqIJCopoZMcDuByAA/mqXIlgFnmLAMwgOTQKsWYG4yba1BURCSi1Bb6/QC+CSBfFh0GYGtofVtQFkFyMskWki3t7e1lBRo6iJurhS4iElE0oZOcAKDNzFoLVUsoi2VcM5tpZs1m1tzU1FRGmJGAMgerbH8RkZQqpYU+FsAVJDcDmANgHMlHc+psA3BqaH04gB1ViTCXErqISKKiCd3M7jKz4WY2AsAkAEvM7NqcavMAXBdc7TIawF4z21n9cKFBURGRPPpWuiPJmwDAzGYAWADgMgAbABwAcENVoks+sZtrUFREJKKshG5mSwEsDZZnhMoNwK3VDCwvdbmIiCTSN0VFRFJCCV1EJCX8S+gaFBURSeRfQtegqIhIIn8TulroIiIRSugiIimhhC4ikhL+JXQNioqIJPIvoWtQVEQkkb8JXS10EZEIJXQRkZRQQhcRSQn/EroGRUVEEvmX0DUoKiKSyN+Erha6iEiEErqISEoooYuIpIR/CV2DoiIiifxL6BoUFRFJ5G9CVwtdRCRCCV1EJCWU0EVEUsK/hK5BURGRRP4ldA2KiogkKprQSR5PcjnJ1STXkrw3oc6FJPeSXBVMU2oTLtTlIiKSR98S6hwCMM7MOkk2AniJ5EIzW5ZT70Uzm1D9EHMooYuIJCqa0M3MAHQGq43BVL9sqoQuIpKopD50kg0kVwFoA7DIzF5OqDYm6JZZSPKsPMeZTLKFZEt7e3tlESuhi4gkKimhm9kRMzsXwHAAo0ienVNlBYDTzewcAD8CMDfPcWaaWbOZNTc1NVUWsQZFRUQSlXWVi5ntAbAUwPic8g4z6wyWFwBoJDmoWkHGkGqhi4jkKOUqlyaSA4Ll/gAuAvB6Tp0hpGs6kxwVHHd39cN9/4RK6CIiOUq5ymUogEdINsAl6ifMbD7JmwDAzGYAmAjgZpJdAA4CmBQMptaGErqISEwpV7msAXBeQvmM0PI0ANOqG1oBffoooYuI5PDvm6KAa6FrUFREJMLfhK4WuohIhBK6iEhKKKGLiKSEnwldg6IiIjF+JnQNioqIxPib0NVCFxGJUEIXEUkJJXQRkZTwM6FrUFREJMbPhK5BURGRGH8TulroIiIRSugiIimhhC4ikhJ+JvT2dqCjo95RiIj0Kn4mdACYPbveEYiI9Cr+JnQREYlQQhcRSYlSflO09xkyBBg3rt5RiIj0Kn620Pv3d98WFRGR9/mZFfv00TdFRURy+JvQdR26iEiEnwld93IREYkpmtBJHk9yOcnVJNeSvDehDkn+kOQGkmtInl+bcANqoYuIxJRylcshAOPMrJNkI4CXSC40s2WhOpcCODOYPgFgejCvDbXQRURiirbQzekMVhuDKbd5fCWAWUHdZQAGkBxa3VBD1EIXEYkpqQ+dZAPJVQDaACwys5dzqgwDsDW0vi0oqw210EVEYkpK6GZ2xMzOBTAcwCiSZ+dUYdJuuQUkJ5NsIdnS3t5efrQZumxRRCSmrKtczGwPgKUAxuds2gbg1ND6cAA7EvafaWbNZtbc1NRUZqghun2uiEhMKVe5NJEcECz3B3ARgNdzqs0DcF1wtctoAHvNbGfVo81QH7qISEwpV7kMBfAIyQa4D4AnzGw+yZsAwMxmAFgA4DIAGwAcAHBDjeJ11OUiIhJTNKGb2RoA5yWUzwgtG4BbqxtaARoUFRGJ8fOboupyERGJ8TOhq4UuIhLjZ0JXC11EJMbPhK4WuohIjJ8JXS10EZEYPxO6WugiIjF+JnS10EVEYvxN6Gqhi4hE+JnQ1eUiIhLjZ0JXl4uISIyfCV0tdBGRGD8TulroIiIxfiZ0tdBFRGL8TOhqoYuIxPib0NVCFxGJ8DOhq8tFRCTGz4SuLhcRkRg/E7pa6CIiMX4mdLXQRURi/EzoaqGLiMT4mdDVQhcRifEzoauFLiIS42dCVwtdRCTGz4R+8CDw1lv1jkJEpFcpmtBJnkryeZLrSK4leVtCnQtJ7iW5Kpim1CbcwLPPAh0dNT2FiIhv+pZQpwvAHWa2guQHAbSSXGRmr+XUe9HMJlQ/RBERKUXRFrqZ7TSzFcHyPgDrAAyrdWAiIlKesvrQSY4AcB6AlxM2jyG5muRCkmfl2X8yyRaSLe3t7WUHKyIi+ZWc0El+AMDTAG43s9wO7BUATjezcwD8CMDcpGOY2Uwzazaz5qampkpjBm67DfjQhyrfX0QkhUpK6CQb4ZL5z8zsmdztZtZhZp3B8gIAjSQHVTXSsIYG4MiRmh1eRMRHpVzlQgA/AbDOzKbmqTMkqAeSo4Lj7q5moBFK6CIiMaVc5TIWwBcBvEJyVVB2N4DTAMDMZgCYCOBmkl0ADgKYZFbDb/4ooYuIxBRN6Gb2EgAWqTMNwLRqBVVUQ4O++i8iksPPb4r26aMWuohIDj8TekODm6uVLiLyPr8TulrpIiLvU0KXY093N9DWVu8oRKrO74SuLhepREMDMHgwsHlzvSM5dnV3u981mDWr3pGkip8JvU8QtlroPbdrF/DCC5Xtu3070NICtLYCQ4cCXV3Vja3Wbryx3hH0zN69R/+cN93kEnFPfeELbn799T0/lrzPz4R+LHW5vPsuMGVK4cd6+DCwbl1lxx8yBPj0p7M/GEK6Kd/XCMyA738f2LMHGD4c+PjHgeZmd3/6xsb859m2LXvsatuxAzh0CNi0Cfiv/ypc98CB7PKSJYXrmgH790fL3nvPPd89cfAgcO65+T9Iw6+BGXDKKcD06dE6mzYBAwa4er/+tSt77DG3fuhQtt7+/aXdanrjRrdvsefkgQfcPHzrjUOHgC1bsut79wK33hp9z370o8C112bXh4Xu7zduXPH4wv7qr2rzPsrV2gpMnAj84Q/l7dfZ6V7jejCzukwXXHCBVewHP3Bv9bffrvwY9ZD5E92xw+zdd83a2sy6u81Wrsxu27gxeR8gut7aavaNb7j9P/MZV3bNNa7Ok09m65uZzZrl1v/pn9z6u++69fvuyx7vnXfcsTLrd9zh5pMnm40ZEz9/vinz2mzYUPhxHDlitn17dnt3t9mcOWaHD8eft6FD3X7d3fFtu3bFY9izJ7v9jTfM2tuz6+PGxWMxM9uyxWzVKrPvfc+9LsUea6k2b87uc+SIKwu/3oDZL36R3RZ+DR580Gz37ux65vE/91xyPJnl/v2z58+UnXaamz/xhCvv6jK74AJXlnk/ZKYlS1xZ2MKFZlOmJD8H+eL48pfj25980uyii8y+8IX4Y7jxxvjz9+abbtvixWbvvWf213+drf/b35b+Opi599aSJdn1++8327cv+zp99avZ1yE37hNOcPPLLzf7j/8wu+WWbL3PftbsrLPi+4V95zuu7KWXyos5AYAWy5NXj1oCz516lNCnTXOh79pV+TGq7ZZbXEwPP+zW29rcmzHjrbeKJ8PMlEnM77wTLZ8xI173D3+Irv/t32aXBw40a2qKbs/9o8xMy5a5JFxqjKVOU6ea7d0bLVu9Orv84Q+bHToU3d7ZmX3e1q2LbmttdfXN8p/zqafMFiww27kzW9bVlX+ft9+OlxU6PmB28KBLMEm2bHF1Xnstus8dd7jtjz6a/7jhx/ulL5m9+GJ2/Stfyb9fbrz9+vX8tcs8z/mei3BjIjPt2ROvE14/+WQ3P+MMs3POSX4cYX/+5/njGzw4u9ynj/sAyawfOODiX7zYrX/xi9F9r7suuxz+kFiwwOzaa0t7fjKNj3DZqlXZ5eOOc/MjR7Jl48eXlk8KSF9Cnz7dhb5zZ+XH6KktW8waGlwLyiz/H9e990Zf3FKnpOSdNP34x+UdN9/0P/+TjbU3TBn5tj/+eP1jBNz74NZb3Xz27OL1cxNgtab582tz3IMHo/9llDtlWrZJ0+23m33uc/Hy1193r/0zz9T/9a3F1EPpS+gPPOBC37at8mNUItPyyv03f+3a6Pr27UfvzXHiifV/gwLZrpZqTlddVf/HBZh99KOlt9o0lT5dcYXZv/xL8jaz+sdXy2nGjIrTUKGE7ueg6Pz5br59+9E7pxlw2mluefDg6Lazcn7PY1gZP+h0yinAvHnu+J/5THKd3QVuXFnqlQ5r1pQeU5KPfzy7fPzx2eVDh1zsf//3xY/x+9+Xd865ibfVr44f/CBeNmECcOed0TIzN+D8058CZ59d2bl27Khsv0KOPx741a/cYHOpurqyFxSMH+8GtsP+8i8L79/aCmzYABx3XHxb7mN84ono+j33xPeZOhW46y7gkkuA2bOj28KDrIVcdFHxOnPmlHas8Hs89xzlPM9XX128Tq1+4Cdfpq/11KMWeqafeNmyyo9Rjtx+6nxTof6+pKmlJX6ujg7XlZOps3ixK3/vvcLHeucdswsvzL+9uzv6b/n115tdfbUbJCsl1oydO7P/qdx9dzT2TN033nADXN3dbso30BTu4y407djhHv+wYW7gqlDdf/iHeNnZZ0fXP/zh5HjeeiteliTcV1vqc1duCy7clRZ+PwBmd96Z/LwDZhMmRNcffdTsu98127Qp+bFkxk3efNN1HWX2GzIk/3sg3C9+8GC2/M47o++Jz38+W2/hwuzy175mNnNmPJZ8z0V4jGPjRjcekll/7jmzpUuLP//Ll5v927+55yGpTmenGzAN7/P889FxktyxnvB08KCrf8kl0YH9HTuydcJxP/JI8utRAqSuyyVzFceaNZUfI0l48CKs1D/CzIh8oWnt2uigX5JrrkmOY+BAs9GjXb/9nj3ZK1HC9U4/PXq+886Lbv/a11yCC+vudkkus09bm4uhu9t9mG3ZUtrzt2+f2dathes89JA7x/r1bj1zzhdfdI8pqb82SVtbNul0dbkPtMzAp5l7npuasuvh1/bBB7Pl+c6zYkXyFTdh+d4DuR+S+eqamS1alP/xdnW5RLR/f3ZQ78c/jsfxu98ln2vWrMLx58p9/wNmffu6q1IyV4NUKnzsBQvy18v3PF11VfQKlc5Os3nzkvfNyPf6ZRqE4QHcTP1C7zkz977dutUl9zlzzP74jwvXz31Or77aLb/6av59ikhfQp8714Xe2lr5MZK0tUWf/OXLCyfn9vbo+pEj7pKmzPpvfuMGGp9+uvgbJSzc0i+ku9tdLvX1r2fLOjvdGEPSJX6F7N/vzvfP/1zefj3V0WH2y19Gy8p5rsrR1WX2859Hy/73f925nn66/ONlrlx69lk3//a3s9syVxetXu3Wjxwx+8hHzD796eyHUMbKle4ywauvdu+5JIcPuw+7JAcORJ+z9nY34Bi+SqU32LPH7J57Ctfp7jYbOTL7ePJdSVQtmzZFLxV+4YXaXg7d1ub+U+6B9CX0n//chV7tLpff/Cb7Rsq9Vhgw+/Wv3afzPfdku0Keesq1OjPC3R4ZmU/+RYtKi2PfPnd5YbEWokjGfffFW6w+Gzu2Nh/qKVAoodNtP/qam5utpaWlsp1/9Svg4ovdN+3+4i+qF9TIkdn7e3zqU9Fv8l15ZWmDdIsWuUEewKV1EZEqItlqZs1J2/y8yiXzFfOefgU7V1NTdjn3a9n5RsBzXXwxcPvtld8fRUSkQn4m9MzNuf71X6t73Msvz7/tG98o/Tjf/351/3MQESlBKT8S3fu8956bL1pU3eM+9li87MiR7AeIiEgv5memqvTOgsXk9nlPn65kLiLe8LOFPnBg7Y77yU+6m+53dADnnFOb84iI1ICfCX3SJODzny/tK7al6OgATjwxuz5yZHWOKyJyFPnZn0C6+6r071+d433lK9U5johIHRVN6CRPJfk8yXUk15K8LaEOSf6Q5AaSa0ieX5twQ/r1i/4yS6X+5E+iNxLSteMi4qlSuly6ANxhZitIfhBAK8lFZvZaqM6lAM4Mpk8AmB7Ma+e446qT0MN3AFQyFxGPFW2hm9lOM1sRLO8DsA5A7v1hrwSQuRPQMgADSA6terRh/fplL1+sVHd3dnn06J4dS0SkzsrqQyc5AsB5AF7O2TQMwNbQ+jbEkz5ITibZQrKlvaf3A65GCz1zz+WpU7M/tCsi4qmSEzrJDwB4GsDtZpb7M+JJP8Ed678ws5lm1mxmzU3hr9lXohot9NeCXqNRo3S9uYh4r6QsRrIRLpn/zMyeSaiyDcCpofXhAGrwMy0hjY3Avn09O8bChW7+p3/a83hEROqslKtcCOAnANaZ2dQ81eYBuC642mU0gL1mtrOKccYtXgysWFHZvt/5jrv0cdo0t37yydWLS0SkTkq5ymUsgC8CeIXkqqDsbgCnAYCZzQCwAMBlADYAOADghuqHmoeZS87lmDKlNrGIiNRR0YRuZi8huY88XMcA3FqtoMrS1ZW9nW4pMt0sGeo7F5GU8D+bvftuefWnT3fzv/kb4KWXqn9PdRGROvE3od9zj5uXe+ni8OHASScBDz0EjB2rFrqIpIafN+cC3L1cgOIJ/fBh1y2Tue9LpoUuIpIy/jZPf/tbN3/88eTtmZ9q7tcPOOEEIPz7pQ0NtY9PROQo8zehb9jg5vPmJW+/4YZod8orrwA33+yWP/ax2sYmIlIH/na5DB7s5rt2JW9/5JHo+pe+lF2+++7axCQiUkf+ttCvuMLNR4yoaxgiIr2Fvwl90iQ3f+454D//M7pt+/bC+151VW1iEhGpI38TevjLRH/3d9Ftmzdnlx9+OLu8a5cbKO3rb0+TiEg+/ib0QubOdfPVq4HrrweuucatDxpUv5hERGosHQl9/Pjo+r//u5ufGtwA8qc/BXbv1peIRCTV0pHhwl8uCv8K0UknuXlDg+6oKCKpl46EHqYvDYnIMSodCb2nP3QhIpICfif02bPdfP16d/VK+DYAPf15OhERz/id0DNXr+zb565Fz1ybDpR3j3QRkRTwO6GHffWr9Y5ARKSu0pPQRUSOcf4n9PBtcUVEjmH+J/TMD11kTJ8OrFxZn1hEROrI/5uaDByYXZ49OztQKiJyjPG/hR7+Ov/EifWLQ0SkzvxP6GG6VFFEjmH+d7kAwJNP6tuiInLMK5rQSf43gAkA2szs7ITtFwJ4FsCmoOgZM7uvmkEWpa4WEZGSWugPA5gGYFaBOi+a2YSqRCQiIhUp2oduZi8AeOcoxCIiIj1QrUHRMSRXk1xI8qx8lUhOJtlCsqW9vb1KpxYREaA6CX0FgNPN7BwAPwIwN19FM5tpZs1m1tzU1FSFU4uISEaPE7qZdZhZZ7C8AEAjSf14p4jIUdbjhE5yCEkGy6OCY+7u6XFFRKQ8pVy2+BiACwEMIrkNwP8B0AgAZjYDwEQAN5PsAnAQwCQzs5pFLCIiiYomdDMreHMUM5sGd1mjiIjUEevVmCbZDuDNMncbBODtGoRTa77GDfgbu+I+unyNG/Av9tPNLPGqkrol9EqQbDGz5nrHUS5f4wb8jV1xH12+xg34HXuudN2cS0TkGKaELiKSEr4l9Jn1DqBCvsYN+Bu74j66fI0b8Dv2CK/60EVEJD/fWugiIpKHErqISEp4k9BJjie5nuQGkt+qUwz/TbKN5KuhspNJLiL5+2B+UmjbXUG860l+LlR+AclXgm0/DN064TiSjwflL5McUYWYTyX5PMl1JNeSvM2HuIPjHk9yeXAnz7Uk7/Ul9uDYDSRXkpzvS9wkNwfnW0WyxaO4B5B8iuTrwXt9jA9xV52Z9foJQAOAjQDOANAPwGoAf1aHOD4F4HwAr4bK/i+AbwXL3wLwvWD5z4I4jwMwMoi/Idi2HMAYAASwEMClQfktAGYEy5MAPF6FmIcCOD9Y/iCAN4LYenXcwbEI4APBciOAlwGM9iH24HhfBzAbwHwf3ivBsTYDGJRT5kPcjwD4crDcD8AAH+Ku9lT3AEp8scYA+EVo/S4Ad9UplhGIJvT1AIYGy0MBrE+KEcAvgscxFMDrofJrADwQrhMs94X79hqrHP+zAC72MO4T4G7V/AkfYgcwHMBiAOOQTeg+xL0Z8YTeq+MG8CG4n8CkT3HXYvKly2UYgK2h9W1BWW8w2Mx2AkAwPyUozxfzsGA5tzyyj5l1AdgLYGC1Ag3+TTwPrqXrRdxBt8UqAG0AFpmZL7HfD+CbALpDZT7EbQB+SbKV5GRP4j4DQDuAh4IurgdJ/pEHcVedLwmdCWW9/XrLfDEXeiw1e5wkPwDgaQC3m1lHoap5YqhL3GZ2xMzOhWvxjiIZ+6HykF4RO8nMj6q3lrpLnhjq8ZyPNbPzAVwK4FaSnypQt7fE3ReuK3S6mZ0HYD9cF0s+vSXuqvMloW8DcGpofTiAHXWKJdcukkMBIJi3BeX5Yt4WLOeWR/Yh2RfAiajC77mSbIRL5j8zs2d8iTvMzPYAWApgvAexjwVwBcnNAOYAGEfyUQ/ihpntCOZtAP4fgFEexL0NwLbgvzcAeAouwff2uKvOl4T+OwBnkhxJsh/coMS8OseUMQ/A9cHy9XB91JnyScHo+EgAZwJYHvzrt4/k6GAE/bqcfTLHmghgiQWddpUKzvETAOvMbKovcQexN5EcECz3B3ARgNd7e+xmdpeZDTezEXDv1SVmdm1vj5vkH5H8YGYZwCUAXu3tcZvZWwC2kvxIUPRZAK/19rhrot6d+KVOAC6Du0JjI4Bv1ymGxwDsBHAY7hP7Rrh+tMUAfh/MTw7V/3YQ73oEo+VBeTPcH8pGuHvJZ76xezyAJwFsgBttP6MKMX8S7l/DNQBWBdNlvT3u4LgfA7AyiP1VAFOC8l4fe+i8FyI7KNqr44bri14dTGszf2e9Pe7guOcCaAneK3MBnORD3NWe9NV/EZGU8KXLRUREilBCFxFJCSV0EZGUUEIXEUkJJXQRkZRQQhcRSQkldBGRlPj/qGbulWKyPSQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "y = np.array(kld_list)\n",
    "x = np.arange(len(y))\n",
    "yhat = savgol_filter(y,501, 3) \n",
    "\n",
    "plt.plot(x[500:], yhat[500:], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "y = np.array(losses)\n",
    "x = np.arange(len(y))\n",
    "yhat = savgol_filter(y,51, 3) \n",
    "\n",
    "plt.plot(x[500:], yhat[500:], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Riccardo\\Anaconda3\\envs\\sequential-transfer-rl\\lib\\site-packages\\torch\\serialization.py:360: UserWarning: Couldn't retrieve source code for container of type InferenceNetwork2. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(inference_net, \"inference_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-task learning optimal policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_sin\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import deque\n",
    "from gym import spaces\n",
    "\n",
    "\n",
    "from ppo_a2c.model import Policy, MLPBase, ImprovedMLPBase\n",
    "from ppo_a2c.algo.ppo import PPO\n",
    "from ppo_a2c.storage import RolloutStorage\n",
    "from ppo_a2c.envs import make_vec_envs_multi_task\n",
    "from ppo_a2c.utils import get_vec_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General parameters\n",
    "device = \"cpu\"\n",
    "env_name = \"gauss-v0\"\n",
    "seed = 0\n",
    "gamma = None\n",
    "log_dir = \".\"\n",
    "\n",
    "# Training parameters\n",
    "num_steps_multi_task = 150\n",
    "num_processes = 32\n",
    "\n",
    "# PPO parametrs\n",
    "clip_param_multi_task = 0.2\n",
    "ppo_epoch_multi_task = 4\n",
    "num_mini_batch_multi_task = 8\n",
    "value_loss_coef_multi_task = 0.5\n",
    "entropy_coef_multi_task = 0.0\n",
    "lr_multi_task = 0.0001\n",
    "eps_multi_task = 1e-6\n",
    "max_grad_norm_multi_task = 0.5\n",
    "\n",
    "# Training parameters\n",
    "use_linear_lr_decay = False\n",
    "use_gae = False\n",
    "gae_lambda = 0.95\n",
    "use_proper_time_limits = False\n",
    "log_interval = 100\n",
    "eval_interval = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_multi_task = MLPBase\n",
    "obs_shape_multi_task = (2,) # state + latent space of the current model\n",
    "action_space_multi_task = spaces.Box(low=np.array([-1]), high=np.array([1]))\n",
    "actor_critic_multi_task = Policy(obs_shape_multi_task,\n",
    "                                 action_space_multi_task, base=base_multi_task,\n",
    "                                 base_kwargs={'recurrent': False,'hidden_size':16,'use_elu':True})\n",
    "\n",
    "agent_multi_task = PPO(actor_critic_multi_task,\n",
    "          clip_param_multi_task,\n",
    "          ppo_epoch_multi_task,\n",
    "          num_mini_batch_multi_task,\n",
    "          value_loss_coef_multi_task,\n",
    "          entropy_coef_multi_task,\n",
    "          lr=lr_multi_task,\n",
    "          eps=eps_multi_task,\n",
    "          max_grad_norm=max_grad_norm_multi_task,\n",
    "          use_clipped_value_loss=True)\n",
    "\n",
    "episode_rewards = deque(maxlen=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_obs(latent, latent_dim, num_proc):\n",
    "    \"\"\"\n",
    "    Augment observation with the latent space\n",
    "    \n",
    "    Input\n",
    "    - obs: observation from the environment (shape: (num_proc, env_obs_shape))\n",
    "    - latent: list of tuples of latent parameters (size list: num proc, size tuple: latent dim)\n",
    "    - latent_dim: dimension of the latent space\n",
    "    - env_obs_shape: shape of the observation from the environment\n",
    "    \n",
    "    \n",
    "    Output:\n",
    "    - tensor of size (num_processes, latent_dim+env_obs_shape)\n",
    "    \"\"\"\n",
    "    new_obs = torch.empty((num_proc, latent_dim))\n",
    "    \n",
    "    for i in range(num_proc):\n",
    "        new_obs[i] = torch.tensor(latent[i])\n",
    "    \n",
    "    return new_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def multi_task_evaluate(actor_critic, env_name, seed, num_processes, eval_log_dir, device,\n",
    "                       num_task_to_evaluate, latent_dim, env_obs_shape):\n",
    "    assert num_task_to_evaluate % num_processes == 0\n",
    "    \n",
    "    print(\"Evaluation...\")\n",
    "    \n",
    "    n_iter = num_task_to_evaluate // num_processes\n",
    "    r_epi_list = []\n",
    "    \n",
    "    for _ in range(n_iter):\n",
    "        # Sample new task\n",
    "        curr_task_idx = np.random.randint(low=0, high=n_tasks, size=(num_processes,))\n",
    "        # curr_task_idx = fixed_idx\n",
    "        curr_latent = [param[i] for i in curr_task_idx]\n",
    "\n",
    "        envs_kwargs = [{'mean':param[curr_task_idx[i]][0], \n",
    "                        'std':param[curr_task_idx[i]][1],\n",
    "                        'scale_reward':False} for i in range(num_processes)]\n",
    "        eval_envs = make_vec_envs_multi_task(env_name,\n",
    "                                        seed + num_processes, \n",
    "                                        num_processes,\n",
    "                                        None,\n",
    "                                        log_dir,\n",
    "                                        device,\n",
    "                                        False,\n",
    "                                        envs_kwargs,\n",
    "                                        num_frame_stack=None)\n",
    "        \n",
    "        eval_episode_rewards = []\n",
    "\n",
    "        obs = eval_envs.reset()\n",
    "        obs = augment_obs(curr_latent, latent_dim, num_processes)\n",
    "        eval_recurrent_hidden_states = torch.zeros(\n",
    "            num_processes, actor_critic.recurrent_hidden_state_size, device=device)\n",
    "        eval_masks = torch.zeros(num_processes, 1, device=device)\n",
    "        \n",
    "        while len(eval_episode_rewards) < 10:\n",
    "            with torch.no_grad():\n",
    "                _, action, _, eval_recurrent_hidden_states = actor_critic.act(\n",
    "                    obs,\n",
    "                    eval_recurrent_hidden_states,\n",
    "                    eval_masks,\n",
    "                    deterministic=True)\n",
    "\n",
    "            # Obser reward and next obs\n",
    "            obs, _, done, infos = eval_envs.step(action)\n",
    "            obs = augment_obs(curr_latent, latent_dim, num_processes)\n",
    "            \n",
    "            eval_masks = torch.tensor(\n",
    "                [[0.0] if done_ else [1.0] for done_ in done],\n",
    "                dtype=torch.float32,\n",
    "                device=device)\n",
    "\n",
    "            for info in infos:\n",
    "                if 'episode' in info.keys():\n",
    "                    total_epi_reward = info['episode']['r']\n",
    "                    eval_episode_rewards.append(total_epi_reward)\n",
    "                \n",
    "\n",
    "        r_epi_list.append(eval_episode_rewards)\n",
    "        eval_envs.close()\n",
    "        \n",
    "    r_epi_list = reduce(list.__add__, r_epi_list)\n",
    "    print(\"Evaluation using {} tasks. Mean reward: {}\".format(n_iter, np.mean(r_epi_list)))\n",
    "    return np.mean(r_epi_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 143.9374944921875\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 143.5965143203125\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 141.1602116484375\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 146.33813352343748\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 145.6324271953125\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 143.66349988281252\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 130.3402779453125\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 142.04561257812497\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 143.705583046875\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 140.3546724453125\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 144.727586546875\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 140.71887003125\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 136.93633582812498\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 141.959502390625\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 144.335876515625\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 142.3949495546875\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 139.63541910156252\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 135.45488478125\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 135.355424015625\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 132.42237339843751\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 136.5467845078125\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 141.948529390625\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 143.637691859375\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 140.7394832890625\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 145.871118640625\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 143.398766125\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 142.68898240625\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 139.3221694921875\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 139.96980253125\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 146.496962265625\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 146.008846265625\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 147.01408160937498\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 147.9570768046875\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 146.8267867578125\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 138.6235539921875\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 145.4630486640625\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 145.78810567187503\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 144.8420692421875\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 146.7918636328125\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 136.812106625\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 135.6806770078125\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 143.24877891406248\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 145.4747189453125\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 138.5734503359375\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 135.8804366015625\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 142.354113296875\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 141.229192921875\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 147.808218578125\n",
      "Evaluation...\n",
      "Evaluation using 4 tasks. Mean reward: 140.219711421875\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "meta_training_iter = 1000\n",
    "num_update_per_meta_training_iter = 1\n",
    "num_task_to_evaluate = 128\n",
    "\n",
    "latent_dim = 2\n",
    "env_obs_shape = 1\n",
    "\n",
    "log_interval = 5\n",
    "eval_interval = 20\n",
    "# eval_list = []\n",
    "\n",
    "for j in range(meta_training_iter):\n",
    "    # Sample new task\n",
    "    curr_task_idx = np.random.randint(low=0, high=n_tasks, size=(num_processes,))\n",
    "    # curr_task_idx = fixed_idx\n",
    "    curr_latent = [param[i] for i in curr_task_idx]\n",
    "    \n",
    "    envs_kwargs = [{'mean':param[curr_task_idx[i]][0], \n",
    "                    'std':param[curr_task_idx[i]][1],\n",
    "                    'scale_reward':False} for i in range(num_processes)]\n",
    "    \n",
    "    envs = make_vec_envs_multi_task(env_name,\n",
    "                                    seed, \n",
    "                                    num_processes,\n",
    "                                    gamma,\n",
    "                                    log_dir,\n",
    "                                    device,\n",
    "                                    False,\n",
    "                                    envs_kwargs,\n",
    "                                    num_frame_stack=None)\n",
    "    obs = envs.reset()\n",
    "    obs = augment_obs(curr_latent, latent_dim, num_processes)\n",
    "    \n",
    "    rollouts_multi_task = RolloutStorage(num_steps_multi_task, num_processes,\n",
    "                              obs_shape_multi_task, action_space_multi_task,\n",
    "                              actor_critic_multi_task.recurrent_hidden_state_size)\n",
    "    \n",
    "    rollouts_multi_task.obs[0].copy_(obs)\n",
    "    rollouts_multi_task.to(device)\n",
    "    \n",
    "    for _ in range(num_update_per_meta_training_iter):\n",
    "        # Collect observations and store them into the storage\n",
    "        for step in range(num_steps):\n",
    "            # Sample actions\n",
    "            with torch.no_grad():\n",
    "                value, action, action_log_prob, recurrent_hidden_states = actor_critic_multi_task.act(\n",
    "                    rollouts_multi_task.obs[step], rollouts_multi_task.recurrent_hidden_states[step],\n",
    "                    rollouts_multi_task.masks[step])\n",
    "\n",
    "            # Obser reward and next obs\n",
    "            obs, reward, done, infos = envs.step(action)\n",
    "            obs = augment_obs(curr_latent, latent_dim, num_processes)\n",
    "            \n",
    "            for info in infos:\n",
    "                if 'episode' in info.keys():\n",
    "                    episode_rewards.append(info['episode']['r'])\n",
    "\n",
    "            # If done then clean the history of observations.\n",
    "            masks = torch.FloatTensor(\n",
    "                [[0.0] if done_ else [1.0] for done_ in done])\n",
    "            bad_masks = torch.FloatTensor(\n",
    "                [[0.0] if 'bad_transition' in info.keys() else [1.0]\n",
    "                 for info in infos])\n",
    "            rollouts_multi_task.insert(obs, recurrent_hidden_states, action,\n",
    "                            action_log_prob, value, reward, masks, bad_masks)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            next_value = actor_critic_multi_task.get_value(\n",
    "                rollouts_multi_task.obs[-1], rollouts_multi_task.recurrent_hidden_states[-1],\n",
    "                rollouts_multi_task.masks[-1]).detach()\n",
    "\n",
    "        rollouts_multi_task.compute_returns(next_value, use_gae, 1,\n",
    "                                 gae_lambda, use_proper_time_limits)\n",
    "\n",
    "        value_loss, action_loss, dist_entropy = agent_multi_task.update(rollouts_multi_task)\n",
    "\n",
    "        rollouts_multi_task.after_update()\n",
    "\n",
    "    if j % log_interval == 0 and len(episode_rewards) > 1:\n",
    "            total_num_steps = (j + 1) * num_processes * num_steps\n",
    "            end = time.time()\n",
    "            print(\n",
    "                \"Updates {}, num timesteps {}, FPS {} \\n Last {} training episodes: mean/median reward {:.1f}/{:.1f}, min/max reward {:.1f}/{:.1f}\\n\"\n",
    "                .format(j, total_num_steps,\n",
    "                        int(total_num_steps / (end - start)),\n",
    "                        len(episode_rewards), np.mean(episode_rewards),\n",
    "                        np.median(episode_rewards), np.min(episode_rewards),\n",
    "                        np.max(episode_rewards), dist_entropy, value_loss,\n",
    "                        action_loss))\n",
    "    \n",
    "    if (eval_interval is not None and j % eval_interval == 0 and j>1):\n",
    "        e = multi_task_evaluate(actor_critic_multi_task, env_name, seed, num_processes, \".\", device,\n",
    "                                num_task_to_evaluate, latent_dim, env_obs_shape)\n",
    "        eval_list.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "y = np.array(eval_list)\n",
    "x = np.arange(len(y))\n",
    "yhat = savgol_filter(y,31, 3) \n",
    "\n",
    "plt.plot(x, yhat, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_sin\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import deque\n",
    "from gym import spaces\n",
    "import torch\n",
    "\n",
    "\n",
    "from ppo_a2c.model import Policy, MLPBase, ImprovedMLPBase\n",
    "from ppo_a2c.algo.ppo import PPO\n",
    "from ppo_a2c.storage import RolloutStorage\n",
    "from ppo_a2c.envs import make_vec_envs_multi_task\n",
    "from ppo_a2c.utils import get_vec_normalize\n",
    "from ppo_a2c.envs import RewardSmoother, ObsSmoother, AdvancedRewardSmoother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_net = torch.load(\"inference_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General parameters\n",
    "device = \"cpu\"\n",
    "env_name = \"gauss-v0\"\n",
    "seed = 0\n",
    "gamma = 0.99\n",
    "log_dir = \".\"\n",
    "\n",
    "# Training parameters\n",
    "num_steps = 30\n",
    "num_processes = 32\n",
    "\n",
    "# PPO parametrs\n",
    "clip_param = 0.2\n",
    "ppo_epoch = 4\n",
    "num_mini_batch = 8\n",
    "value_loss_coef = 0.5\n",
    "entropy_coef = 0.001\n",
    "lr = 0.00005\n",
    "eps = 1e-6\n",
    "max_grad_norm=0.5\n",
    "\n",
    "# Training parameters\n",
    "use_linear_lr_decay = False\n",
    "use_gae = False\n",
    "gae_lambda = 0.95\n",
    "use_proper_time_limits = False\n",
    "\n",
    "# A2C\n",
    "base = MLPBase\n",
    "obs_shape = (8,) # state + latent space of the current model\n",
    "action_space = spaces.Box(low=-1., high=1., shape=(1,), dtype=\"float\")\n",
    "actor_critic = Policy(obs_shape,\n",
    "                      action_space, base=base,\n",
    "                      base_kwargs={'recurrent':False,'hidden_size':32,'use_elu':False})\n",
    "\n",
    "# PPO \n",
    "agent = PPO(actor_critic,\n",
    "          clip_param,\n",
    "          ppo_epoch,\n",
    "          num_mini_batch,\n",
    "          value_loss_coef,\n",
    "          entropy_coef,\n",
    "          lr=lr,\n",
    "          eps=eps,\n",
    "          max_grad_norm=max_grad_norm,\n",
    "          use_clipped_value_loss=True)\n",
    "\n",
    "# Reward log structure\n",
    "episode_rewards = deque(maxlen=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mse(p, t, latent_dim):\n",
    "    if type(p) == list:\n",
    "        p = torch.tensor([p[i].flatten().tolist() for i in range(num_processes)])\n",
    "    return F.mse_loss(p[:, 0:latent_dim], t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward(p, t, latent_dim):\n",
    "    like = get_like(p, t, latent_dim)\n",
    "    return like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posterior(vi, action, reward, prior, prev_latent_space, use_prev_state=True):\n",
    "    \"\"\"\n",
    "    Feed the variational model with the actual reward to identifiy the latent space\n",
    "    and get the current reward using the posterior and the true task\n",
    "    \"\"\"\n",
    "    num_proc = action.shape[0]\n",
    "    prev_latent_space = torch.tensor(prev_latent_space)\n",
    "    flatten_prior = torch.tensor([prior[i].flatten().tolist() for i in range(num_processes)])\n",
    "    \n",
    "    # To feed VI, i need (n_batch, 1, 2)\n",
    "    context = torch.empty(num_proc, 1, 2)\n",
    "    for i in range(num_proc):\n",
    "        t = (100 - (-100))/(1 -(-1)) * (action[i] - 1) + 100\n",
    "        context[i] = torch.cat([t, reward[i]])\n",
    "    \n",
    "    res = vi(context=context, prev_z=prev_latent_space, prior=flatten_prior, use_prev_state=use_prev_state)\n",
    "    res = res[1:]\n",
    "    res = torch.cat([res[0].detach(), res[1].detach()], 1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_latent(num_proc, old_var, latent_dim):\n",
    "    rescaled_latent = []\n",
    "    \n",
    "    max_old = [40, 35]\n",
    "    min_old = [-40, 15]\n",
    "    \n",
    "    for i in range(num_proc):\n",
    "        new = []\n",
    "        for j in range(latent_dim):\n",
    "            t = (1 - (-1)) / (max_old[j] - min_old[j]) * (old_var[i][j] - max_old[j]) + 1\n",
    "            if t > 1:\n",
    "                print(\"Exceeding max in latent dim {}\".format(j))\n",
    "                t = 1.\n",
    "            elif t < -1:\n",
    "                print(\"Exceeding min in latent dim {}\".format(j))\n",
    "                t = -1\n",
    "            new.append(t)\n",
    "        rescaled_latent.append(new)\n",
    "    return rescaled_latent\n",
    "\n",
    "def rescale_posterior(num_proc, old_var, latent_dim):\n",
    "    rescaled_posterior = []\n",
    "    \n",
    "    max_old = [100, 50, 20, 20]\n",
    "    min_old = [-100, 0, 0, 0]\n",
    "    \n",
    "    for i in range(num_proc):\n",
    "        new = []\n",
    "        for j in range(latent_dim * 2):\n",
    "            t = (1 - (-1)) / (max_old[j] - min_old[j]) * (old_var[i][j] - max_old[j]) + 1\n",
    "            if t > 1:\n",
    "                print(\"Exceeding max in posterior dim {}, value {}, max {}\".format(j, old_var[i][j], max_old[j]))\n",
    "                t = 1.\n",
    "            elif t < -1:\n",
    "                print(\"Exceeding min in posterior dim {}, value {}, min {}\".format(j,  old_var[i][j], min_old[j]))\n",
    "                t = -1\n",
    "            new.append(t)\n",
    "        rescaled_posterior.append(new)\n",
    "        \n",
    "    return torch.tensor(rescaled_posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def al_augment_obs(obs, prev_latent, latent_dim, env_obs_shape, posterior, prior,rescale_obs=True):\n",
    "    num_proc = obs.shape[0]\n",
    "    new_obs = torch.empty((num_proc, 4*latent_dim))\n",
    "    \n",
    "    prior = torch.tensor([prior[i].flatten().tolist() for i in range(num_processes)])\n",
    "    \n",
    "    if(type(posterior) == list):\n",
    "        posterior = torch.tensor([posterior[i].flatten().tolist() for i in range(num_processes)])\n",
    "    else:\n",
    "        posterior[:, latent_dim:] = posterior[:, latent_dim:].exp()\n",
    "    \n",
    "    if rescale_obs:\n",
    "        #prev_latent = rescale_latent(num_proc, prev_latent, latent_dim)\n",
    "        posterior = rescale_posterior(num_proc, posterior, latent_dim)\n",
    "        prior = rescale_posterior(num_proc, prior, latent_dim)\n",
    "    \n",
    "    for i in range(num_proc): \n",
    "        #new_obs[i] = torch.cat([obs[i], torch.Tensor(prev_latent[i]),posterior[i]])\n",
    "        new_obs[i] = torch.cat([prior[i], posterior[i]])\n",
    "    \n",
    "    return new_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_like(posterior, offset_star, latent_dim):\n",
    "    if type(posterior) == list:\n",
    "        posterior = torch.tensor([posterior[i].flatten().tolist() for i in range(num_processes)])\n",
    "        posterior[:, latent_dim:] = posterior[:, latent_dim:].log()\n",
    "    \n",
    "    l = torch.sum(-(1/(2*posterior[:, latent_dim:].exp()))*(posterior[:, 0:latent_dim]-offset_star).pow(2), 1).unsqueeze(1)  \n",
    "    return l\n",
    "\n",
    "def get_best_like(vi, num_proc, num_r, tasks, prior, prev_t, latent_dim, n_samples=30):\n",
    "    # Retrieve tasks\n",
    "    num_t = num_proc // num_r\n",
    "    t = torch.empty((num_t, latent_dim))\n",
    "    p = torch.empty((num_t, 2 * latent_dim))\n",
    "    z = torch.empty((num_t, latent_dim))\n",
    "    \n",
    "    for i in range(num_t):\n",
    "        t[i] = tasks[i * num_r].clone().detach()\n",
    "        p[i] = prior[i * num_r].flatten().clone().detach()\n",
    "        z[i] = torch.tensor([prev_t[i * num_r]])\n",
    "    \n",
    "    # Retrieve informative data\n",
    "    context = torch.empty((num_t, n_samples, 2))\n",
    "    for i in range(num_t):\n",
    "        x_space = torch.arange(-100, 100, 0.01)\n",
    "        f_space = torch.exp(-((x_space - t[i][0]) ** 2) / (t[i][1] ** 2))\n",
    "        w = f_space / f_space.sum()\n",
    "        temp = torch.multinomial(w, n_samples, replacement=True)\n",
    "        x = x_space[temp]\n",
    "        y = torch.exp(-((x-t[i,0])**2)/(t[i, 1]**2))\n",
    "        context[i, :, 0] = x\n",
    "        context[i, :, 1] = y\n",
    "        \n",
    "    # Compute posterior and likelihood\n",
    "    res = vi(context=context, prior=p, prev_z=z)[1:]\n",
    "    post = torch.empty((num_t, latent_dim * 2))\n",
    "    for i in range(num_t):\n",
    "        post[i] = torch.cat([res[0][i, :], res[1][i, :]])\n",
    "    for i in range(num_t):\n",
    "        p[i][latent_dim:] = p[i][latent_dim:].log()\n",
    "    \n",
    "    best = torch.empty((num_proc, 1))\n",
    "    like_post = get_like(post, t, latent_dim)\n",
    "    for i in range(num_t):\n",
    "         for j in range(num_r):\n",
    "                best[(i*num_r)+j] = like_post[i]\n",
    "    \n",
    "    return best.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def fake_eval(actor_critic, vi, env_name, seed, num_processes, eval_log_dir, device,\n",
    "                            num_task_to_evaluate, latent_dim, env_obs_shape, max_horizon=150):\n",
    "    assert num_task_to_evaluate % num_processes == 0\n",
    "    \n",
    "    n_iter = num_task_to_evaluate // num_processes\n",
    "    reward_iter = torch.zeros(num_processes, max_horizon)\n",
    "    r_list = []\n",
    "    mse_list_at_horizon = []\n",
    "    mse_list_at_10 = []\n",
    "    mse_list_at_50 = []\n",
    "    mse_list_at_0 = []\n",
    "    \n",
    "    for _ in range(n_iter):\n",
    "        # Choose pair of init task and distribution for the next task\n",
    "        task_idx = torch.randint(low=0, high=n_tasks, size=(num_processes,))\n",
    "        new_tasks = torch.tensor([param[i] for i in task_idx])\n",
    "\n",
    "        prev_task_param = torch.randint(low=0, high=n_tasks, size=(num_processes,))\n",
    "\n",
    "        prior = [prior_dist[prev_task_param[i]].clone().detach() for i in range(num_processes)]\n",
    "        prev_task = torch.empty(num_processes, 2)\n",
    "\n",
    "        mu = [prior[i][0].clone().detach() for i in range(num_processes)]\n",
    "        var = [prior[i][1].clone().detach() for i in range(num_processes)]\n",
    "\n",
    "        offset_param = [torch.normal(mu[i], var[i]).tolist() for i in range(num_processes)]\n",
    "        offset_param = torch.tensor(offset_param)\n",
    "\n",
    "        prev_task = new_tasks - offset_param\n",
    "\n",
    "        for i in range(num_processes):\n",
    "            prior[i][0, :] = prev_task[i] + prior[i][0, :].clone().detach()\n",
    "\n",
    "        prev_task = prev_task.tolist()\n",
    "        mu = [mu[i] + torch.tensor(prev_task[i]) for i in range(num_processes)]\n",
    "\n",
    "        # Sample new task\n",
    "        envs_kwargs = [{'amplitude':1, \n",
    "                        'mean':new_tasks[i][0].item(),\n",
    "                        'std':new_tasks[i][1].item(),\n",
    "                        'noise_std':0.001,\n",
    "                        'scale_reward':False} for i in range(num_processes)]\n",
    "        \n",
    "        obs_rms_eval = ObsSmootherTemp(obs_shape=(7,))\n",
    "        \n",
    "        eval_envs = make_vec_envs_multi_task(env_name,\n",
    "                                             seed, \n",
    "                                             num_processes,\n",
    "                                             None,\n",
    "                                             log_dir,\n",
    "                                             device,\n",
    "                                             False,\n",
    "                                             envs_kwargs,\n",
    "                                             num_frame_stack=None)\n",
    "\n",
    "        obs = eval_envs.reset()\n",
    "        obs = al_augment_obs(obs, prev_task, latent_dim, env_obs_shape, prior, prior)\n",
    "        \n",
    "        obs = obs_rms_eval.step(obs)\n",
    "        \n",
    "        epi_done = []\n",
    "\n",
    "        eval_recurrent_hidden_states = torch.zeros(\n",
    "            num_processes, actor_critic.recurrent_hidden_state_size, device=device)\n",
    "        eval_masks = torch.zeros(num_processes, 1, device=device)\n",
    "        \n",
    "        t=0 \n",
    "        \n",
    "        use_prev_state = False\n",
    "        \n",
    "        while len(epi_done) < num_processes:\n",
    "            with torch.no_grad():\n",
    "                _, action, _, eval_recurrent_hidden_states = actor_critic.act(\n",
    "                    obs,\n",
    "                    eval_recurrent_hidden_states,\n",
    "                    eval_masks,\n",
    "                    deterministic=False)\n",
    "            action = torch.empty((num_processes,1))\n",
    "            \n",
    "            for idx in range(num_processes):\n",
    "                if t == 0:\n",
    "                    action[idx] = torch.normal(mu[idx][0], mu[idx][1])\n",
    "                else:\n",
    "                    action[idx] = torch.normal(posterior[idx, 0], posterior[idx, 1])\n",
    "            action = (1-(-1))/(100-(-100))*(action-100)+1\n",
    "\n",
    "            # Obser reward and next obs\n",
    "            if t == 0:\n",
    "                mse_list_at_0.append(get_mse(prior, new_tasks, 2).item())\n",
    "            \n",
    "            obs, reward, done, infos = eval_envs.step(action)\n",
    "            posterior = get_posterior(vi, action, reward, prior, prev_task, use_prev_state=use_prev_state)\n",
    "            reward = get_reward(posterior, new_tasks, latent_dim)\n",
    "            obs = al_augment_obs(obs, prev_task, latent_dim, env_obs_shape, posterior, prior)\n",
    "            obs = obs_rms_eval.step(obs)\n",
    "            use_prev_state = True\n",
    "            reward_iter[:, t] = reward.squeeze()\n",
    "            t = t+1\n",
    "            \n",
    "            if t == 10:\n",
    "                mse_list_at_10.append(get_mse(posterior, new_tasks, 2).item())\n",
    "            if t == 50:\n",
    "                mse_list_at_50.append(get_mse(posterior, new_tasks, 2).item())\n",
    "            \n",
    "            eval_masks = torch.tensor(\n",
    "                [[0.0] if done_ else [1.0] for done_ in done],\n",
    "                dtype=torch.float32,\n",
    "                device=device)\n",
    "\n",
    "            for info in infos:\n",
    "                if 'episode' in info.keys():\n",
    "                    epi_done.append(True)\n",
    "            \n",
    "        mse_list_at_horizon.append(get_mse(posterior, new_tasks, 2).item())\n",
    "        r_list.append(reward_iter)\n",
    "        eval_envs.close()\n",
    "        \n",
    "    mean_mse_0 = np.mean(mse_list_at_0)\n",
    "    mean_mse_horizon = np.mean(mse_list_at_horizon)\n",
    "    mean_mse_10 = np.mean(mse_list_at_10)\n",
    "    mean_mse_50 = np.mean(mse_list_at_50)\n",
    "    mean_r = np.mean(reduce(list.__add__, [torch.sum(elem, 1).tolist() for elem in r_list]))\n",
    "    print(\"Evaluation using {} tasks. Mean reward: {}. Mean MSE: {:.2f} || {:.2f} || {:.2f} || {:.2f}\".\n",
    "          format(n_iter*num_processes, mean_r, mean_mse_0, mean_mse_10, mean_mse_50, mean_mse_horizon))\n",
    "    return mean_r, r_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def identification_evaluate(actor_critic, vi, env_name, seed, num_processes, eval_log_dir, device,\n",
    "                            num_task_to_evaluate, latent_dim, env_obs_shape, max_horizon=150):\n",
    "    assert num_task_to_evaluate % num_processes == 0\n",
    "    \n",
    "    n_iter = num_task_to_evaluate // num_processes\n",
    "    reward_iter = torch.zeros(num_processes, max_horizon)\n",
    "    r_list = []\n",
    "    mse_list_at_horizon = []\n",
    "    mse_list_at_10 = []\n",
    "    mse_list_at_50 = []\n",
    "    mse_list_at_0 = []\n",
    "    \n",
    "    for _ in range(n_iter):\n",
    "        # Choose pair of init task and distribution for the next task\n",
    "        task_idx = torch.randint(low=0, high=n_tasks, size=(num_processes,))\n",
    "        new_tasks = torch.tensor([param[i] for i in task_idx])\n",
    "\n",
    "        prev_task_param = torch.randint(low=0, high=n_tasks, size=(num_processes,))\n",
    "\n",
    "        prior = [prior_dist[prev_task_param[i]].clone().detach() for i in range(num_processes)]\n",
    "        prev_task = torch.empty(num_processes, 2)\n",
    "\n",
    "        mu = [prior[i][0].clone().detach() for i in range(num_processes)]\n",
    "        var = [prior[i][1].clone().detach() for i in range(num_processes)]\n",
    "\n",
    "        offset_param = [torch.normal(mu[i], var[i]).tolist() for i in range(num_processes)]\n",
    "        offset_param = torch.tensor(offset_param)\n",
    "\n",
    "        prev_task = new_tasks - offset_param\n",
    "\n",
    "        for i in range(num_processes):\n",
    "            prior[i][0, :] = prev_task[i] + prior[i][0, :].clone().detach()\n",
    "\n",
    "        prev_task = prev_task.tolist()\n",
    "        mu = [mu[i] + torch.tensor(prev_task[i]) for i in range(num_processes)]\n",
    "        \n",
    "        # Sample new task\n",
    "        envs_kwargs = [{'amplitude':1, \n",
    "                        'mean':new_tasks[i][0].item(),\n",
    "                        'std':new_tasks[i][1].item(),\n",
    "                        'noise_std':0.001,\n",
    "                        'scale_reward':False} for i in range(num_processes)]\n",
    "        \n",
    "        obs_rms_eval = ObsSmootherTemp(obs_shape=(7,))\n",
    "        \n",
    "        eval_envs = make_vec_envs_multi_task(env_name,\n",
    "                                        seed, \n",
    "                                        num_processes,\n",
    "                                        None,\n",
    "                                        log_dir,\n",
    "                                        device,\n",
    "                                        False,\n",
    "                                        envs_kwargs,\n",
    "                                        num_frame_stack=None)\n",
    "\n",
    "        obs = eval_envs.reset()\n",
    "        obs = al_augment_obs(obs, prev_task, latent_dim, env_obs_shape, prior, prior)\n",
    "        \n",
    "        obs = obs_rms_eval.step(obs)\n",
    "        \n",
    "        epi_done = []\n",
    "\n",
    "        eval_recurrent_hidden_states = torch.zeros(\n",
    "            num_processes, actor_critic.recurrent_hidden_state_size, device=device)\n",
    "        eval_masks = torch.zeros(num_processes, 1, device=device)\n",
    "        \n",
    "        t=0 \n",
    "        \n",
    "        use_prev_state = False\n",
    "        while len(epi_done) < num_processes:\n",
    "            with torch.no_grad():\n",
    "                _, action, _, eval_recurrent_hidden_states = actor_critic.act(\n",
    "                    obs,\n",
    "                    eval_recurrent_hidden_states,\n",
    "                    eval_masks,\n",
    "                    deterministic=False)\n",
    "\n",
    "            # Obser reward and next obs\n",
    "            if t == 0:\n",
    "                mse_list_at_0.append(get_mse(prior, new_tasks, 2).item())\n",
    "            \n",
    "            obs, reward, done, infos = eval_envs.step(action)\n",
    "            posterior = get_posterior(vi, action, reward, prior, prev_task, use_prev_state=use_prev_state)\n",
    "            reward = get_reward(posterior, new_tasks, latent_dim)\n",
    "            obs = al_augment_obs(obs, prev_task, latent_dim, env_obs_shape, posterior, prior)\n",
    "            obs = obs_rms_eval.step(obs)\n",
    "            use_prev_state = True\n",
    "            reward_iter[:, t] = reward.squeeze()\n",
    "            t = t+1\n",
    "            \n",
    "            if t == 10:\n",
    "                mse_list_at_10.append(get_mse(posterior, new_tasks, 2).item())\n",
    "            if t == 50:\n",
    "                mse_list_at_50.append(get_mse(posterior, new_tasks, 2).item())\n",
    "            \n",
    "            eval_masks = torch.tensor(\n",
    "                [[0.0] if done_ else [1.0] for done_ in done],\n",
    "                dtype=torch.float32,\n",
    "                device=device)\n",
    "\n",
    "            for info in infos:\n",
    "                if 'episode' in info.keys():\n",
    "                    epi_done.append(True)\n",
    "            \n",
    "        mse_list_at_horizon.append(get_mse(posterior, new_tasks, 2).item())\n",
    "        r_list.append(reward_iter)\n",
    "        eval_envs.close()\n",
    "        \n",
    "    mean_mse_0 = np.mean(mse_list_at_0)\n",
    "    mean_mse_horizon = np.mean(mse_list_at_horizon)\n",
    "    mean_mse_10 = np.mean(mse_list_at_10)\n",
    "    mean_mse_50 = np.mean(mse_list_at_50)\n",
    "    mean_r = np.mean(reduce(list.__add__, [torch.sum(elem, 1).tolist() for elem in r_list]))\n",
    "    print(\"Evaluation using {} tasks. Mean reward: {}. Mean MSE: {:.2f} || {:.2f} || {:.2f} || {:.2f}\".\n",
    "          format(n_iter*num_processes, mean_r, mean_mse_0, mean_mse_10, mean_mse_50, mean_mse_horizon))\n",
    "    return mean_r, r_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation using 128 tasks. Mean reward: -393.7668699771166. Mean MSE: 9.11 || 1.93 || 1.04 || 0.78\n",
      "Evaluation using 128 tasks. Mean reward: -700.0639516115189. Mean MSE: 9.39 || 2.54 || 1.15 || 0.84\n",
      "Evaluation using 128 tasks. Mean reward: -444.35441640019417. Mean MSE: 9.44 || 2.40 || 1.12 || 0.80\n",
      "Evaluation using 128 tasks. Mean reward: -457.9572494328022. Mean MSE: 9.45 || 2.05 || 1.01 || 0.79\n",
      "Evaluation using 128 tasks. Mean reward: -385.9866738319397. Mean MSE: 11.38 || 2.51 || 1.11 || 0.85\n",
      "Evaluation using 128 tasks. Mean reward: -308.4610213637352. Mean MSE: 7.18 || 1.37 || 0.71 || 0.56\n",
      "Evaluation using 128 tasks. Mean reward: -346.05783146619797. Mean MSE: 7.81 || 1.62 || 0.83 || 0.65\n",
      "Evaluation using 128 tasks. Mean reward: -484.8431434035301. Mean MSE: 9.18 || 2.09 || 0.94 || 0.73\n",
      "Evaluation using 128 tasks. Mean reward: -482.76983815431595. Mean MSE: 6.65 || 1.42 || 0.74 || 0.58\n",
      "Evaluation using 128 tasks. Mean reward: -332.22653982043266. Mean MSE: 6.46 || 1.57 || 0.75 || 0.57\n",
      "Evaluation using 128 tasks. Mean reward: -496.2349759340286. Mean MSE: 11.29 || 2.21 || 1.12 || 0.86\n",
      "Evaluation using 128 tasks. Mean reward: -334.63554787635803. Mean MSE: 8.18 || 1.74 || 0.79 || 0.62\n",
      "Evaluation using 128 tasks. Mean reward: -349.9935140013695. Mean MSE: 9.38 || 1.99 || 0.89 || 0.69\n",
      "Evaluation using 128 tasks. Mean reward: -300.2838845252991. Mean MSE: 8.88 || 1.88 || 0.93 || 0.72\n",
      "Evaluation using 128 tasks. Mean reward: -465.90244340896606. Mean MSE: 8.27 || 1.81 || 0.85 || 0.67\n",
      "Evaluation using 128 tasks. Mean reward: -430.92657923698425. Mean MSE: 10.05 || 2.06 || 0.94 || 0.72\n",
      "Evaluation using 128 tasks. Mean reward: -440.0964888930321. Mean MSE: 8.71 || 2.06 || 0.95 || 0.72\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-20e8254a05ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0meval_interval\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0meval_interval\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         e = identification_evaluate(actor_critic, inference_net,env_name, seed, num_processes, \".\", device,\n\u001b[1;32m--> 164\u001b[1;33m                                     128, latent_dim, env_obs_shape)\n\u001b[0m\u001b[0;32m    165\u001b[0m         \u001b[0meval_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-4ab185c7c286>\u001b[0m in \u001b[0;36midentification_evaluate\u001b[1;34m(actor_critic, vi, env_name, seed, num_processes, eval_log_dir, device, num_task_to_evaluate, latent_dim, env_obs_shape, max_horizon)\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[0mposterior\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_posterior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprev_task\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_prev_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_prev_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_reward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposterior\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_tasks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mal_augment_obs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprev_task\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_obs_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposterior\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m             \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobs_rms_eval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[0muse_prev_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-e490ba2cfbd1>\u001b[0m in \u001b[0;36mal_augment_obs\u001b[1;34m(obs, prev_latent, latent_dim, env_obs_shape, posterior, prior, rescale_obs)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_proc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m#new_obs[i] = torch.cat([obs[i], torch.Tensor(prev_latent[i]),posterior[i]])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mnew_obs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprior\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposterior\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_obs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "meta_training_iter = 100000\n",
    "num_update_per_meta_training_iter = 1\n",
    "num_task_to_evaluate = num_processes\n",
    "\n",
    "latent_dim = 2\n",
    "env_obs_shape = 1\n",
    "obs_dim = 4\n",
    "\n",
    "num_processes  = 32\n",
    "log_interval = 5\n",
    "eval_interval = 1\n",
    "eval_list = []\n",
    "\n",
    "variational_model = inference_net\n",
    "\n",
    "for k in range(meta_training_iter):   \n",
    "    # Choose pair of init task and distribution for the next task\n",
    "    task_idx = torch.randint(low=0, high=n_tasks, size=(num_processes,))\n",
    "    new_tasks = torch.tensor([param[i] for i in task_idx])\n",
    "\n",
    "    prev_task_param = torch.randint(low=0, high=n_tasks, size=(num_processes,))\n",
    "\n",
    "    prior = [prior_dist[prev_task_param[i]].clone().detach() for i in range(num_processes)]\n",
    "    prev_task = torch.empty(num_processes, 2)\n",
    "\n",
    "    mu = [prior[i][0].clone().detach() for i in range(num_processes)]\n",
    "    var = [prior[i][1].clone().detach() for i in range(num_processes)]\n",
    "\n",
    "    offset_param = [torch.normal(mu[i], var[i]).tolist() for i in range(num_processes)]\n",
    "    offset_param = torch.tensor(offset_param)\n",
    "\n",
    "    prev_task = new_tasks - offset_param\n",
    "\n",
    "    for i in range(num_processes):\n",
    "        prior[i][0, :] = prev_task[i] + prior[i][0, :].clone().detach()\n",
    "\n",
    "    prev_task = prev_task.tolist()\n",
    "    mu = [mu[i] + torch.tensor(prev_task[i]) for i in range(num_processes)]\n",
    "    \n",
    "    # Sample new task\n",
    "    envs_kwargs = [{'amplitude':1, \n",
    "                    'mean':new_tasks[i][0].item(),\n",
    "                    'std':new_tasks[i][1].item(),\n",
    "                    'noise_std':0.001,\n",
    "                    'scale_reward':False} for i in range(num_processes)]\n",
    "    \n",
    "    envs = make_vec_envs_multi_task(env_name,\n",
    "                                    seed, \n",
    "                                    num_processes,\n",
    "                                    None,\n",
    "                                    log_dir,\n",
    "                                    device,\n",
    "                                    False,\n",
    "                                    envs_kwargs,\n",
    "                                    num_frame_stack=None)\n",
    "    \n",
    "    obs = envs.reset()\n",
    "    obs = al_augment_obs(obs, prev_task, latent_dim, env_obs_shape, prior, prior)\n",
    "    \n",
    "    rollouts = RolloutStorage(num_steps, num_processes,\n",
    "                              obs_shape, action_space,\n",
    "                              actor_critic.recurrent_hidden_state_size)\n",
    "    \n",
    "    rollouts.obs[0].copy_(obs)\n",
    "    rollouts.to(device)\n",
    "    \n",
    "    use_prev_state = False\n",
    "    \n",
    "    rms = FakeRewardSmoother()\n",
    "    # rms = AdvancedRewardSmoother(num_processes, num_replicas, gamma=gamma)\n",
    "    # rms = RewardSmoother(num_envs=num_processes, cliprew=10, gamma=gamma)\n",
    "    obs_rms = ObsSmootherTemp(obs_shape=(7,))\n",
    "    obs = obs_rms.step(obs)\n",
    "    \n",
    "    for _ in range(num_update_per_meta_training_iter):\n",
    "        # Collect observations and store them into the storage\n",
    "        for step in range(num_steps):\n",
    "            # Sample actions\n",
    "            with torch.no_grad():\n",
    "                value, action, action_log_prob, recurrent_hidden_states = actor_critic.act(\n",
    "                    rollouts.obs[step], rollouts.recurrent_hidden_states[step],\n",
    "                    rollouts.masks[step])\n",
    "\n",
    "            # Obser reward and next obs\n",
    "            obs, reward, done, infos = envs.step(action)\n",
    "            posterior = get_posterior(variational_model, action, reward, prior, prev_task, use_prev_state=use_prev_state)\n",
    "            use_prev_state = True\n",
    "            \n",
    "            reward_prev = get_reward(posterior, new_tasks, latent_dim)\n",
    "            reward = rms.step(reward_prev, done)\n",
    "            obs = al_augment_obs(obs, prev_task, latent_dim, env_obs_shape, posterior, prior)\n",
    "            obs = obs_rms.step(obs)\n",
    "            \n",
    "            # If done then clean the history of observations.\n",
    "            if done.any():\n",
    "                use_prev_state = False\n",
    "            masks = torch.FloatTensor(\n",
    "                [[0.0] if done_ else [1.0] for done_ in done])\n",
    "            bad_masks = torch.FloatTensor(\n",
    "                [[0.0] if 'bad_transition' in info.keys() else [1.0]\n",
    "                 for info in infos])\n",
    "            \n",
    "            rollouts.insert(obs, recurrent_hidden_states, action,\n",
    "                            action_log_prob, value, reward, masks, bad_masks)\n",
    "     \n",
    "        with torch.no_grad():\n",
    "            next_value = actor_critic.get_value(\n",
    "                rollouts.obs[-1], rollouts.recurrent_hidden_states[-1],\n",
    "                rollouts.masks[-1]).detach()\n",
    "\n",
    "        rollouts.compute_returns(next_value, use_gae, gamma,\n",
    "                                 gae_lambda, use_proper_time_limits)\n",
    "\n",
    "        value_loss, action_loss, dist_entropy = agent.update(rollouts)\n",
    "\n",
    "        rollouts.after_update()\n",
    "        \n",
    "    rms.reset()\n",
    "    eval_interval = 10\n",
    "    if (eval_interval is not None and k % eval_interval == 0 and k>1):\n",
    "        e = identification_evaluate(actor_critic, inference_net,env_name, seed, num_processes, \".\", device,\n",
    "                                    128, latent_dim, env_obs_shape)\n",
    "        eval_list.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeRewardSmoother:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def step(self, reward, done):\n",
    "        return reward\n",
    "\n",
    "    def reset(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baselines.common.running_mean_std import RunningMeanStd\n",
    "\n",
    "class ObsSmootherTemp:\n",
    "    def __init__(self, obs_shape, clipob=10., epsilon=1e-8):\n",
    "        self.clipob = clipob\n",
    "        self.epsilon = epsilon\n",
    "        self.ob_rms = RunningMeanStd(shape=obs_shape)\n",
    "\n",
    "    def step(self, obs):\n",
    "        return obs\n",
    "        #obs = obs.numpy()\n",
    "        #self.ob_rms.update(obs)\n",
    "        #obs = np.clip((obs - self.ob_rms.mean) / np.sqrt(self.ob_rms.var + self.epsilon), -self.clipob, self.clipob)\n",
    "        #return torch.tensor(obs, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "l = [eval_list[i][0] for i in range(len(eval_list))]\n",
    "\n",
    "y = np.array(l)\n",
    "x = np.arange(len(y))\n",
    "yhat = savgol_filter(y, 51, 3) \n",
    "\n",
    "plt.plot(x, yhat, color='red')\n",
    "#plt.plot(l)\n",
    "plt.show()\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posterior_debug(variational_model, action, reward, prior, prev_latent_space, use_prev_state=True):\n",
    "    \"\"\"\n",
    "    Feed the variational model with the actual reward to identifiy the latent space\n",
    "    and get the current reward using the posterior and the true task\n",
    "    \"\"\"\n",
    "    #prev_latent_space = torch.tensor(prev_latent_space)\n",
    "    num_proc=1\n",
    "    flatten_prior = torch.tensor([prior.flatten().tolist() for i in range(num_proc)])[0]\n",
    "    \n",
    "    # To feed VI, i need (n_batch, 1, 2)\n",
    "    context = torch.empty(num_proc, 1, 2)\n",
    "    for i in range(num_proc):\n",
    "        context[i] = torch.cat([torch.tensor([action.item()]), torch.tensor([reward.item()])])\n",
    "    \n",
    "    posterior = variational_model(context=context, prev_z=prev_latent_space, prior=flatten_prior, use_prev_state=use_prev_state)\n",
    "    posterior = posterior[1:]\n",
    "    posterior = torch.cat([posterior[0].detach(), posterior[1].detach()], 1)\n",
    "    return posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_net = torch.load(\"inference_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior loss 7.340719699859619\n",
      "Reward -376.53363037109375\n",
      "Final 1.5112009833101183\n",
      "\n",
      "\n",
      "Prior loss 6.931302070617676\n",
      "Reward -475.42034912109375\n",
      "Final 2.13309088681126\n",
      "\n",
      "\n",
      "Prior loss 8.667194366455078\n",
      "Reward -460.37213134765625\n",
      "Final 2.376362554728985\n",
      "\n",
      "\n",
      "Prior loss 11.478805541992188\n",
      "Reward -478.16851806640625\n",
      "Final 2.4513191510923207\n",
      "\n",
      "\n",
      "Prior loss 8.548314094543457\n",
      "Reward -650.4971923828125\n",
      "Final 3.062259681057185\n",
      "\n",
      "\n",
      "Prior loss 13.514175415039062\n",
      "Reward -1253.782958984375\n",
      "Final 4.601800855831243\n",
      "\n",
      "\n",
      "Prior loss 6.889156818389893\n",
      "Reward -434.2346496582031\n",
      "Final 1.8488404473755509\n",
      "\n",
      "\n",
      "Prior loss 10.923748970031738\n",
      "Reward -527.6890258789062\n",
      "Final 2.018138045212254\n",
      "\n",
      "\n",
      "Prior loss 6.158041954040527\n",
      "Reward -437.3888244628906\n",
      "Final 1.898487947655667\n",
      "\n",
      "\n",
      "Prior loss 6.220515251159668\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-234-9cc5c0b076d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0muse_prev_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0mposterior\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_posterior_debug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minference_net\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprev_task\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_prev_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_prev_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[0mfinal_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposterior\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_tasks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-027d36280ae9>\u001b[0m in \u001b[0;36mget_posterior_debug\u001b[1;34m(variational_model, action, reward, prior, prev_latent_space, use_prev_state)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mcontext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mposterior\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvariational_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprev_z\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprev_latent_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflatten_prior\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_prev_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_prev_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mposterior\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mposterior\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mposterior\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mposterior\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposterior\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Riccardo\\Anaconda3\\envs\\sequential-transfer-rl\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-58004c2025ea>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, context, prev_z, prior, use_prev_state)\u001b[0m\n\u001b[0;32m    134\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprev_z\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_prev_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreparameterize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-58004c2025ea>\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, context, prev_z, prior, use_prev_state)\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;31m# Data preparation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mprev_z\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprev_z\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[0mprev_z\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprev_z\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[0moriginal_prior\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprior\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for _ in range(30):\n",
    "    prev_task_idx = torch.randint(low=0, high=n_tasks, size=(num_processes,))\n",
    "    prev_task = [param[prev_task_idx[i]] for i in range(num_processes,)]\n",
    "\n",
    "    prior_idx = torch.randint(low=0, high=n_tasks, size=(num_processes,))\n",
    "    prior = [prior_dist[prior_idx[i]].clone().detach() for i in range(num_processes)]\n",
    "\n",
    "    # Sample current task from the prior \n",
    "    mu = [prior[i][0].clone().detach() for i in range(num_processes)]\n",
    "    var = [prior[i][1].clone().detach() for i in range(num_processes)]\n",
    "\n",
    "    offset_param = [torch.normal(mu[i], var[i]).tolist() for i in range(num_processes)]\n",
    "    offset_param = torch.tensor(offset_param)\n",
    "\n",
    "    # Modify the prior\n",
    "    for i in range(num_processes):\n",
    "        prior[i][0, :] = prior[i][0, :] + torch.tensor(prev_task[i])\n",
    "\n",
    "    mu = [mu[i] + torch.tensor(prev_task[i]) for i in range(num_processes)]\n",
    "    new_tasks = offset_param + torch.tensor(prev_task)\n",
    "\n",
    "    t = torch.tensor([prior[i].flatten().tolist() for i in range(32)])\n",
    "    print(\"Prior loss {}\".format(F.mse_loss(t[:, 0:2], new_tasks).item()))\n",
    "    \n",
    "    like_list = []\n",
    "    final_loss = []\n",
    "    for task in range(num_processes):\n",
    "        curr_like = 0\n",
    "        x = torch.normal(mean=torch.tensor([prior[task][0][0]]), std=torch.tensor([prior[task][0][1]]))\n",
    "        y = torch.exp(-((x-new_tasks[task,0])**2)/(new_tasks[task, 1]**2))\n",
    "        for s in range(150):\n",
    "            use_prev_state = True if s > 0 else False\n",
    "            posterior = get_posterior_debug(inference_net, x, y, prior[task], torch.tensor(prev_task[task]), use_prev_state=use_prev_state)\n",
    "            if s == 10:\n",
    "                final_loss.append(F.mse_loss(posterior[0][0:2], new_tasks[task]).item())\n",
    "            l = torch.sum(-(1/(2*posterior[0, latent_dim:].exp()))*(posterior[0, 0:latent_dim]-new_tasks[task]).pow(2)) \n",
    "            curr_like += l\n",
    "            x = torch.normal(mean=torch.tensor([posterior[0][0]]), std=torch.tensor([posterior[0][1]]))\n",
    "            y = torch.exp(-((x-new_tasks[task,0])**2)/(new_tasks[task, 1]**2))\n",
    "        like_list.append(curr_like)\n",
    "    print(\"Reward {}\".format(np.mean(like_list)))\n",
    "    print(\"Final {}\".format(np.mean(final_loss)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0.])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset_param + prev_task[0] - target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg sum reward -569.3123779296875\n",
      "Avg init loss 10.58705666474998\n",
      "Avg fin loss 2.459076871862635\n",
      "\n",
      "Avg sum reward -561.9092407226562\n",
      "Avg init loss 11.63562855613418\n",
      "Avg fin loss 2.5571884110104293\n",
      "\n",
      "Avg sum reward -364.62286376953125\n",
      "Avg init loss 4.071773024450522\n",
      "Avg fin loss 1.5416721549117938\n",
      "\n",
      "Avg sum reward -631.57421875\n",
      "Avg init loss 7.739219904877245\n",
      "Avg fin loss 2.776363192660938\n",
      "\n",
      "Avg sum reward -372.3067932128906\n",
      "Avg init loss 7.485127763458877\n",
      "Avg fin loss 1.6082890037214383\n",
      "\n",
      "Avg sum reward -300.08135986328125\n",
      "Avg init loss 6.846096712863073\n",
      "Avg fin loss 1.6230857156333514\n",
      "\n",
      "Avg sum reward -296.5817565917969\n",
      "Avg init loss 6.846026549115777\n",
      "Avg fin loss 1.4567715419107117\n",
      "\n",
      "Avg sum reward -481.67962646484375\n",
      "Avg init loss 7.864618497202173\n",
      "Avg fin loss 2.4334596606495325\n",
      "\n",
      "Avg sum reward -315.10009765625\n",
      "Avg init loss 4.9444071072211955\n",
      "Avg fin loss 1.2514138966798782\n",
      "\n",
      "Avg sum reward -728.0061645507812\n",
      "Avg init loss 9.433902491815388\n",
      "Avg fin loss 2.8608156066620722\n",
      "\n",
      "Avg sum reward -589.7879638671875\n",
      "Avg init loss 7.3124838506337255\n",
      "Avg fin loss 2.614748807391152\n",
      "\n",
      "Avg sum reward -643.8138427734375\n",
      "Avg init loss 4.613265005667927\n",
      "Avg fin loss 2.846547570909024\n",
      "\n",
      "Avg sum reward -599.7072143554688\n",
      "Avg init loss 7.632792572490871\n",
      "Avg fin loss 2.786106413928792\n",
      "\n",
      "Avg sum reward -488.05487060546875\n",
      "Avg init loss 9.779660417698324\n",
      "Avg fin loss 2.226908935503161\n",
      "\n",
      "Avg sum reward -752.1055297851562\n",
      "Avg init loss 6.31860224402044\n",
      "Avg fin loss 3.049114218039904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(15):\n",
    "    latent_dim = 2\n",
    "    init_loss = []\n",
    "    sum_reward = []\n",
    "    final_loss = []\n",
    "    \n",
    "    for _ in range(32):\n",
    "        # Choose pair of init task and distribution for the next task\n",
    "        task_idx = torch.randint(low=0, high=n_tasks, size=(10,))\n",
    "        prev_task = torch.tensor([param[i] for i in task_idx])\n",
    "\n",
    "        prior_idx = torch.randint(low=0, high=n_tasks, size=(10,))\n",
    "        \n",
    "        prior = torch.empty(10, 4)\n",
    "        for t_idx in range(10):\n",
    "            prior[t_idx] = prior_dist[prior_idx[t_idx]].reshape(1, 4).squeeze(0)\n",
    "        \n",
    "        target = torch.empty(10, 2)\n",
    "        \n",
    "        mu = prior_dist[prior_idx[0]][0]\n",
    "        var = prior_dist[prior_idx[0]][1]\n",
    "        offset_param = torch.normal(mu, var)\n",
    "        target[0] = prev_task[0] + offset_param \n",
    "        prior[0][0:2] = prev_task[0] + prior[0][0:2] \n",
    "        \n",
    "        # Generate data 125\n",
    "        x_space = torch.arange(-100, 100, 0.01)\n",
    "        f_space = torch.exp(-((x_space - prior[0][0]) ** 2) / (prior[0][1] ** 2))\n",
    "        w = f_space / f_space.sum()\n",
    "        temp = torch.multinomial(w, 1, replacement=True)\n",
    "        x = x_space[temp]\n",
    "        y = torch.exp(-((x-target[0,0])**2)/(target[0, 1]**2))\n",
    "\n",
    "        loss_list = []\n",
    "        like_list = []\n",
    "        loss_list.append(F.mse_loss(prior[0][0:2], target[0]).item())\n",
    "        for s in range(150):\n",
    "            use_prev_state = True if s > 0 else False\n",
    "            posterior = get_posterior_debug(inference_net, x, y, prior[0], prev_task[0], use_prev_state=use_prev_state)\n",
    "            loss_list.append(F.mse_loss(posterior[0][0:2], target[0]).item())\n",
    "            l = torch.sum(-(1/(2*posterior[0, latent_dim:].exp()))*(posterior[0, 0:latent_dim]-target[0]).pow(2)) \n",
    "            like_list.append(l)\n",
    "            x = torch.normal(mean=torch.tensor([posterior[0][0]]), std=torch.tensor([posterior[0][1]]))\n",
    "            y = torch.exp(-((x-target[0,0])**2)/(target[0, 1]**2))\n",
    "        \n",
    "        sum_reward.append(np.sum(like_list))\n",
    "        init_loss.append(loss_list[0])\n",
    "        final_loss.append(loss_list[10])\n",
    "    print(\"Avg sum reward {}\".format(np.mean(sum_reward)))\n",
    "    print(\"Avg init loss {}\".format(np.mean(init_loss)))\n",
    "    print(\"Avg fin loss {}\\n\".format(np.mean(final_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg sum reward -271.3575134277344\n",
      "Avg init loss 7.255287999054417\n",
      "Avg fin loss 1.159103069046978\n",
      "\n",
      "\n",
      "Avg sum reward -449.65643310546875\n",
      "Avg init loss 11.527373017277569\n",
      "Avg fin loss 2.506708252360113\n",
      "\n",
      "\n",
      "Avg sum reward -280.9597473144531\n",
      "Avg init loss 8.451346851477865\n",
      "Avg fin loss 1.4670912814326584\n",
      "\n",
      "\n",
      "Avg sum reward -386.91278076171875\n",
      "Avg init loss 7.31937725370517\n",
      "Avg fin loss 1.8360265843803063\n",
      "\n",
      "\n",
      "Avg sum reward -420.3238525390625\n",
      "Avg init loss 9.174345712177455\n",
      "Avg fin loss 2.0776532328454778\n",
      "\n",
      "\n",
      "Avg sum reward -473.8013000488281\n",
      "Avg init loss 10.1648808530299\n",
      "Avg fin loss 2.0735176417510957\n",
      "\n",
      "\n",
      "Avg sum reward -314.5928955078125\n",
      "Avg init loss 6.372849454637617\n",
      "Avg fin loss 1.3896513283834793\n",
      "\n",
      "\n",
      "Avg sum reward -450.01715087890625\n",
      "Avg init loss 12.170947121456265\n",
      "Avg fin loss 1.9375369109911844\n",
      "\n",
      "\n",
      "Avg sum reward -378.7605895996094\n",
      "Avg init loss 7.8079616776667535\n",
      "Avg fin loss 1.8007244491600432\n",
      "\n",
      "\n",
      "Avg sum reward -419.80694580078125\n",
      "Avg init loss 9.695794148836285\n",
      "Avg fin loss 1.9498640805541072\n",
      "\n",
      "\n",
      "Avg sum reward -429.641845703125\n",
      "Avg init loss 9.63905624684412\n",
      "Avg fin loss 1.7862823533068877\n",
      "\n",
      "\n",
      "Avg sum reward -329.9259948730469\n",
      "Avg init loss 11.037760961451568\n",
      "Avg fin loss 1.2723636237788014\n",
      "\n",
      "\n",
      "Avg sum reward -402.6580810546875\n",
      "Avg init loss 7.659345874126302\n",
      "Avg fin loss 1.8394613356213085\n",
      "\n",
      "\n",
      "Avg sum reward -424.290283203125\n",
      "Avg init loss 9.616007507604081\n",
      "Avg fin loss 1.6726029288620339\n",
      "\n",
      "\n",
      "Avg sum reward -351.1444091796875\n",
      "Avg init loss 5.11762926611118\n",
      "Avg fin loss 1.3663659750855004\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(15):\n",
    "    init_loss = []\n",
    "    sum_reward = []\n",
    "    final_loss = []\n",
    "    \n",
    "    for _ in range(32):\n",
    "        # Choose pair of init task and distribution for the next task\n",
    "        task_idx = torch.randint(low=0, high=n_tasks, size=(10,))\n",
    "        target = torch.tensor([param[i] for i in task_idx])\n",
    "\n",
    "        prev_task_param = torch.randint(low=0, high=n_tasks, size=(10,))\n",
    "\n",
    "        prior = torch.empty(10, 4)\n",
    "        for t_idx in range(10):\n",
    "            prior[t_idx] = prior_dist[prev_task_param[t_idx]].reshape(1, 4).squeeze(0)\n",
    "        \n",
    "\n",
    "        prev_task = torch.empty(10, 2)\n",
    "        mu = prior_dist[prev_task_param[0]][0]\n",
    "        var = prior_dist[prev_task_param[0]][1]\n",
    "\n",
    "        offset_param = torch.normal(mu, var)\n",
    "\n",
    "        prev_task[0] = target[0] - offset_param \n",
    "        prior[0][0:2] = prev_task[0] + prior[0][0:2] \n",
    "\n",
    "        # Generate data 125\n",
    "        x_space = torch.arange(-100, 100, 0.01)\n",
    "        #f_space = torch.exp(-((x_space - prior[0][0]) ** 2) / (prior[0][1] ** 2))\n",
    "        #w = f_space / f_space.sum()\n",
    "        #temp = torch.multinomial(w, 1, replacement=True)\n",
    "        temp = torch.randint(low=0, high=x_space.shape[0],size=(1,))\n",
    "        x = x_space[temp]\n",
    "        y = torch.exp(-((x-target[0,0])**2)/(target[0, 1]**2))\n",
    "\n",
    "        loss_list = []\n",
    "        like_list = []\n",
    "        loss_list.append(F.mse_loss(prior[0][0:2], target[0]).item())\n",
    "        for s in range(150):\n",
    "            use_prev_state = True if s > 0 else False\n",
    "            posterior = get_posterior_debug(inference_net, x, y, prior[0], prev_task[0], use_prev_state=use_prev_state)\n",
    "            loss_list.append(F.mse_loss(posterior[0][0:2], target[0]).item())\n",
    "            l = torch.sum(-(1/(2*posterior[0, latent_dim:].exp()))*(posterior[0, 0:latent_dim]-target[0]).pow(2)) \n",
    "            like_list.append(l)\n",
    "            x = torch.normal(mean=torch.tensor([posterior[0][0]]), std=torch.tensor([posterior[0][1]]))\n",
    "            y = torch.exp(-((x-target[0,0])**2)/(target[0, 1]**2))\n",
    "            #temp = torch.randint(low=0, high=x_space.shape[0],size=(1,))\n",
    "            #x = x_space[temp]\n",
    "            y = torch.exp(-((x-target[0,0])**2)/(target[0, 1]**2))\n",
    "\n",
    "        sum_reward.append(np.sum(like_list))\n",
    "        init_loss.append(loss_list[0])\n",
    "        final_loss.append(loss_list[10])\n",
    "    print(\"Avg sum reward {}\".format(np.mean(sum_reward)))\n",
    "    print(\"Avg init loss {}\".format(np.mean(init_loss)))\n",
    "    print(\"Avg fin loss {}\".format(np.mean(final_loss)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg init loss 7.1185324266552925\n",
      "Avg fin loss 2.1012035674694927\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_loss = []\n",
    "final_loss = []\n",
    "num_processes=4\n",
    "for i in range(50):\n",
    "    # Sample previous task and prior distribution on the next task\n",
    "    prev_task_idx = torch.randint(low=0, high=n_tasks, size=(num_processes,))\n",
    "    prev_task = [param[prev_task_idx[i]] for i in range(num_processes,)]\n",
    "\n",
    "    prior_idx = torch.randint(low=0, high=n_tasks, size=(num_processes,))\n",
    "    prior = [prior_dist[prior_idx[i]].clone().detach() for i in range(num_processes)]\n",
    "\n",
    "    # Sample current task from the prior \n",
    "    mu = [prior[i][0].clone().detach() for i in range(num_processes)]\n",
    "    var = [prior[i][1].clone().detach() for i in range(num_processes)]\n",
    "\n",
    "    offset_param = [torch.normal(mu[i], var[i]).tolist() for i in range(num_processes)]\n",
    "    offset_param = torch.tensor(offset_param)\n",
    "\n",
    "    # Modify the prior\n",
    "    for i in range(num_processes):\n",
    "        prior[i][0, :] = prior[i][0, :] + torch.tensor(prev_task[i])\n",
    "\n",
    "    mu = [mu[i] + torch.tensor(prev_task[i]) for i in range(num_processes)]\n",
    "    new_tasks = offset_param + torch.tensor(prev_task)    \n",
    "\n",
    "    # Generate data 125\n",
    "    x_space = torch.arange(-100, 100, 0.01)\n",
    "    f_space = torch.exp(-((x_space - new_tasks[0][0]) ** 2) / (new_tasks[0][1] ** 2))\n",
    "    w = f_space / f_space.sum()\n",
    "    temp = torch.multinomial(w, 1000, replacement=True)\n",
    "    #temp = torch.randint(low=0, high=x_space.shape[0],size=(101,))\n",
    "    x = x_space[temp]\n",
    "    y = torch.exp(-((x-new_tasks[0,0])**2)/(new_tasks[0, 1]**2))\n",
    "\n",
    "    loss_list = []\n",
    "    loss_list.append(F.mse_loss(prior[0][0, 0:2], new_tasks[0]).item())\n",
    "    for i in range(101):\n",
    "        use_prev_state = True if i > 0 else False\n",
    "        posterior = get_posterior_debug(inference_net, x[i], y[i], prior[0], torch.tensor(prev_task[0]), use_prev_state=use_prev_state)\n",
    "        loss_list.append(F.mse_loss(posterior[0][0:2], new_tasks[0]).item())\n",
    "        if i == 20 and loss_list[-1] > 20:\n",
    "            print(offset_param[0])\n",
    "        #if i == 100 or i == 1:\n",
    "        #    print(\"Posterior var {}\".format(posterior[0][2:].exp()))\n",
    "\n",
    "    plt.plot(loss_list)\n",
    "    #print(loss_list[0])\n",
    "    #print(loss_list[-1])\n",
    "    init_loss.append(loss_list[0])\n",
    "    final_loss.append(loss_list[10])\n",
    "print(\"Avg init loss {}\".format(np.mean(init_loss)))\n",
    "print(\"Avg fin loss {}\".format(np.mean(final_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(actor_critic, \"identification_policy\")\n",
    "torch.save(actor_critic_multi_task, \"multi_task_policy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection meta-policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we want to meta-train a policy to choose when we should explore and start exploring.\n",
    "Ideas:\n",
    "- It should a policy that output 1 and 0? How should we train something like that? What should the loss be? Somehow it would be related to the per-episode reward... However, the best the we can do somehow depends on the all the task evolution... but we do not know that...\n",
    "\n",
    "Baselines:\n",
    "- POSTERIOR and MULTI-TASK: A meta-optimal policy that selects the action on the basis of the posterior. This is really easy to evaluate: just take multi-task policy and use VAE\n",
    "- ORACLE: a policy who knows the exact task parameters at each timestep\n",
    "- FIXED-IDENTIFICATION: stop identifying after a fixed number of samples. We can study for instance how many samples do we need to go beyond a certain MSE error. However, this somehow depends on the prior. The naive thing is a fixed number, however, we could do better: the number to get below the MSE error depend on the prior distribution... How can we train something like that? It should be a classification network that given the posterior, the prior and the number of query of the policy, outputs 1 if we should or not stop the search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_net = InferenceNetwork2(n_in=8,z_dim=2)\n",
    "optimizer = torch.optim.Adam(inference_net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose pair of init task and distribution for the next task\n",
    "task_idx = torch.randint(low=0, high=n_tasks, size=(num_processes,))\n",
    "new_tasks = torch.tensor([param[i] for i in task_idx])\n",
    "\n",
    "prev_task_param = torch.randint(low=0, high=n_tasks, size=(num_processes,))\n",
    "\n",
    "prior = [prior_dist[prev_task_param[i]].clone().detach() for i in range(num_processes)]\n",
    "prev_task = torch.empty(num_processes, 2)\n",
    "\n",
    "mu = [prior[i][0].clone().detach() for i in range(num_processes)]\n",
    "var = [prior[i][1].clone().detach() for i in range(num_processes)]\n",
    "\n",
    "offset_param = [torch.normal(mu[i], var[i]).tolist() for i in range(num_processes)]\n",
    "offset_param = torch.tensor(offset_param)\n",
    "\n",
    "prev_task = new_tasks - offset_param\n",
    "\n",
    "for i in range(num_processes):\n",
    "    prior[i][0, :] = prev_task[i] + prior[i][0, :].clone().detach()\n",
    "\n",
    "prev_task = prev_task.tolist()\n",
    "mu = [mu[i] + torch.tensor(prev_task[i]) for i in range(num_processes)]\n",
    "\n",
    "# Sample new task\n",
    "envs_kwargs = [{'amplitude':1, \n",
    "                'mean':new_tasks[i][0].item(),\n",
    "                'std':new_tasks[i][1].item(),\n",
    "                'noise_std':0.001,\n",
    "                'scale_reward':False} for i in range(num_processes)]\n",
    "\n",
    "envs = make_vec_envs_multi_task(env_name,\n",
    "                                seed, \n",
    "                                num_processes,\n",
    "                                None,\n",
    "                                log_dir,\n",
    "                                device,\n",
    "                                False,\n",
    "                                envs_kwargs,\n",
    "                                num_frame_stack=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_seq_len = 1\n",
    "max_seq_len = 150\n",
    "num_vae_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batch = 32\n",
    "prior = torch.empty(n_batch, 4)\n",
    "mu_prior = torch.empty(n_batch, 2)\n",
    "logvar_prior = torch.empty(n_batch, 2)\n",
    "for t_idx in range(n_batch):\n",
    "    prior[t_idx] = prior_dist[prev_task_param[t_idx]].reshape(1, 4).squeeze(0).clone().detach()\n",
    "    mu_prior[t_idx] = prior_dist[prev_task_param[t_idx]][0].clone().detach()\n",
    "    logvar_prior[t_idx] = prior_dist[prev_task_param[t_idx]][1].clone().detach().log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [32 x 1], m2: [8 x 32] at C:\\w\\1\\s\\tmp_conda_3.7_100118\\conda\\conda-bld\\pytorch_1579082551706\\work\\aten\\src\\TH/generic/THTensorMath.cpp:136",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-137-10192d990717>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m                         \u001b[0mrecurrent_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                         \u001b[0mmasks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                         deterministic=True)\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m# Creating context to be fed to the network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\non-stationary-meta\\ppo_a2c\\model.py\u001b[0m in \u001b[0;36mact\u001b[1;34m(self, inputs, rnn_hxs, masks, deterministic)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnn_hxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactor_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnn_hxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnn_hxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m         \u001b[0mdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactor_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Riccardo\\Anaconda3\\envs\\sequential-transfer-rl\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\non-stationary-meta\\ppo_a2c\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, rnn_hxs, masks)\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnn_hxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_gru\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnn_hxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m         \u001b[0mhidden_critic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m         \u001b[0mhidden_actor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Riccardo\\Anaconda3\\envs\\sequential-transfer-rl\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Riccardo\\Anaconda3\\envs\\sequential-transfer-rl\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Riccardo\\Anaconda3\\envs\\sequential-transfer-rl\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Riccardo\\Anaconda3\\envs\\sequential-transfer-rl\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Riccardo\\Anaconda3\\envs\\sequential-transfer-rl\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1368\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: size mismatch, m1: [32 x 1], m2: [8 x 32] at C:\\w\\1\\s\\tmp_conda_3.7_100118\\conda\\conda-bld\\pytorch_1579082551706\\work\\aten\\src\\TH/generic/THTensorMath.cpp:136"
     ]
    }
   ],
   "source": [
    "for k in range(num_vae_steps):\n",
    "    num_data_context = torch.randint(low=min_seq_len, high=max_seq_len, size=(1,)).item()\n",
    "    idx = torch.randperm(max_seq_len)\n",
    "    ctx_idx = idx[0:num_data_context]\n",
    "\n",
    "    context = torch.empty(n_batch, num_data_context, 2)\n",
    "    prev_task = torch.empty(n_batch, 2)\n",
    "    \n",
    "    for t_idx in range(n_batch):\n",
    "        # Creating new task\n",
    "        mu = prior_dist[prev_task_param[t_idx]][0].clone().detach()\n",
    "        var = prior_dist[prev_task_param[t_idx]][1].clone().detach()\n",
    "\n",
    "        offset_param = torch.normal(mu, var)\n",
    "        prev_task[t_idx] = new_tasks[i] - offset_param\n",
    "        prior[t_idx][0:2] = prev_task[t_idx] + prior[t_idx][0:2].clone().detach()\n",
    "        mu_prior[t_idx] = prev_task[t_idx] + mu_prior[t_idx].clone().detach()\n",
    "    \n",
    "    obs = envs.reset()\n",
    "    \n",
    "    for _ in range(num_data_context):\n",
    "        \n",
    "        _, action, _, recurrent_hidden_states = actor_critic.act(\n",
    "                        obs,\n",
    "                        recurrent_hidden_states,\n",
    "                        masks,\n",
    "                        deterministic=True)\n",
    "\n",
    "        # Creating context to be fed to the network\n",
    "        #batch = task[k]['train']\n",
    "        #batch = torch.cat([batch[0], batch[1]], dim=1)\n",
    "        #context[i] = batch[ctx_idx]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "envs.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tried to reset an environment before done. If you want to allow early resets, wrap your env with Monitor(env, path, allow_early_resets=True)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-143-33006e149bf7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0menvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0menvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\GitHub\\non-stationary-meta\\ppo_a2c\\envs.py\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m         \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvenv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m         \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user.laptop-fg37h74p\\documents\\github\\baselines\\baselines\\common\\vec_env\\vec_normalize.py\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvenv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_obfilt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user.laptop-fg37h74p\\documents\\github\\baselines\\baselines\\common\\vec_env\\dummy_vec_env.py\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m             \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_obs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_obs_from_buf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user.laptop-fg37h74p\\documents\\github\\baselines\\baselines\\bench\\monitor.py\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_keywords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user.laptop-fg37h74p\\documents\\github\\baselines\\baselines\\bench\\monitor.py\u001b[0m in \u001b[0;36mreset_state\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallow_early_resets\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneeds_reset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Tried to reset an environment before done. If you want to allow early resets, wrap your env with Monitor(env, path, allow_early_resets=True)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrewards\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneeds_reset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Tried to reset an environment before done. If you want to allow early resets, wrap your env with Monitor(env, path, allow_early_resets=True)"
     ]
    }
   ],
   "source": [
    "action = torch.zeros(32, 1)\n",
    "envs.step(action)\n",
    "envs.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_hat = torch.tensor(([[-4.5736, -5.6167],\n",
    "        [-4.5995, -5.5584],\n",
    "        [-4.5447, -5.6031],\n",
    "        [-4.5297, -5.5113],\n",
    "        [-4.6044, -5.5776],\n",
    "        [-4.5590, -5.6067],\n",
    "        [-4.5123, -5.5357],\n",
    "        [-4.5706, -5.5982],\n",
    "        [-4.5858, -5.5714],\n",
    "        [-4.5625, -5.5824],\n",
    "        [-4.4981, -5.4977],\n",
    "        [-4.5742, -5.5858],\n",
    "        [-4.5905, -5.5652],\n",
    "        [-4.5940, -5.5453],\n",
    "        [-4.5768, -5.5583],\n",
    "        [-4.6133, -5.5942],\n",
    "        [-4.5947, -5.5796],\n",
    "        [-4.5960, -5.5496],\n",
    "        [-4.5939, -5.5749],\n",
    "        [-4.5499, -5.5939],\n",
    "        [-4.5859, -5.5737],\n",
    "        [-4.6060, -5.5917],\n",
    "        [-4.5622, -5.5881],\n",
    "        [-4.5937, -5.5275],\n",
    "        [-4.5483, -5.5648],\n",
    "        [-4.5279, -5.5324],\n",
    "        [-4.5729, -5.5762],\n",
    "        [-4.5582, -5.5640],\n",
    "        [-4.5754, -5.5296],\n",
    "        [-4.5762, -5.5990],\n",
    "        [-4.6007, -5.5767],\n",
    "        [-4.5499, -5.5863]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "logvar_hat = torch.tensor(([[-2.7202,  3.5733],\n",
    "        [-2.7427,  3.5949],\n",
    "        [-2.7453,  3.4146],\n",
    "        [-2.7562,  3.6051],\n",
    "        [-2.6888,  3.6820],\n",
    "        [-2.7102,  3.5139],\n",
    "        [-2.6849,  3.5726],\n",
    "        [-2.7284,  3.6229],\n",
    "        [-2.7323,  3.5869],\n",
    "        [-2.7436,  3.5241],\n",
    "        [-2.7217,  3.6121],\n",
    "        [-2.7509,  3.6344],\n",
    "        [-2.7200,  3.5609],\n",
    "        [-2.7387,  3.5669],\n",
    "        [-2.7256,  3.6080],\n",
    "        [-2.7027,  3.6222],\n",
    "        [-2.7467,  3.5562],\n",
    "        [-2.7350,  3.6479],\n",
    "        [-2.7684,  3.5777],\n",
    "        [-2.7411,  3.4838],\n",
    "        [-2.7227,  3.5752],\n",
    "        [-2.7380,  3.6019],\n",
    "        [-2.7510,  3.5215],\n",
    "        [-2.7348,  3.6059],\n",
    "        [-2.7772,  3.5317],\n",
    "        [-2.6809,  3.5654],\n",
    "        [-2.7414,  3.5932],\n",
    "        [-2.6938,  3.5981],\n",
    "        [-2.7203,  3.5340],\n",
    "        [-2.7988,  3.5107],\n",
    "        [-2.6951,  3.5948],\n",
    "        [-2.7277,  3.4164]]))\n",
    "z = torch.tensor(([[ 6.7558e-01,  2.2573e+01],\n",
    "        [-2.7218e-02,  2.6196e+01],\n",
    "        [-3.7066e+01,  2.3923e+01],\n",
    "        [-3.6919e+01,  1.6424e+01],\n",
    "        [ 9.4472e+00,  2.4021e+01],\n",
    "        [ 1.6121e+00,  3.0990e+01],\n",
    "        [-2.4685e+01,  1.8533e+01],\n",
    "        [ 7.9599e-01,  2.1005e+01],\n",
    "        [ 9.6045e+00,  2.8377e+01],\n",
    "        [ 1.0271e+01,  2.6835e+01],\n",
    "        [-2.2725e+01,  2.2635e+01],\n",
    "        [ 3.5228e+01,  2.3419e+01],\n",
    "        [-6.1438e+00,  1.9029e+01],\n",
    "        [-2.9312e+00,  2.2424e+01],\n",
    "        [ 4.6941e+00,  1.5226e+01],\n",
    "        [ 2.0995e+01,  3.4946e+01],\n",
    "        [ 1.7635e+01,  2.7040e+01],\n",
    "        [ 1.3886e+01,  1.7287e+01],\n",
    "        [ 3.0028e+01,  3.4110e+01],\n",
    "        [ 3.2592e+00,  1.9136e+01],\n",
    "        [ 2.4801e+00,  2.8218e+01],\n",
    "        [ 3.1573e+01,  2.8707e+01],\n",
    "        [ 1.5901e+01,  3.0177e+01],\n",
    "        [-2.1286e+00,  2.7334e+01],\n",
    "        [-2.0234e+01,  3.3972e+01],\n",
    "        [-3.0675e+01,  2.5438e+01],\n",
    "        [ 1.7635e+01,  2.7040e+01],\n",
    "        [-1.4248e+01,  3.2116e+01],\n",
    "        [ 5.7589e+00,  1.7996e+01],\n",
    "        [ 1.2729e+01,  2.3523e+01],\n",
    "        [-8.5331e+00,  2.6929e+01],\n",
    "        [-6.0825e+00,  3.3631e+01]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = torch.mean(torch.sum(logvar_hat.exp(), 1)) + F.mse_loss(mu_hat, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(35.6061)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.sum(logvar_hat.exp(),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "709.6632080078125"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
