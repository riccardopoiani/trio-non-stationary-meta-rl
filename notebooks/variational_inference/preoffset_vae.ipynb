{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from task.TaskGenerator import SinTaskGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreOffsetVAENew(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PreOffsetVAE, self).__init__()\n",
    "        self.enc1 = torch.nn.Linear(3, 16) # 3 input: x, f_t(x), f_(t-1)(x)\n",
    "        self.enc2 = torch.nn.GRU(input_size=16, hidden_size=16, num_layers=4, batch_first=True)\n",
    "        self.enc31 = torch.nn.Linear(64, 3)\n",
    "        #self.enc32 = torch.nn.Linear(64, 3)\n",
    "        \n",
    "    def encode(self, context):\n",
    "        seq_len = context.shape[0]\n",
    "        t = F.relu(self.enc1(context)).view(1, seq_len, 16)\n",
    "        t = self.enc2(t)[0][0][-1, :] # we are interested only in the last output of the sequence\n",
    "        t = F.relu(t)\n",
    "        return self.enc31(t)\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "    \n",
    "    def forward(self, context):\n",
    "        #mu, logvar = self.encode(context)\n",
    "        #z = self.reparameterize(mu, logvar)\n",
    "        #return z, mu, logvar\n",
    "        return self.encode(context)\n",
    "    \n",
    "class PreOffsetVAEBatchVersion(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PreOffsetVAEBatchVersion, self).__init__()\n",
    "        self.enc1 = torch.nn.Linear(2, 16) # 3 input: x, f_t(x), f_(t-1)(x)\n",
    "        self.enc2 = torch.nn.GRU(input_size=16, hidden_size=16, num_layers=2, batch_first=True)\n",
    "        self.enc3 = torch.nn.Linear(16, 16)\n",
    "        self.enc4 = torch.nn.Linear(16, 3)\n",
    "        \n",
    "    def encode(self, context):\n",
    "        n_batch = context.shape[0]\n",
    "        seq_len = context.shape[1]\n",
    "        t = F.elu(self.enc1(context)).view(n_batch, seq_len, 16)\n",
    "        t = self.enc2(t)[0][:, -1, :] # we are interested only in the last output of the sequence\n",
    "        t = F.elu(t)\n",
    "        t = F.elu(self.enc3(t))\n",
    "        return  self.enc4(t)\n",
    "        \n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "    \n",
    "    def forward(self, context):\n",
    "        return self.encode(context)\n",
    "\n",
    "class PreOffsetVAE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PreOffsetVAE, self).__init__()\n",
    "        self.enc1 = torch.nn.Linear(2, 16) # 3 input: x, f_t(x), f_(t-1)(x)\n",
    "        self.enc2 = torch.nn.GRU(input_size=16, hidden_size=16, num_layers=4, batch_first=True)\n",
    "        self.enc31 = torch.nn.Linear(64, 3)\n",
    "        #self.enc32 = torch.nn.Linear(64, 3)\n",
    "        \n",
    "    def encode(self, context):\n",
    "        seq_len = context.shape[0]\n",
    "        t = F.relu(self.enc1(context)).view(1, seq_len, 16)\n",
    "        t = self.enc2(t)[0][0][-1, :] # we are interested only in the last output of the sequence\n",
    "        t = F.relu(t)\n",
    "        #return self.enc31(t), self.enc32(t)\n",
    "        return self.enc31(t)\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "    \n",
    "    def forward(self, context):\n",
    "        #mu, logvar = self.encode(context)\n",
    "        #z = self.reparameterize(mu, logvar)\n",
    "        #return z, mu, logvar\n",
    "        return self.encode(context)\n",
    "    \n",
    "class PreOffsetVAEBatchVersion(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PreOffsetVAEBatchVersion, self).__init__()\n",
    "        self.enc1 = torch.nn.Linear(2, 16) # 3 input: x, f_t(x), f_(t-1)(x)\n",
    "        self.enc2 = torch.nn.GRU(input_size=16, hidden_size=16, num_layers=2, batch_first=True)\n",
    "        self.enc3 = torch.nn.Linear(16, 16)\n",
    "        self.enc4 = torch.nn.Linear(16, 3)\n",
    "        \n",
    "    def encode(self, context):\n",
    "        n_batch = context.shape[0]\n",
    "        seq_len = context.shape[1]\n",
    "        t = F.elu(self.enc1(context)).view(n_batch, seq_len, 16)\n",
    "        t = self.enc2(t)[0][:, -1, :] # we are interested only in the last output of the sequence\n",
    "        t = F.elu(t)\n",
    "        t = F.elu(self.enc3(t))\n",
    "        return  self.enc4(t)\n",
    "        \n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "    \n",
    "    def forward(self, context):\n",
    "        return self.encode(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreOffsetVAEBatchVersionNEWNEW(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PreOffsetVAEBatchVersionNEWNEW, self).__init__()\n",
    "        self.enc1 = torch.nn.Linear(3, 16) # 3 input: x, f_t(x), f_(t-1)(x)\n",
    "        self.enc2 = torch.nn.GRU(input_size=16, hidden_size=16, num_layers=2, batch_first=True)\n",
    "        self.enc3 = torch.nn.Linear(16, 16)\n",
    "        self.enc4 = torch.nn.Linear(16, 3)\n",
    "        \n",
    "    def encode(self, context):\n",
    "        n_batch = context.shape[0]\n",
    "        seq_len = context.shape[1]\n",
    "        t = F.elu(self.enc1(context)).view(n_batch, seq_len, 16)\n",
    "        t = self.enc2(t)[0][:, -1, :] # we are interested only in the last output of the sequence\n",
    "        t = F.elu(t)\n",
    "        t = F.elu(self.enc3(t))\n",
    "        return  self.enc4(t)\n",
    "        \n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "    \n",
    "    def forward(self, context):\n",
    "        return self.encode(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PreOffsetVAEBatchVersionNEWNEW()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_f, f):\n",
    "    MSE = F.mse_loss(recon_f, f)\n",
    "    #KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    return MSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_gen = SinTaskGenerator(x_min=-5, x_max=5)\n",
    "dataset = []\n",
    "\n",
    "# Task parameters range\n",
    "max_a = 0.5\n",
    "min_a = 10\n",
    "\n",
    "min_phase = -1\n",
    "max_phase = 1\n",
    "\n",
    "min_freq = 1\n",
    "max_freq = 5\n",
    "\n",
    "def sample_task(n_batches=10, test_perc=0, batch_size=128):\n",
    "    a = (min_a - max_a) * torch.rand(1) + max_a\n",
    "    phase = (min_phase - max_phase) * torch.rand(1) + max_phase\n",
    "    f = (min_freq - max_freq) * torch.rand(1) + max_freq\n",
    "    \n",
    "    \"\"\"\n",
    "    a_t2 = a_t1 + torch.rand(1) * offset_a_max\n",
    "    phase_t2 = phase_t1 + torch.rand(1) * offset_phase_max\n",
    "    f_t2 = f_t1 + torch.rand(1) * offset_f_max\n",
    "    \"\"\"\n",
    "    data = task_gen.get_data_loader(amplitude=a, \n",
    "                                    phase=phase,\n",
    "                                    frequency=f,\n",
    "                                    num_batches=n_batches,\n",
    "                                    test_perc=test_perc, \n",
    "                                    batch_size=batch_size)\n",
    "\n",
    "    return data, a, phase, f\n",
    "\n",
    "# Dataset creation\n",
    "n_tasks = 1000\n",
    "data_set = []\n",
    "a_set = []\n",
    "phase_set = []\n",
    "f_set = []\n",
    "for _ in range(n_tasks):\n",
    "    data, a, phase, f = sample_task(n_batches=1, test_perc=0, batch_size=128)\n",
    "    data_set.append(data)\n",
    "    a_set.append(a)\n",
    "    phase_set.append(phase)\n",
    "    f_set.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 2\n",
    "\n",
    "\n",
    "def batch_train_offset(epoch, n_batch=10):\n",
    "    train_loss = 0\n",
    "    n_batch = 32\n",
    "    batch_per_task = 1\n",
    "    task_idx = torch.randint(low=0, high=n_tasks, size=(n_batch,))\n",
    "    task_loader = [data_set[i] for i in task_idx]\n",
    "\n",
    "    for k in range(batch_per_task):\n",
    "        num_data_context = torch.randint(low=10, high=30, size=(1,)).item()\n",
    "        num_data_eval = 128 - num_data_context\n",
    "        idx = torch.randint(0, 128, (128,))\n",
    "\n",
    "        context = torch.empty(n_batch*batch_per_task, num_data_context, 2)\n",
    "        x = torch.empty(n_batch*batch_per_task, num_data_eval, 2)\n",
    "        y = torch.empty(n_batch*batch_per_task, num_data_eval, 1)\n",
    "\n",
    "        # Retrieving data to be fed to the network \n",
    "        i = 0\n",
    "        for task in task_loader:\n",
    "            batch = task[k]['train']\n",
    "            ctx_idx = idx[0:num_data_context]\n",
    "            x_idx = idx[num_data_context:]\n",
    "\n",
    "            y[i] = batch[1][x_idx]\n",
    "\n",
    "            batch = torch.cat([batch[0], batch[1]], dim=1)\n",
    "\n",
    "            x[i] = batch[x_idx]\n",
    "            context[i] = batch[ctx_idx]\n",
    "\n",
    "            i+=1\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        z = model(context)\n",
    "\n",
    "        # Compute reconstruction\n",
    "        y_hat = z[:, 0].unsqueeze(1) * torch.sin((z[:, 1].unsqueeze(1) * x[:, :, 0]) + z[:, 2].unsqueeze(1))\n",
    "        y = y.squeeze()\n",
    "\n",
    "        loss = loss_function(y_hat, y)\n",
    "        loss.backward()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return train_loss / (batch_per_task)\n",
    "\n",
    "def batch_train(epoch, n_batch=10):\n",
    "    train_loss = 0\n",
    "    n_batch = 32\n",
    "    batch_per_task = 1\n",
    "    task_idx = torch.randint(low=0, high=n_tasks, size=(n_batch,))\n",
    "    task_loader = [data_set[i] for i in task_idx]\n",
    "\n",
    "    for k in range(batch_per_task):\n",
    "        num_data_context = torch.randint(low=10, high=30, size=(1,)).item()\n",
    "        num_data_eval = 128 - num_data_context\n",
    "        idx = torch.randint(0, 128, (128,))\n",
    "\n",
    "        context = torch.empty(n_batch*batch_per_task, num_data_context, 2)\n",
    "        x = torch.empty(n_batch*batch_per_task, num_data_eval, 2)\n",
    "        y = torch.empty(n_batch*batch_per_task, num_data_eval, 1)\n",
    "\n",
    "        # Retrieving data to be fed to the network \n",
    "        i = 0\n",
    "        for task in task_loader:\n",
    "            batch = task[k]['train']\n",
    "            ctx_idx = idx[0:num_data_context]\n",
    "            x_idx = idx[num_data_context:]\n",
    "\n",
    "            y[i] = batch[1][x_idx]\n",
    "\n",
    "            batch = torch.cat([batch[0], batch[1]], dim=1)\n",
    "\n",
    "            x[i] = batch[x_idx]\n",
    "            context[i] = batch[ctx_idx]\n",
    "\n",
    "            i+=1\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        z = model(context)\n",
    "\n",
    "        # Compute reconstruction\n",
    "        y_hat = z[:, 0].unsqueeze(1) * torch.sin((z[:, 1].unsqueeze(1) * x[:, :, 0]) + z[:, 2].unsqueeze(1))\n",
    "        y = y.squeeze()\n",
    "\n",
    "        loss = loss_function(y_hat, y)\n",
    "        loss.backward()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return train_loss / (batch_per_task)\n",
    "    \n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    task_idx = torch.randint(low=0, high=n_tasks, size=(1,)).item()\n",
    "    data_loader = data_set[task_idx]\n",
    "    \n",
    "    # Current task latent space\n",
    "    a = a_set[task_idx]\n",
    "    p = phase_set[task_idx]\n",
    "    f = f_set[task_idx]\n",
    "    \n",
    "    # Previous task latent space\n",
    "    #a_prev = a + torch.rand(1) * offset\n",
    "    #p_prev = p + torch.rand(1) * offset\n",
    "    #f_prev = f + torch.rand(1) * offset\n",
    "    \n",
    "    for batch_idx, batch in enumerate(data_loader):\n",
    "        # Retrieving information from the dataset\n",
    "        num_data_context = torch.randint(low=10, high=30, size=(1,)).item()\n",
    "        batch = batch['train']\n",
    "        idx = torch.randint(0, 128, (128,))\n",
    "        ctx_idx = idx[0:num_data_context]\n",
    "        x_idx = idx[num_data_context:]\n",
    "        \n",
    "        y = batch[1][x_idx]\n",
    "        batch = torch.cat([batch[0], batch[1]], dim=1)\n",
    "        x = batch[x_idx]\n",
    "        context = batch[ctx_idx]\n",
    "        \n",
    "        \n",
    "        # Compute latent model\n",
    "        optimizer.zero_grad()\n",
    "        z = model(context)\n",
    "        \n",
    "        # Compute reconstruction\n",
    "        y_hat = (z[0]) * torch.sin((z[1])*x[:, 0:1] + (z[2]))\n",
    "        loss = loss_function(y_hat, y)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    return train_loss / (batch_idx+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 0 Average loss: 16.3918\n",
      "====> Epoch: 100 Average loss: 17.0588\n",
      "====> Epoch: 200 Average loss: 17.1839\n",
      "====> Epoch: 300 Average loss: 17.1704\n",
      "====> Epoch: 400 Average loss: 17.1752\n",
      "====> Epoch: 500 Average loss: 17.0686\n",
      "====> Epoch: 600 Average loss: 17.0508\n",
      "====> Epoch: 700 Average loss: 17.0496\n",
      "====> Epoch: 800 Average loss: 16.9937\n",
      "====> Epoch: 900 Average loss: 16.9837\n",
      "====> Epoch: 1000 Average loss: 16.9572\n",
      "====> Epoch: 1100 Average loss: 16.9292\n",
      "====> Epoch: 1200 Average loss: 16.9445\n",
      "====> Epoch: 1300 Average loss: 16.9444\n",
      "====> Epoch: 1400 Average loss: 16.9781\n",
      "====> Epoch: 1500 Average loss: 16.9665\n",
      "====> Epoch: 1600 Average loss: 16.9810\n",
      "====> Epoch: 1700 Average loss: 16.9670\n",
      "====> Epoch: 1800 Average loss: 16.9788\n",
      "====> Epoch: 1900 Average loss: 16.9707\n",
      "====> Epoch: 2000 Average loss: 16.9918\n",
      "====> Epoch: 2100 Average loss: 16.9825\n",
      "====> Epoch: 2200 Average loss: 16.9742\n",
      "====> Epoch: 2300 Average loss: 16.9670\n",
      "====> Epoch: 2400 Average loss: 16.9547\n",
      "====> Epoch: 2500 Average loss: 16.9584\n",
      "====> Epoch: 2600 Average loss: 16.9424\n",
      "====> Epoch: 2700 Average loss: 16.9311\n",
      "====> Epoch: 2800 Average loss: 16.9329\n",
      "====> Epoch: 2900 Average loss: 16.9403\n",
      "====> Epoch: 3000 Average loss: 16.9392\n",
      "====> Epoch: 3100 Average loss: 16.9526\n",
      "====> Epoch: 3200 Average loss: 16.9529\n",
      "====> Epoch: 3300 Average loss: 16.9572\n",
      "====> Epoch: 3400 Average loss: 16.9566\n",
      "====> Epoch: 3500 Average loss: 16.9662\n",
      "====> Epoch: 3600 Average loss: 16.9705\n",
      "====> Epoch: 3700 Average loss: 16.9865\n",
      "====> Epoch: 3800 Average loss: 16.9799\n",
      "====> Epoch: 3900 Average loss: 16.9737\n",
      "====> Epoch: 4000 Average loss: 16.9790\n",
      "====> Epoch: 4100 Average loss: 16.9735\n",
      "====> Epoch: 4200 Average loss: 16.9733\n",
      "====> Epoch: 4300 Average loss: 16.9778\n",
      "====> Epoch: 4400 Average loss: 16.9663\n",
      "====> Epoch: 4500 Average loss: 16.9629\n",
      "====> Epoch: 4600 Average loss: 16.9681\n",
      "====> Epoch: 4700 Average loss: 16.9658\n",
      "====> Epoch: 4800 Average loss: 16.9669\n",
      "====> Epoch: 4900 Average loss: 16.9622\n",
      "====> Epoch: 5000 Average loss: 16.9582\n",
      "====> Epoch: 5100 Average loss: 16.9634\n",
      "====> Epoch: 5200 Average loss: 16.9722\n",
      "====> Epoch: 5300 Average loss: 16.9658\n",
      "====> Epoch: 5400 Average loss: 16.9651\n",
      "====> Epoch: 5500 Average loss: 16.9642\n",
      "====> Epoch: 5600 Average loss: 16.9738\n",
      "====> Epoch: 5700 Average loss: 16.9717\n",
      "====> Epoch: 5800 Average loss: 16.9780\n",
      "====> Epoch: 5900 Average loss: 16.9761\n",
      "====> Epoch: 6000 Average loss: 16.9882\n",
      "====> Epoch: 6100 Average loss: 16.9913\n",
      "====> Epoch: 6200 Average loss: 16.9894\n",
      "====> Epoch: 6300 Average loss: 16.9835\n",
      "====> Epoch: 6400 Average loss: 16.9889\n",
      "====> Epoch: 6500 Average loss: 16.9885\n",
      "====> Epoch: 6600 Average loss: 16.9893\n",
      "====> Epoch: 6700 Average loss: 16.9891\n",
      "====> Epoch: 6800 Average loss: 16.9866\n",
      "====> Epoch: 6900 Average loss: 16.9866\n",
      "====> Epoch: 7000 Average loss: 16.9882\n",
      "====> Epoch: 7100 Average loss: 16.9953\n",
      "====> Epoch: 7200 Average loss: 16.9955\n",
      "====> Epoch: 7300 Average loss: 16.9997\n",
      "====> Epoch: 7400 Average loss: 17.0012\n",
      "====> Epoch: 7500 Average loss: 16.9973\n",
      "====> Epoch: 7600 Average loss: 17.0042\n",
      "====> Epoch: 7700 Average loss: 17.0027\n",
      "====> Epoch: 7800 Average loss: 16.9999\n",
      "====> Epoch: 7900 Average loss: 17.0009\n",
      "====> Epoch: 8000 Average loss: 17.0016\n",
      "====> Epoch: 8100 Average loss: 17.0041\n",
      "====> Epoch: 8200 Average loss: 17.0009\n",
      "====> Epoch: 8300 Average loss: 16.9950\n",
      "====> Epoch: 8400 Average loss: 16.9936\n",
      "====> Epoch: 8500 Average loss: 16.9893\n",
      "====> Epoch: 8600 Average loss: 16.9857\n",
      "====> Epoch: 8700 Average loss: 16.9830\n",
      "====> Epoch: 8800 Average loss: 16.9821\n",
      "====> Epoch: 8900 Average loss: 16.9785\n",
      "====> Epoch: 9000 Average loss: 16.9786\n",
      "====> Epoch: 9100 Average loss: 16.9757\n",
      "====> Epoch: 9200 Average loss: 16.9721\n",
      "====> Epoch: 9300 Average loss: 16.9723\n",
      "====> Epoch: 9400 Average loss: 16.9690\n",
      "====> Epoch: 9500 Average loss: 16.9683\n",
      "====> Epoch: 9600 Average loss: 16.9693\n",
      "====> Epoch: 9700 Average loss: 16.9685\n",
      "====> Epoch: 9800 Average loss: 16.9686\n",
      "====> Epoch: 9900 Average loss: 16.9691\n",
      "====> Epoch: 10000 Average loss: 16.9691\n",
      "====> Epoch: 10100 Average loss: 16.9682\n",
      "====> Epoch: 10200 Average loss: 16.9675\n",
      "====> Epoch: 10300 Average loss: 16.9647\n",
      "====> Epoch: 10400 Average loss: 16.9653\n",
      "====> Epoch: 10500 Average loss: 16.9630\n",
      "====> Epoch: 10600 Average loss: 16.9614\n",
      "====> Epoch: 10700 Average loss: 16.9633\n",
      "====> Epoch: 10800 Average loss: 16.9599\n",
      "====> Epoch: 10900 Average loss: 16.9568\n",
      "====> Epoch: 11000 Average loss: 16.9535\n",
      "====> Epoch: 11100 Average loss: 16.9541\n",
      "====> Epoch: 11200 Average loss: 16.9504\n",
      "====> Epoch: 11300 Average loss: 16.9464\n",
      "====> Epoch: 11400 Average loss: 16.9473\n",
      "====> Epoch: 11500 Average loss: 16.9485\n",
      "====> Epoch: 11600 Average loss: 16.9500\n",
      "====> Epoch: 11700 Average loss: 16.9473\n",
      "====> Epoch: 11800 Average loss: 16.9454\n",
      "====> Epoch: 11900 Average loss: 16.9474\n",
      "====> Epoch: 12000 Average loss: 16.9455\n",
      "====> Epoch: 12100 Average loss: 16.9456\n",
      "====> Epoch: 12200 Average loss: 16.9458\n",
      "====> Epoch: 12300 Average loss: 16.9424\n",
      "====> Epoch: 12400 Average loss: 16.9470\n",
      "====> Epoch: 12500 Average loss: 16.9462\n",
      "====> Epoch: 12600 Average loss: 16.9463\n",
      "====> Epoch: 12700 Average loss: 16.9452\n",
      "====> Epoch: 12800 Average loss: 16.9428\n",
      "====> Epoch: 12900 Average loss: 16.9423\n",
      "====> Epoch: 13000 Average loss: 16.9419\n",
      "====> Epoch: 13100 Average loss: 16.9444\n",
      "====> Epoch: 13200 Average loss: 16.9420\n",
      "====> Epoch: 13300 Average loss: 16.9391\n",
      "====> Epoch: 13400 Average loss: 16.9417\n",
      "====> Epoch: 13500 Average loss: 16.9385\n",
      "====> Epoch: 13600 Average loss: 16.9355\n",
      "====> Epoch: 13700 Average loss: 16.9352\n",
      "====> Epoch: 13800 Average loss: 16.9367\n",
      "====> Epoch: 13900 Average loss: 16.9377\n",
      "====> Epoch: 14000 Average loss: 16.9361\n",
      "====> Epoch: 14100 Average loss: 16.9345\n",
      "====> Epoch: 14200 Average loss: 16.9368\n",
      "====> Epoch: 14300 Average loss: 16.9338\n",
      "====> Epoch: 14400 Average loss: 16.9336\n",
      "====> Epoch: 14500 Average loss: 16.9345\n",
      "====> Epoch: 14600 Average loss: 16.9348\n",
      "====> Epoch: 14700 Average loss: 16.9359\n",
      "====> Epoch: 14800 Average loss: 16.9387\n",
      "====> Epoch: 14900 Average loss: 16.9401\n",
      "====> Epoch: 15000 Average loss: 16.9395\n",
      "====> Epoch: 15100 Average loss: 16.9394\n",
      "====> Epoch: 15200 Average loss: 16.9359\n",
      "====> Epoch: 15300 Average loss: 16.9362\n",
      "====> Epoch: 15400 Average loss: 16.9344\n",
      "====> Epoch: 15500 Average loss: 16.9346\n",
      "====> Epoch: 15600 Average loss: 16.9351\n",
      "====> Epoch: 15700 Average loss: 16.9364\n",
      "====> Epoch: 15800 Average loss: 16.9393\n",
      "====> Epoch: 15900 Average loss: 16.9390\n",
      "====> Epoch: 16000 Average loss: 16.9398\n",
      "====> Epoch: 16100 Average loss: 16.9400\n",
      "====> Epoch: 16200 Average loss: 16.9378\n",
      "====> Epoch: 16300 Average loss: 16.9341\n",
      "====> Epoch: 16400 Average loss: 16.9331\n",
      "====> Epoch: 16500 Average loss: 16.9328\n",
      "====> Epoch: 16600 Average loss: 16.9318\n",
      "====> Epoch: 16700 Average loss: 16.9315\n",
      "====> Epoch: 16800 Average loss: 16.9307\n",
      "====> Epoch: 16900 Average loss: 16.9271\n",
      "====> Epoch: 17000 Average loss: 16.9272\n",
      "====> Epoch: 17100 Average loss: 16.9269\n",
      "====> Epoch: 17200 Average loss: 16.9263\n",
      "====> Epoch: 17300 Average loss: 16.9227\n",
      "====> Epoch: 17400 Average loss: 16.9241\n",
      "====> Epoch: 17500 Average loss: 16.9225\n",
      "====> Epoch: 17600 Average loss: 16.9227\n",
      "====> Epoch: 17700 Average loss: 16.9228\n",
      "====> Epoch: 17800 Average loss: 16.9195\n",
      "====> Epoch: 17900 Average loss: 16.9201\n",
      "====> Epoch: 18000 Average loss: 16.9186\n",
      "====> Epoch: 18100 Average loss: 16.9168\n",
      "====> Epoch: 18200 Average loss: 16.9171\n",
      "====> Epoch: 18300 Average loss: 16.9172\n",
      "====> Epoch: 18400 Average loss: 16.9172\n",
      "====> Epoch: 18500 Average loss: 16.9175\n",
      "====> Epoch: 18600 Average loss: 16.9150\n",
      "====> Epoch: 18700 Average loss: 16.9180\n",
      "====> Epoch: 18800 Average loss: 16.9181\n",
      "====> Epoch: 18900 Average loss: 16.9191\n",
      "====> Epoch: 19000 Average loss: 16.9188\n",
      "====> Epoch: 19100 Average loss: 16.9189\n",
      "====> Epoch: 19200 Average loss: 16.9173\n",
      "====> Epoch: 19300 Average loss: 16.9179\n",
      "====> Epoch: 19400 Average loss: 16.9195\n",
      "====> Epoch: 19500 Average loss: 16.9177\n",
      "====> Epoch: 19600 Average loss: 16.9147\n",
      "====> Epoch: 19700 Average loss: 16.9128\n",
      "====> Epoch: 19800 Average loss: 16.9113\n",
      "====> Epoch: 19900 Average loss: 16.9104\n",
      "====> Epoch: 20000 Average loss: 16.9112\n",
      "====> Epoch: 20100 Average loss: 16.9127\n",
      "====> Epoch: 20200 Average loss: 16.9139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 20300 Average loss: 16.9142\n",
      "====> Epoch: 20400 Average loss: 16.9147\n",
      "====> Epoch: 20500 Average loss: 16.9137\n",
      "====> Epoch: 20600 Average loss: 16.9122\n",
      "====> Epoch: 20700 Average loss: 16.9097\n",
      "====> Epoch: 20800 Average loss: 16.9069\n",
      "====> Epoch: 20900 Average loss: 16.9069\n",
      "====> Epoch: 21000 Average loss: 16.9053\n",
      "====> Epoch: 21100 Average loss: 16.9046\n",
      "====> Epoch: 21200 Average loss: 16.9054\n",
      "====> Epoch: 21300 Average loss: 16.9072\n",
      "====> Epoch: 21400 Average loss: 16.9050\n",
      "====> Epoch: 21500 Average loss: 16.9034\n",
      "====> Epoch: 21600 Average loss: 16.9042\n",
      "====> Epoch: 21700 Average loss: 16.9040\n",
      "====> Epoch: 21800 Average loss: 16.9019\n",
      "====> Epoch: 21900 Average loss: 16.9028\n",
      "====> Epoch: 22000 Average loss: 16.9033\n",
      "====> Epoch: 22100 Average loss: 16.9023\n",
      "====> Epoch: 22200 Average loss: 16.9005\n",
      "====> Epoch: 22300 Average loss: 16.8996\n",
      "====> Epoch: 22400 Average loss: 16.8982\n",
      "====> Epoch: 22500 Average loss: 16.8986\n",
      "====> Epoch: 22600 Average loss: 16.8973\n",
      "====> Epoch: 22700 Average loss: 16.8967\n",
      "====> Epoch: 22800 Average loss: 16.8963\n",
      "====> Epoch: 22900 Average loss: 16.8962\n",
      "====> Epoch: 23000 Average loss: 16.8961\n",
      "====> Epoch: 23100 Average loss: 16.8953\n",
      "====> Epoch: 23200 Average loss: 16.8938\n",
      "====> Epoch: 23300 Average loss: 16.8942\n",
      "====> Epoch: 23400 Average loss: 16.8942\n",
      "====> Epoch: 23500 Average loss: 16.8955\n",
      "====> Epoch: 23600 Average loss: 16.8943\n",
      "====> Epoch: 23700 Average loss: 16.8924\n",
      "====> Epoch: 23800 Average loss: 16.8943\n",
      "====> Epoch: 23900 Average loss: 16.8965\n",
      "====> Epoch: 24000 Average loss: 16.8949\n",
      "====> Epoch: 24100 Average loss: 16.8919\n",
      "====> Epoch: 24200 Average loss: 16.8915\n",
      "====> Epoch: 24300 Average loss: 16.8897\n",
      "====> Epoch: 24400 Average loss: 16.8897\n",
      "====> Epoch: 24500 Average loss: 16.8893\n",
      "====> Epoch: 24600 Average loss: 16.8891\n",
      "====> Epoch: 24700 Average loss: 16.8906\n",
      "====> Epoch: 24800 Average loss: 16.8902\n",
      "====> Epoch: 24900 Average loss: 16.8905\n",
      "====> Epoch: 25000 Average loss: 16.8883\n",
      "====> Epoch: 25100 Average loss: 16.8869\n",
      "====> Epoch: 25200 Average loss: 16.8878\n",
      "====> Epoch: 25300 Average loss: 16.8890\n",
      "====> Epoch: 25400 Average loss: 16.8888\n",
      "====> Epoch: 25500 Average loss: 16.8878\n",
      "====> Epoch: 25600 Average loss: 16.8881\n",
      "====> Epoch: 25700 Average loss: 16.8887\n",
      "====> Epoch: 25800 Average loss: 16.8901\n",
      "====> Epoch: 25900 Average loss: 16.8912\n",
      "====> Epoch: 26000 Average loss: 16.8919\n",
      "====> Epoch: 26100 Average loss: 16.8917\n",
      "====> Epoch: 26200 Average loss: 16.8916\n",
      "====> Epoch: 26300 Average loss: 16.8933\n",
      "====> Epoch: 26400 Average loss: 16.8937\n",
      "====> Epoch: 26500 Average loss: 16.8940\n",
      "====> Epoch: 26600 Average loss: 16.8930\n",
      "====> Epoch: 26700 Average loss: 16.8925\n",
      "====> Epoch: 26800 Average loss: 16.8919\n",
      "====> Epoch: 26900 Average loss: 16.8920\n",
      "====> Epoch: 27000 Average loss: 16.8899\n",
      "====> Epoch: 27100 Average loss: 16.8898\n",
      "====> Epoch: 27200 Average loss: 16.8899\n",
      "====> Epoch: 27300 Average loss: 16.8889\n",
      "====> Epoch: 27400 Average loss: 16.8887\n",
      "====> Epoch: 27500 Average loss: 16.8893\n",
      "====> Epoch: 27600 Average loss: 16.8884\n",
      "====> Epoch: 27700 Average loss: 16.8883\n",
      "====> Epoch: 27800 Average loss: 16.8883\n",
      "====> Epoch: 27900 Average loss: 16.8864\n",
      "====> Epoch: 28000 Average loss: 16.8868\n",
      "====> Epoch: 28100 Average loss: 16.8860\n",
      "====> Epoch: 28200 Average loss: 16.8866\n",
      "====> Epoch: 28300 Average loss: 16.8862\n",
      "====> Epoch: 28400 Average loss: 16.8862\n",
      "====> Epoch: 28500 Average loss: 16.8866\n",
      "====> Epoch: 28600 Average loss: 16.8855\n",
      "====> Epoch: 28700 Average loss: 16.8858\n",
      "====> Epoch: 28800 Average loss: 16.8872\n",
      "====> Epoch: 28900 Average loss: 16.8885\n",
      "====> Epoch: 29000 Average loss: 16.8871\n",
      "====> Epoch: 29100 Average loss: 16.8866\n",
      "====> Epoch: 29200 Average loss: 16.8869\n",
      "====> Epoch: 29300 Average loss: 16.8866\n",
      "====> Epoch: 29400 Average loss: 16.8847\n",
      "====> Epoch: 29500 Average loss: 16.8865\n",
      "====> Epoch: 29600 Average loss: 16.8853\n",
      "====> Epoch: 29700 Average loss: 16.8855\n",
      "====> Epoch: 29800 Average loss: 16.8853\n",
      "====> Epoch: 29900 Average loss: 16.8848\n",
      "====> Epoch: 30000 Average loss: 16.8841\n",
      "====> Epoch: 30100 Average loss: 16.8840\n",
      "====> Epoch: 30200 Average loss: 16.8836\n",
      "====> Epoch: 30300 Average loss: 16.8844\n",
      "====> Epoch: 30400 Average loss: 16.8840\n",
      "====> Epoch: 30500 Average loss: 16.8842\n",
      "====> Epoch: 30600 Average loss: 16.8843\n",
      "====> Epoch: 30700 Average loss: 16.8848\n",
      "====> Epoch: 30800 Average loss: 16.8847\n",
      "====> Epoch: 30900 Average loss: 16.8842\n",
      "====> Epoch: 31000 Average loss: 16.8851\n",
      "====> Epoch: 31100 Average loss: 16.8846\n",
      "====> Epoch: 31200 Average loss: 16.8853\n",
      "====> Epoch: 31300 Average loss: 16.8860\n",
      "====> Epoch: 31400 Average loss: 16.8851\n",
      "====> Epoch: 31500 Average loss: 16.8856\n",
      "====> Epoch: 31600 Average loss: 16.8883\n",
      "====> Epoch: 31700 Average loss: 16.8896\n",
      "====> Epoch: 31800 Average loss: 16.8897\n",
      "====> Epoch: 31900 Average loss: 16.8906\n",
      "====> Epoch: 32000 Average loss: 16.8899\n",
      "====> Epoch: 32100 Average loss: 16.8884\n",
      "====> Epoch: 32200 Average loss: 16.8885\n",
      "====> Epoch: 32300 Average loss: 16.8896\n",
      "====> Epoch: 32400 Average loss: 16.8894\n",
      "====> Epoch: 32500 Average loss: 16.8891\n",
      "====> Epoch: 32600 Average loss: 16.8902\n",
      "====> Epoch: 32700 Average loss: 16.8900\n",
      "====> Epoch: 32800 Average loss: 16.8887\n",
      "====> Epoch: 32900 Average loss: 16.8889\n",
      "====> Epoch: 33000 Average loss: 16.8871\n",
      "====> Epoch: 33100 Average loss: 16.8867\n",
      "====> Epoch: 33200 Average loss: 16.8874\n",
      "====> Epoch: 33300 Average loss: 16.8861\n",
      "====> Epoch: 33400 Average loss: 16.8865\n",
      "====> Epoch: 33500 Average loss: 16.8857\n",
      "====> Epoch: 33600 Average loss: 16.8858\n",
      "====> Epoch: 33700 Average loss: 16.8867\n",
      "====> Epoch: 33800 Average loss: 16.8877\n",
      "====> Epoch: 33900 Average loss: 16.8873\n",
      "====> Epoch: 34000 Average loss: 16.8863\n",
      "====> Epoch: 34100 Average loss: 16.8854\n",
      "====> Epoch: 34200 Average loss: 16.8852\n",
      "====> Epoch: 34300 Average loss: 16.8859\n",
      "====> Epoch: 34400 Average loss: 16.8857\n",
      "====> Epoch: 34500 Average loss: 16.8860\n",
      "====> Epoch: 34600 Average loss: 16.8862\n",
      "====> Epoch: 34700 Average loss: 16.8852\n",
      "====> Epoch: 34800 Average loss: 16.8856\n",
      "====> Epoch: 34900 Average loss: 16.8864\n",
      "====> Epoch: 35000 Average loss: 16.8860\n",
      "====> Epoch: 35100 Average loss: 16.8858\n",
      "====> Epoch: 35200 Average loss: 16.8857\n",
      "====> Epoch: 35300 Average loss: 16.8845\n",
      "====> Epoch: 35400 Average loss: 16.8839\n",
      "====> Epoch: 35500 Average loss: 16.8849\n",
      "====> Epoch: 35600 Average loss: 16.8854\n",
      "====> Epoch: 35700 Average loss: 16.8850\n",
      "====> Epoch: 35800 Average loss: 16.8843\n",
      "====> Epoch: 35900 Average loss: 16.8840\n",
      "====> Epoch: 36000 Average loss: 16.8847\n",
      "====> Epoch: 36100 Average loss: 16.8840\n",
      "====> Epoch: 36200 Average loss: 16.8836\n",
      "====> Epoch: 36300 Average loss: 16.8831\n",
      "====> Epoch: 36400 Average loss: 16.8819\n",
      "====> Epoch: 36500 Average loss: 16.8823\n",
      "====> Epoch: 36600 Average loss: 16.8815\n",
      "====> Epoch: 36700 Average loss: 16.8820\n",
      "====> Epoch: 36800 Average loss: 16.8828\n",
      "====> Epoch: 36900 Average loss: 16.8824\n",
      "====> Epoch: 37000 Average loss: 16.8823\n",
      "====> Epoch: 37100 Average loss: 16.8818\n",
      "====> Epoch: 37200 Average loss: 16.8825\n",
      "====> Epoch: 37300 Average loss: 16.8836\n",
      "====> Epoch: 37400 Average loss: 16.8829\n",
      "====> Epoch: 37500 Average loss: 16.8820\n",
      "====> Epoch: 37600 Average loss: 16.8821\n",
      "====> Epoch: 37700 Average loss: 16.8811\n",
      "====> Epoch: 37800 Average loss: 16.8817\n",
      "====> Epoch: 37900 Average loss: 16.8820\n",
      "====> Epoch: 38000 Average loss: 16.8825\n",
      "====> Epoch: 38100 Average loss: 16.8829\n",
      "====> Epoch: 38200 Average loss: 16.8825\n",
      "====> Epoch: 38300 Average loss: 16.8828\n",
      "====> Epoch: 38400 Average loss: 16.8818\n",
      "====> Epoch: 38500 Average loss: 16.8820\n",
      "====> Epoch: 38600 Average loss: 16.8810\n",
      "====> Epoch: 38700 Average loss: 16.8808\n",
      "====> Epoch: 38800 Average loss: 16.8822\n",
      "====> Epoch: 38900 Average loss: 16.8825\n",
      "====> Epoch: 39000 Average loss: 16.8836\n",
      "====> Epoch: 39100 Average loss: 16.8846\n",
      "====> Epoch: 39200 Average loss: 16.8838\n",
      "====> Epoch: 39300 Average loss: 16.8834\n",
      "====> Epoch: 39400 Average loss: 16.8832\n",
      "====> Epoch: 39500 Average loss: 16.8824\n",
      "====> Epoch: 39600 Average loss: 16.8822\n",
      "====> Epoch: 39700 Average loss: 16.8824\n",
      "====> Epoch: 39800 Average loss: 16.8825\n",
      "====> Epoch: 39900 Average loss: 16.8836\n",
      "====> Epoch: 40000 Average loss: 16.8830\n",
      "====> Epoch: 40100 Average loss: 16.8841\n",
      "====> Epoch: 40200 Average loss: 16.8845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 40300 Average loss: 16.8847\n",
      "====> Epoch: 40400 Average loss: 16.8850\n",
      "====> Epoch: 40500 Average loss: 16.8849\n",
      "====> Epoch: 40600 Average loss: 16.8842\n",
      "====> Epoch: 40700 Average loss: 16.8841\n",
      "====> Epoch: 40800 Average loss: 16.8844\n",
      "====> Epoch: 40900 Average loss: 16.8843\n",
      "====> Epoch: 41000 Average loss: 16.8848\n",
      "====> Epoch: 41100 Average loss: 16.8843\n",
      "====> Epoch: 41200 Average loss: 16.8842\n",
      "====> Epoch: 41300 Average loss: 16.8840\n",
      "====> Epoch: 41400 Average loss: 16.8850\n",
      "====> Epoch: 41500 Average loss: 16.8847\n",
      "====> Epoch: 41600 Average loss: 16.8848\n",
      "====> Epoch: 41700 Average loss: 16.8848\n",
      "====> Epoch: 41800 Average loss: 16.8852\n",
      "====> Epoch: 41900 Average loss: 16.8850\n",
      "====> Epoch: 42000 Average loss: 16.8846\n",
      "====> Epoch: 42100 Average loss: 16.8847\n",
      "====> Epoch: 42200 Average loss: 16.8851\n",
      "====> Epoch: 42300 Average loss: 16.8864\n",
      "====> Epoch: 42400 Average loss: 16.8866\n",
      "====> Epoch: 42500 Average loss: 16.8871\n",
      "====> Epoch: 42600 Average loss: 16.8861\n",
      "====> Epoch: 42700 Average loss: 16.8861\n",
      "====> Epoch: 42800 Average loss: 16.8857\n",
      "====> Epoch: 42900 Average loss: 16.8855\n",
      "====> Epoch: 43000 Average loss: 16.8853\n",
      "====> Epoch: 43100 Average loss: 16.8856\n",
      "====> Epoch: 43200 Average loss: 16.8848\n",
      "====> Epoch: 43300 Average loss: 16.8847\n",
      "====> Epoch: 43400 Average loss: 16.8846\n",
      "====> Epoch: 43500 Average loss: 16.8858\n",
      "====> Epoch: 43600 Average loss: 16.8863\n",
      "====> Epoch: 43700 Average loss: 16.8858\n",
      "====> Epoch: 43800 Average loss: 16.8859\n",
      "====> Epoch: 43900 Average loss: 16.8854\n",
      "====> Epoch: 44000 Average loss: 16.8856\n",
      "====> Epoch: 44100 Average loss: 16.8849\n",
      "====> Epoch: 44200 Average loss: 16.8857\n",
      "====> Epoch: 44300 Average loss: 16.8869\n",
      "====> Epoch: 44400 Average loss: 16.8867\n",
      "====> Epoch: 44500 Average loss: 16.8869\n",
      "====> Epoch: 44600 Average loss: 16.8863\n",
      "====> Epoch: 44700 Average loss: 16.8866\n",
      "====> Epoch: 44800 Average loss: 16.8862\n",
      "====> Epoch: 44900 Average loss: 16.8863\n",
      "====> Epoch: 45000 Average loss: 16.8861\n",
      "====> Epoch: 45100 Average loss: 16.8875\n",
      "====> Epoch: 45200 Average loss: 16.8873\n",
      "====> Epoch: 45300 Average loss: 16.8870\n",
      "====> Epoch: 45400 Average loss: 16.8867\n",
      "====> Epoch: 45500 Average loss: 16.8870\n",
      "====> Epoch: 45600 Average loss: 16.8870\n",
      "====> Epoch: 45700 Average loss: 16.8877\n",
      "====> Epoch: 45800 Average loss: 16.8877\n",
      "====> Epoch: 45900 Average loss: 16.8879\n",
      "====> Epoch: 46000 Average loss: 16.8879\n",
      "====> Epoch: 46100 Average loss: 16.8877\n",
      "====> Epoch: 46200 Average loss: 16.8869\n",
      "====> Epoch: 46300 Average loss: 16.8869\n",
      "====> Epoch: 46400 Average loss: 16.8865\n",
      "====> Epoch: 46500 Average loss: 16.8852\n",
      "====> Epoch: 46600 Average loss: 16.8847\n",
      "====> Epoch: 46700 Average loss: 16.8850\n",
      "====> Epoch: 46800 Average loss: 16.8845\n",
      "====> Epoch: 46900 Average loss: 16.8851\n",
      "====> Epoch: 47000 Average loss: 16.8857\n",
      "====> Epoch: 47100 Average loss: 16.8851\n",
      "====> Epoch: 47200 Average loss: 16.8846\n",
      "====> Epoch: 47300 Average loss: 16.8845\n",
      "====> Epoch: 47400 Average loss: 16.8850\n",
      "====> Epoch: 47500 Average loss: 16.8850\n",
      "====> Epoch: 47600 Average loss: 16.8849\n",
      "====> Epoch: 47700 Average loss: 16.8844\n",
      "====> Epoch: 47800 Average loss: 16.8840\n",
      "====> Epoch: 47900 Average loss: 16.8837\n",
      "====> Epoch: 48000 Average loss: 16.8834\n",
      "====> Epoch: 48100 Average loss: 16.8841\n",
      "====> Epoch: 48200 Average loss: 16.8835\n",
      "====> Epoch: 48300 Average loss: 16.8837\n",
      "====> Epoch: 48400 Average loss: 16.8837\n",
      "====> Epoch: 48500 Average loss: 16.8834\n",
      "====> Epoch: 48600 Average loss: 16.8834\n",
      "====> Epoch: 48700 Average loss: 16.8830\n",
      "====> Epoch: 48800 Average loss: 16.8825\n",
      "====> Epoch: 48900 Average loss: 16.8822\n",
      "====> Epoch: 49000 Average loss: 16.8811\n",
      "====> Epoch: 49100 Average loss: 16.8805\n",
      "====> Epoch: 49200 Average loss: 16.8797\n",
      "====> Epoch: 49300 Average loss: 16.8792\n",
      "====> Epoch: 49400 Average loss: 16.8798\n",
      "====> Epoch: 49500 Average loss: 16.8798\n",
      "====> Epoch: 49600 Average loss: 16.8803\n",
      "====> Epoch: 49700 Average loss: 16.8808\n",
      "====> Epoch: 49800 Average loss: 16.8804\n",
      "====> Epoch: 49900 Average loss: 16.8807\n",
      "====> Epoch: 50000 Average loss: 16.8825\n",
      "====> Epoch: 50100 Average loss: 16.8829\n",
      "====> Epoch: 50200 Average loss: 16.8844\n",
      "====> Epoch: 50300 Average loss: 16.8838\n",
      "====> Epoch: 50400 Average loss: 16.8836\n",
      "====> Epoch: 50500 Average loss: 16.8832\n",
      "====> Epoch: 50600 Average loss: 16.8831\n",
      "====> Epoch: 50700 Average loss: 16.8833\n",
      "====> Epoch: 50800 Average loss: 16.8833\n",
      "====> Epoch: 50900 Average loss: 16.8840\n",
      "====> Epoch: 51000 Average loss: 16.8840\n",
      "====> Epoch: 51100 Average loss: 16.8833\n",
      "====> Epoch: 51200 Average loss: 16.8830\n",
      "====> Epoch: 51300 Average loss: 16.8833\n",
      "====> Epoch: 51400 Average loss: 16.8830\n",
      "====> Epoch: 51500 Average loss: 16.8827\n",
      "====> Epoch: 51600 Average loss: 16.8821\n",
      "====> Epoch: 51700 Average loss: 16.8815\n",
      "====> Epoch: 51800 Average loss: 16.8811\n",
      "====> Epoch: 51900 Average loss: 16.8814\n",
      "====> Epoch: 52000 Average loss: 16.8809\n",
      "====> Epoch: 52100 Average loss: 16.8805\n",
      "====> Epoch: 52200 Average loss: 16.8798\n",
      "====> Epoch: 52300 Average loss: 16.8791\n",
      "====> Epoch: 52400 Average loss: 16.8791\n",
      "====> Epoch: 52500 Average loss: 16.8791\n",
      "====> Epoch: 52600 Average loss: 16.8782\n",
      "====> Epoch: 52700 Average loss: 16.8782\n",
      "====> Epoch: 52800 Average loss: 16.8776\n",
      "====> Epoch: 52900 Average loss: 16.8761\n",
      "====> Epoch: 53000 Average loss: 16.8756\n",
      "====> Epoch: 53100 Average loss: 16.8757\n",
      "====> Epoch: 53200 Average loss: 16.8766\n",
      "====> Epoch: 53300 Average loss: 16.8765\n",
      "====> Epoch: 53400 Average loss: 16.8767\n",
      "====> Epoch: 53500 Average loss: 16.8761\n",
      "====> Epoch: 53600 Average loss: 16.8753\n",
      "====> Epoch: 53700 Average loss: 16.8753\n",
      "====> Epoch: 53800 Average loss: 16.8755\n",
      "====> Epoch: 53900 Average loss: 16.8756\n",
      "====> Epoch: 54000 Average loss: 16.8761\n",
      "====> Epoch: 54100 Average loss: 16.8772\n",
      "====> Epoch: 54200 Average loss: 16.8774\n",
      "====> Epoch: 54300 Average loss: 16.8767\n",
      "====> Epoch: 54400 Average loss: 16.8762\n",
      "====> Epoch: 54500 Average loss: 16.8765\n",
      "====> Epoch: 54600 Average loss: 16.8760\n",
      "====> Epoch: 54700 Average loss: 16.8768\n",
      "====> Epoch: 54800 Average loss: 16.8768\n",
      "====> Epoch: 54900 Average loss: 16.8770\n",
      "====> Epoch: 55000 Average loss: 16.8766\n",
      "====> Epoch: 55100 Average loss: 16.8761\n",
      "====> Epoch: 55200 Average loss: 16.8759\n",
      "====> Epoch: 55300 Average loss: 16.8766\n",
      "====> Epoch: 55400 Average loss: 16.8768\n",
      "====> Epoch: 55500 Average loss: 16.8765\n",
      "====> Epoch: 55600 Average loss: 16.8771\n",
      "====> Epoch: 55700 Average loss: 16.8765\n",
      "====> Epoch: 55800 Average loss: 16.8758\n",
      "====> Epoch: 55900 Average loss: 16.8761\n",
      "====> Epoch: 56000 Average loss: 16.8762\n",
      "====> Epoch: 56100 Average loss: 16.8764\n",
      "====> Epoch: 56200 Average loss: 16.8769\n",
      "====> Epoch: 56300 Average loss: 16.8773\n",
      "====> Epoch: 56400 Average loss: 16.8775\n",
      "====> Epoch: 56500 Average loss: 16.8780\n",
      "====> Epoch: 56600 Average loss: 16.8781\n",
      "====> Epoch: 56700 Average loss: 16.8783\n",
      "====> Epoch: 56800 Average loss: 16.8781\n",
      "====> Epoch: 56900 Average loss: 16.8779\n",
      "====> Epoch: 57000 Average loss: 16.8780\n",
      "====> Epoch: 57100 Average loss: 16.8779\n",
      "====> Epoch: 57200 Average loss: 16.8779\n",
      "====> Epoch: 57300 Average loss: 16.8781\n",
      "====> Epoch: 57400 Average loss: 16.8785\n",
      "====> Epoch: 57500 Average loss: 16.8792\n",
      "====> Epoch: 57600 Average loss: 16.8784\n",
      "====> Epoch: 57700 Average loss: 16.8789\n",
      "====> Epoch: 57800 Average loss: 16.8797\n",
      "====> Epoch: 57900 Average loss: 16.8796\n",
      "====> Epoch: 58000 Average loss: 16.8791\n",
      "====> Epoch: 58100 Average loss: 16.8794\n",
      "====> Epoch: 58200 Average loss: 16.8798\n",
      "====> Epoch: 58300 Average loss: 16.8802\n",
      "====> Epoch: 58400 Average loss: 16.8805\n",
      "====> Epoch: 58500 Average loss: 16.8805\n",
      "====> Epoch: 58600 Average loss: 16.8805\n",
      "====> Epoch: 58700 Average loss: 16.8803\n",
      "====> Epoch: 58800 Average loss: 16.8806\n",
      "====> Epoch: 58900 Average loss: 16.8805\n",
      "====> Epoch: 59000 Average loss: 16.8808\n",
      "====> Epoch: 59100 Average loss: 16.8804\n",
      "====> Epoch: 59200 Average loss: 16.8800\n",
      "====> Epoch: 59300 Average loss: 16.8794\n",
      "====> Epoch: 59400 Average loss: 16.8802\n",
      "====> Epoch: 59500 Average loss: 16.8810\n",
      "====> Epoch: 59600 Average loss: 16.8814\n",
      "====> Epoch: 59700 Average loss: 16.8816\n",
      "====> Epoch: 59800 Average loss: 16.8817\n",
      "====> Epoch: 59900 Average loss: 16.8810\n",
      "====> Epoch: 60000 Average loss: 16.8811\n",
      "====> Epoch: 60100 Average loss: 16.8805\n",
      "====> Epoch: 60200 Average loss: 16.8809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 60300 Average loss: 16.8808\n",
      "====> Epoch: 60400 Average loss: 16.8818\n",
      "====> Epoch: 60500 Average loss: 16.8819\n",
      "====> Epoch: 60600 Average loss: 16.8816\n",
      "====> Epoch: 60700 Average loss: 16.8820\n",
      "====> Epoch: 60800 Average loss: 16.8817\n",
      "====> Epoch: 60900 Average loss: 16.8816\n",
      "====> Epoch: 61000 Average loss: 16.8809\n",
      "====> Epoch: 61100 Average loss: 16.8808\n",
      "====> Epoch: 61200 Average loss: 16.8800\n",
      "====> Epoch: 61300 Average loss: 16.8803\n",
      "====> Epoch: 61400 Average loss: 16.8803\n",
      "====> Epoch: 61500 Average loss: 16.8801\n",
      "====> Epoch: 61600 Average loss: 16.8795\n",
      "====> Epoch: 61700 Average loss: 16.8791\n",
      "====> Epoch: 61800 Average loss: 16.8781\n",
      "====> Epoch: 61900 Average loss: 16.8782\n",
      "====> Epoch: 62000 Average loss: 16.8775\n",
      "====> Epoch: 62100 Average loss: 16.8779\n",
      "====> Epoch: 62200 Average loss: 16.8786\n",
      "====> Epoch: 62300 Average loss: 16.8791\n",
      "====> Epoch: 62400 Average loss: 16.8794\n",
      "====> Epoch: 62500 Average loss: 16.8800\n",
      "====> Epoch: 62600 Average loss: 16.8802\n",
      "====> Epoch: 62700 Average loss: 16.8801\n",
      "====> Epoch: 62800 Average loss: 16.8797\n",
      "====> Epoch: 62900 Average loss: 16.8795\n",
      "====> Epoch: 63000 Average loss: 16.8794\n",
      "====> Epoch: 63100 Average loss: 16.8791\n",
      "====> Epoch: 63200 Average loss: 16.8791\n",
      "====> Epoch: 63300 Average loss: 16.8791\n",
      "====> Epoch: 63400 Average loss: 16.8794\n",
      "====> Epoch: 63500 Average loss: 16.8795\n",
      "====> Epoch: 63600 Average loss: 16.8790\n",
      "====> Epoch: 63700 Average loss: 16.8794\n",
      "====> Epoch: 63800 Average loss: 16.8796\n",
      "====> Epoch: 63900 Average loss: 16.8789\n",
      "====> Epoch: 64000 Average loss: 16.8790\n",
      "====> Epoch: 64100 Average loss: 16.8792\n",
      "====> Epoch: 64200 Average loss: 16.8790\n",
      "====> Epoch: 64300 Average loss: 16.8790\n",
      "====> Epoch: 64400 Average loss: 16.8791\n",
      "====> Epoch: 64500 Average loss: 16.8790\n",
      "====> Epoch: 64600 Average loss: 16.8796\n",
      "====> Epoch: 64700 Average loss: 16.8794\n",
      "====> Epoch: 64800 Average loss: 16.8800\n",
      "====> Epoch: 64900 Average loss: 16.8798\n",
      "====> Epoch: 65000 Average loss: 16.8792\n",
      "====> Epoch: 65100 Average loss: 16.8790\n",
      "====> Epoch: 65200 Average loss: 16.8785\n",
      "====> Epoch: 65300 Average loss: 16.8785\n",
      "====> Epoch: 65400 Average loss: 16.8782\n",
      "====> Epoch: 65500 Average loss: 16.8775\n",
      "====> Epoch: 65600 Average loss: 16.8771\n",
      "====> Epoch: 65700 Average loss: 16.8769\n",
      "====> Epoch: 65800 Average loss: 16.8776\n",
      "====> Epoch: 65900 Average loss: 16.8771\n",
      "====> Epoch: 66000 Average loss: 16.8777\n",
      "====> Epoch: 66100 Average loss: 16.8772\n",
      "====> Epoch: 66200 Average loss: 16.8771\n",
      "====> Epoch: 66300 Average loss: 16.8778\n",
      "====> Epoch: 66400 Average loss: 16.8776\n",
      "====> Epoch: 66500 Average loss: 16.8768\n",
      "====> Epoch: 66600 Average loss: 16.8767\n",
      "====> Epoch: 66700 Average loss: 16.8768\n",
      "====> Epoch: 66800 Average loss: 16.8771\n",
      "====> Epoch: 66900 Average loss: 16.8765\n",
      "====> Epoch: 67000 Average loss: 16.8764\n",
      "====> Epoch: 67100 Average loss: 16.8757\n",
      "====> Epoch: 67200 Average loss: 16.8757\n",
      "====> Epoch: 67300 Average loss: 16.8760\n",
      "====> Epoch: 67400 Average loss: 16.8762\n",
      "====> Epoch: 67500 Average loss: 16.8765\n",
      "====> Epoch: 67600 Average loss: 16.8763\n",
      "====> Epoch: 67700 Average loss: 16.8763\n",
      "====> Epoch: 67800 Average loss: 16.8757\n",
      "====> Epoch: 67900 Average loss: 16.8761\n",
      "====> Epoch: 68000 Average loss: 16.8764\n",
      "====> Epoch: 68100 Average loss: 16.8758\n",
      "====> Epoch: 68200 Average loss: 16.8759\n",
      "====> Epoch: 68300 Average loss: 16.8761\n",
      "====> Epoch: 68400 Average loss: 16.8754\n",
      "====> Epoch: 68500 Average loss: 16.8755\n",
      "====> Epoch: 68600 Average loss: 16.8752\n",
      "====> Epoch: 68700 Average loss: 16.8751\n",
      "====> Epoch: 68800 Average loss: 16.8749\n",
      "====> Epoch: 68900 Average loss: 16.8750\n",
      "====> Epoch: 69000 Average loss: 16.8750\n",
      "====> Epoch: 69100 Average loss: 16.8755\n",
      "====> Epoch: 69200 Average loss: 16.8752\n",
      "====> Epoch: 69300 Average loss: 16.8756\n",
      "====> Epoch: 69400 Average loss: 16.8755\n",
      "====> Epoch: 69500 Average loss: 16.8757\n",
      "====> Epoch: 69600 Average loss: 16.8757\n",
      "====> Epoch: 69700 Average loss: 16.8757\n",
      "====> Epoch: 69800 Average loss: 16.8765\n",
      "====> Epoch: 69900 Average loss: 16.8763\n",
      "====> Epoch: 70000 Average loss: 16.8759\n",
      "====> Epoch: 70100 Average loss: 16.8756\n",
      "====> Epoch: 70200 Average loss: 16.8759\n",
      "====> Epoch: 70300 Average loss: 16.8757\n",
      "====> Epoch: 70400 Average loss: 16.8757\n",
      "====> Epoch: 70500 Average loss: 16.8759\n",
      "====> Epoch: 70600 Average loss: 16.8755\n",
      "====> Epoch: 70700 Average loss: 16.8756\n",
      "====> Epoch: 70800 Average loss: 16.8760\n",
      "====> Epoch: 70900 Average loss: 16.8762\n",
      "====> Epoch: 71000 Average loss: 16.8761\n",
      "====> Epoch: 71100 Average loss: 16.8767\n",
      "====> Epoch: 71200 Average loss: 16.8768\n",
      "====> Epoch: 71300 Average loss: 16.8765\n",
      "====> Epoch: 71400 Average loss: 16.8768\n",
      "====> Epoch: 71500 Average loss: 16.8765\n",
      "====> Epoch: 71600 Average loss: 16.8763\n",
      "====> Epoch: 71700 Average loss: 16.8764\n",
      "====> Epoch: 71800 Average loss: 16.8765\n",
      "====> Epoch: 71900 Average loss: 16.8766\n",
      "====> Epoch: 72000 Average loss: 16.8767\n",
      "====> Epoch: 72100 Average loss: 16.8762\n",
      "====> Epoch: 72200 Average loss: 16.8757\n",
      "====> Epoch: 72300 Average loss: 16.8755\n",
      "====> Epoch: 72400 Average loss: 16.8752\n",
      "====> Epoch: 72500 Average loss: 16.8751\n",
      "====> Epoch: 72600 Average loss: 16.8753\n",
      "====> Epoch: 72700 Average loss: 16.8752\n",
      "====> Epoch: 72800 Average loss: 16.8755\n",
      "====> Epoch: 72900 Average loss: 16.8757\n",
      "====> Epoch: 73000 Average loss: 16.8759\n",
      "====> Epoch: 73100 Average loss: 16.8758\n",
      "====> Epoch: 73200 Average loss: 16.8758\n",
      "====> Epoch: 73300 Average loss: 16.8756\n",
      "====> Epoch: 73400 Average loss: 16.8755\n",
      "====> Epoch: 73500 Average loss: 16.8750\n",
      "====> Epoch: 73600 Average loss: 16.8749\n",
      "====> Epoch: 73700 Average loss: 16.8746\n",
      "====> Epoch: 73800 Average loss: 16.8745\n",
      "====> Epoch: 73900 Average loss: 16.8746\n",
      "====> Epoch: 74000 Average loss: 16.8744\n",
      "====> Epoch: 74100 Average loss: 16.8740\n",
      "====> Epoch: 74200 Average loss: 16.8743\n",
      "====> Epoch: 74300 Average loss: 16.8748\n",
      "====> Epoch: 74400 Average loss: 16.8746\n",
      "====> Epoch: 74500 Average loss: 16.8746\n",
      "====> Epoch: 74600 Average loss: 16.8739\n",
      "====> Epoch: 74700 Average loss: 16.8739\n",
      "====> Epoch: 74800 Average loss: 16.8740\n",
      "====> Epoch: 74900 Average loss: 16.8738\n",
      "====> Epoch: 75000 Average loss: 16.8736\n",
      "====> Epoch: 75100 Average loss: 16.8734\n",
      "====> Epoch: 75200 Average loss: 16.8731\n",
      "====> Epoch: 75300 Average loss: 16.8737\n",
      "====> Epoch: 75400 Average loss: 16.8736\n",
      "====> Epoch: 75500 Average loss: 16.8737\n",
      "====> Epoch: 75600 Average loss: 16.8747\n",
      "====> Epoch: 75700 Average loss: 16.8746\n",
      "====> Epoch: 75800 Average loss: 16.8744\n",
      "====> Epoch: 75900 Average loss: 16.8748\n",
      "====> Epoch: 76000 Average loss: 16.8751\n",
      "====> Epoch: 76100 Average loss: 16.8754\n",
      "====> Epoch: 76200 Average loss: 16.8758\n",
      "====> Epoch: 76300 Average loss: 16.8760\n",
      "====> Epoch: 76400 Average loss: 16.8754\n",
      "====> Epoch: 76500 Average loss: 16.8749\n",
      "====> Epoch: 76600 Average loss: 16.8752\n",
      "====> Epoch: 76700 Average loss: 16.8755\n",
      "====> Epoch: 76800 Average loss: 16.8763\n",
      "====> Epoch: 76900 Average loss: 16.8767\n",
      "====> Epoch: 77000 Average loss: 16.8764\n",
      "====> Epoch: 77100 Average loss: 16.8763\n",
      "====> Epoch: 77200 Average loss: 16.8763\n",
      "====> Epoch: 77300 Average loss: 16.8758\n",
      "====> Epoch: 77400 Average loss: 16.8758\n",
      "====> Epoch: 77500 Average loss: 16.8760\n",
      "====> Epoch: 77600 Average loss: 16.8756\n",
      "====> Epoch: 77700 Average loss: 16.8759\n",
      "====> Epoch: 77800 Average loss: 16.8761\n",
      "====> Epoch: 77900 Average loss: 16.8761\n",
      "====> Epoch: 78000 Average loss: 16.8764\n",
      "====> Epoch: 78100 Average loss: 16.8769\n",
      "====> Epoch: 78200 Average loss: 16.8767\n",
      "====> Epoch: 78300 Average loss: 16.8759\n",
      "====> Epoch: 78400 Average loss: 16.8762\n",
      "====> Epoch: 78500 Average loss: 16.8762\n",
      "====> Epoch: 78600 Average loss: 16.8755\n",
      "====> Epoch: 78700 Average loss: 16.8750\n",
      "====> Epoch: 78800 Average loss: 16.8749\n",
      "====> Epoch: 78900 Average loss: 16.8754\n",
      "====> Epoch: 79000 Average loss: 16.8758\n",
      "====> Epoch: 79100 Average loss: 16.8758\n",
      "====> Epoch: 79200 Average loss: 16.8755\n",
      "====> Epoch: 79300 Average loss: 16.8753\n",
      "====> Epoch: 79400 Average loss: 16.8749\n",
      "====> Epoch: 79500 Average loss: 16.8752\n",
      "====> Epoch: 79600 Average loss: 16.8745\n",
      "====> Epoch: 79700 Average loss: 16.8740\n",
      "====> Epoch: 79800 Average loss: 16.8737\n",
      "====> Epoch: 79900 Average loss: 16.8740\n",
      "====> Epoch: 80000 Average loss: 16.8736\n",
      "====> Epoch: 80100 Average loss: 16.8736\n",
      "====> Epoch: 80200 Average loss: 16.8734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 80300 Average loss: 16.8737\n",
      "====> Epoch: 80400 Average loss: 16.8740\n",
      "====> Epoch: 80500 Average loss: 16.8739\n",
      "====> Epoch: 80600 Average loss: 16.8739\n",
      "====> Epoch: 80700 Average loss: 16.8741\n",
      "====> Epoch: 80800 Average loss: 16.8739\n",
      "====> Epoch: 80900 Average loss: 16.8741\n",
      "====> Epoch: 81000 Average loss: 16.8740\n",
      "====> Epoch: 81100 Average loss: 16.8737\n",
      "====> Epoch: 81200 Average loss: 16.8736\n",
      "====> Epoch: 81300 Average loss: 16.8735\n",
      "====> Epoch: 81400 Average loss: 16.8733\n",
      "====> Epoch: 81500 Average loss: 16.8729\n",
      "====> Epoch: 81600 Average loss: 16.8725\n",
      "====> Epoch: 81700 Average loss: 16.8723\n",
      "====> Epoch: 81800 Average loss: 16.8722\n",
      "====> Epoch: 81900 Average loss: 16.8726\n",
      "====> Epoch: 82000 Average loss: 16.8723\n",
      "====> Epoch: 82100 Average loss: 16.8719\n",
      "====> Epoch: 82200 Average loss: 16.8725\n",
      "====> Epoch: 82300 Average loss: 16.8723\n",
      "====> Epoch: 82400 Average loss: 16.8720\n",
      "====> Epoch: 82500 Average loss: 16.8723\n",
      "====> Epoch: 82600 Average loss: 16.8727\n",
      "====> Epoch: 82700 Average loss: 16.8730\n",
      "====> Epoch: 82800 Average loss: 16.8730\n",
      "====> Epoch: 82900 Average loss: 16.8732\n",
      "====> Epoch: 83000 Average loss: 16.8732\n",
      "====> Epoch: 83100 Average loss: 16.8732\n",
      "====> Epoch: 83200 Average loss: 16.8732\n",
      "====> Epoch: 83300 Average loss: 16.8732\n",
      "====> Epoch: 83400 Average loss: 16.8732\n",
      "====> Epoch: 83500 Average loss: 16.8730\n",
      "====> Epoch: 83600 Average loss: 16.8725\n",
      "====> Epoch: 83700 Average loss: 16.8725\n",
      "====> Epoch: 83800 Average loss: 16.8723\n",
      "====> Epoch: 83900 Average loss: 16.8726\n",
      "====> Epoch: 84000 Average loss: 16.8723\n",
      "====> Epoch: 84100 Average loss: 16.8720\n",
      "====> Epoch: 84200 Average loss: 16.8719\n",
      "====> Epoch: 84300 Average loss: 16.8717\n",
      "====> Epoch: 84400 Average loss: 16.8720\n",
      "====> Epoch: 84500 Average loss: 16.8722\n",
      "====> Epoch: 84600 Average loss: 16.8718\n",
      "====> Epoch: 84700 Average loss: 16.8720\n",
      "====> Epoch: 84800 Average loss: 16.8721\n",
      "====> Epoch: 84900 Average loss: 16.8722\n",
      "====> Epoch: 85000 Average loss: 16.8719\n",
      "====> Epoch: 85100 Average loss: 16.8723\n",
      "====> Epoch: 85200 Average loss: 16.8721\n",
      "====> Epoch: 85300 Average loss: 16.8722\n",
      "====> Epoch: 85400 Average loss: 16.8725\n",
      "====> Epoch: 85500 Average loss: 16.8725\n",
      "====> Epoch: 85600 Average loss: 16.8724\n",
      "====> Epoch: 85700 Average loss: 16.8724\n",
      "====> Epoch: 85800 Average loss: 16.8718\n",
      "====> Epoch: 85900 Average loss: 16.8718\n",
      "====> Epoch: 86000 Average loss: 16.8721\n",
      "====> Epoch: 86100 Average loss: 16.8722\n",
      "====> Epoch: 86200 Average loss: 16.8724\n",
      "====> Epoch: 86300 Average loss: 16.8721\n",
      "====> Epoch: 86400 Average loss: 16.8721\n",
      "====> Epoch: 86500 Average loss: 16.8718\n",
      "====> Epoch: 86600 Average loss: 16.8715\n",
      "====> Epoch: 86700 Average loss: 16.8710\n",
      "====> Epoch: 86800 Average loss: 16.8711\n",
      "====> Epoch: 86900 Average loss: 16.8711\n",
      "====> Epoch: 87000 Average loss: 16.8713\n",
      "====> Epoch: 87100 Average loss: 16.8710\n",
      "====> Epoch: 87200 Average loss: 16.8706\n",
      "====> Epoch: 87300 Average loss: 16.8707\n",
      "====> Epoch: 87400 Average loss: 16.8705\n",
      "====> Epoch: 87500 Average loss: 16.8698\n",
      "====> Epoch: 87600 Average loss: 16.8700\n",
      "====> Epoch: 87700 Average loss: 16.8693\n",
      "====> Epoch: 87800 Average loss: 16.8698\n",
      "====> Epoch: 87900 Average loss: 16.8698\n",
      "====> Epoch: 88000 Average loss: 16.8699\n",
      "====> Epoch: 88100 Average loss: 16.8695\n",
      "====> Epoch: 88200 Average loss: 16.8693\n",
      "====> Epoch: 88300 Average loss: 16.8692\n",
      "====> Epoch: 88400 Average loss: 16.8692\n",
      "====> Epoch: 88500 Average loss: 16.8691\n",
      "====> Epoch: 88600 Average loss: 16.8697\n",
      "====> Epoch: 88700 Average loss: 16.8699\n",
      "====> Epoch: 88800 Average loss: 16.8701\n",
      "====> Epoch: 88900 Average loss: 16.8702\n",
      "====> Epoch: 89000 Average loss: 16.8705\n",
      "====> Epoch: 89100 Average loss: 16.8708\n",
      "====> Epoch: 89200 Average loss: 16.8705\n",
      "====> Epoch: 89300 Average loss: 16.8701\n",
      "====> Epoch: 89400 Average loss: 16.8700\n",
      "====> Epoch: 89500 Average loss: 16.8700\n",
      "====> Epoch: 89600 Average loss: 16.8700\n",
      "====> Epoch: 89700 Average loss: 16.8698\n",
      "====> Epoch: 89800 Average loss: 16.8698\n",
      "====> Epoch: 89900 Average loss: 16.8697\n",
      "====> Epoch: 90000 Average loss: 16.8695\n",
      "====> Epoch: 90100 Average loss: 16.8695\n",
      "====> Epoch: 90200 Average loss: 16.8696\n",
      "====> Epoch: 90300 Average loss: 16.8698\n",
      "====> Epoch: 90400 Average loss: 16.8699\n",
      "====> Epoch: 90500 Average loss: 16.8701\n",
      "====> Epoch: 90600 Average loss: 16.8699\n",
      "====> Epoch: 90700 Average loss: 16.8696\n",
      "====> Epoch: 90800 Average loss: 16.8697\n",
      "====> Epoch: 90900 Average loss: 16.8696\n",
      "====> Epoch: 91000 Average loss: 16.8695\n",
      "====> Epoch: 91100 Average loss: 16.8696\n",
      "====> Epoch: 91200 Average loss: 16.8700\n",
      "====> Epoch: 91300 Average loss: 16.8705\n",
      "====> Epoch: 91400 Average loss: 16.8706\n",
      "====> Epoch: 91500 Average loss: 16.8703\n",
      "====> Epoch: 91600 Average loss: 16.8702\n",
      "====> Epoch: 91700 Average loss: 16.8701\n",
      "====> Epoch: 91800 Average loss: 16.8704\n",
      "====> Epoch: 91900 Average loss: 16.8702\n",
      "====> Epoch: 92000 Average loss: 16.8700\n",
      "====> Epoch: 92100 Average loss: 16.8701\n",
      "====> Epoch: 92200 Average loss: 16.8707\n",
      "====> Epoch: 92300 Average loss: 16.8707\n",
      "====> Epoch: 92400 Average loss: 16.8702\n",
      "====> Epoch: 92500 Average loss: 16.8703\n",
      "====> Epoch: 92600 Average loss: 16.8700\n",
      "====> Epoch: 92700 Average loss: 16.8695\n",
      "====> Epoch: 92800 Average loss: 16.8691\n",
      "====> Epoch: 92900 Average loss: 16.8690\n",
      "====> Epoch: 93000 Average loss: 16.8687\n",
      "====> Epoch: 93100 Average loss: 16.8687\n",
      "====> Epoch: 93200 Average loss: 16.8687\n",
      "====> Epoch: 93300 Average loss: 16.8689\n",
      "====> Epoch: 93400 Average loss: 16.8688\n",
      "====> Epoch: 93500 Average loss: 16.8688\n",
      "====> Epoch: 93600 Average loss: 16.8688\n",
      "====> Epoch: 93700 Average loss: 16.8683\n",
      "====> Epoch: 93800 Average loss: 16.8686\n",
      "====> Epoch: 93900 Average loss: 16.8683\n",
      "====> Epoch: 94000 Average loss: 16.8680\n",
      "====> Epoch: 94100 Average loss: 16.8679\n",
      "====> Epoch: 94200 Average loss: 16.8680\n",
      "====> Epoch: 94300 Average loss: 16.8683\n",
      "====> Epoch: 94400 Average loss: 16.8683\n",
      "====> Epoch: 94500 Average loss: 16.8677\n",
      "====> Epoch: 94600 Average loss: 16.8675\n",
      "====> Epoch: 94700 Average loss: 16.8676\n",
      "====> Epoch: 94800 Average loss: 16.8679\n",
      "====> Epoch: 94900 Average loss: 16.8676\n",
      "====> Epoch: 95000 Average loss: 16.8677\n",
      "====> Epoch: 95100 Average loss: 16.8676\n",
      "====> Epoch: 95200 Average loss: 16.8675\n",
      "====> Epoch: 95300 Average loss: 16.8677\n",
      "====> Epoch: 95400 Average loss: 16.8675\n",
      "====> Epoch: 95500 Average loss: 16.8676\n",
      "====> Epoch: 95600 Average loss: 16.8675\n",
      "====> Epoch: 95700 Average loss: 16.8673\n",
      "====> Epoch: 95800 Average loss: 16.8671\n",
      "====> Epoch: 95900 Average loss: 16.8671\n",
      "====> Epoch: 96000 Average loss: 16.8669\n",
      "====> Epoch: 96100 Average loss: 16.8666\n",
      "====> Epoch: 96200 Average loss: 16.8667\n",
      "====> Epoch: 96300 Average loss: 16.8666\n",
      "====> Epoch: 96400 Average loss: 16.8665\n",
      "====> Epoch: 96500 Average loss: 16.8660\n",
      "====> Epoch: 96600 Average loss: 16.8659\n",
      "====> Epoch: 96700 Average loss: 16.8662\n",
      "====> Epoch: 96800 Average loss: 16.8657\n",
      "====> Epoch: 96900 Average loss: 16.8659\n",
      "====> Epoch: 97000 Average loss: 16.8660\n",
      "====> Epoch: 97100 Average loss: 16.8659\n",
      "====> Epoch: 97200 Average loss: 16.8663\n",
      "====> Epoch: 97300 Average loss: 16.8661\n",
      "====> Epoch: 97400 Average loss: 16.8658\n",
      "====> Epoch: 97500 Average loss: 16.8657\n",
      "====> Epoch: 97600 Average loss: 16.8657\n",
      "====> Epoch: 97700 Average loss: 16.8654\n",
      "====> Epoch: 97800 Average loss: 16.8656\n",
      "====> Epoch: 97900 Average loss: 16.8658\n",
      "====> Epoch: 98000 Average loss: 16.8660\n",
      "====> Epoch: 98100 Average loss: 16.8660\n",
      "====> Epoch: 98200 Average loss: 16.8660\n",
      "====> Epoch: 98300 Average loss: 16.8660\n",
      "====> Epoch: 98400 Average loss: 16.8658\n",
      "====> Epoch: 98500 Average loss: 16.8658\n",
      "====> Epoch: 98600 Average loss: 16.8659\n",
      "====> Epoch: 98700 Average loss: 16.8658\n",
      "====> Epoch: 98800 Average loss: 16.8654\n",
      "====> Epoch: 98900 Average loss: 16.8653\n",
      "====> Epoch: 99000 Average loss: 16.8653\n",
      "====> Epoch: 99100 Average loss: 16.8652\n",
      "====> Epoch: 99200 Average loss: 16.8653\n",
      "====> Epoch: 99300 Average loss: 16.8654\n",
      "====> Epoch: 99400 Average loss: 16.8654\n",
      "====> Epoch: 99500 Average loss: 16.8655\n",
      "====> Epoch: 99600 Average loss: 16.8653\n",
      "====> Epoch: 99700 Average loss: 16.8648\n",
      "====> Epoch: 99800 Average loss: 16.8649\n",
      "====> Epoch: 99900 Average loss: 16.8648\n",
      "====> Epoch: 100000 Average loss: 16.8651\n",
      "====> Epoch: 100100 Average loss: 16.8647\n",
      "====> Epoch: 100200 Average loss: 16.8652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 100300 Average loss: 16.8653\n",
      "====> Epoch: 100400 Average loss: 16.8653\n",
      "====> Epoch: 100500 Average loss: 16.8650\n",
      "====> Epoch: 100600 Average loss: 16.8652\n",
      "====> Epoch: 100700 Average loss: 16.8647\n",
      "====> Epoch: 100800 Average loss: 16.8650\n",
      "====> Epoch: 100900 Average loss: 16.8648\n",
      "====> Epoch: 101000 Average loss: 16.8646\n",
      "====> Epoch: 101100 Average loss: 16.8642\n",
      "====> Epoch: 101200 Average loss: 16.8643\n",
      "====> Epoch: 101300 Average loss: 16.8643\n",
      "====> Epoch: 101400 Average loss: 16.8642\n",
      "====> Epoch: 101500 Average loss: 16.8642\n",
      "====> Epoch: 101600 Average loss: 16.8636\n",
      "====> Epoch: 101700 Average loss: 16.8635\n",
      "====> Epoch: 101800 Average loss: 16.8631\n",
      "====> Epoch: 101900 Average loss: 16.8628\n",
      "====> Epoch: 102000 Average loss: 16.8627\n",
      "====> Epoch: 102100 Average loss: 16.8631\n",
      "====> Epoch: 102200 Average loss: 16.8631\n",
      "====> Epoch: 102300 Average loss: 16.8631\n",
      "====> Epoch: 102400 Average loss: 16.8635\n",
      "====> Epoch: 102500 Average loss: 16.8637\n",
      "====> Epoch: 102600 Average loss: 16.8646\n",
      "====> Epoch: 102700 Average loss: 16.8645\n",
      "====> Epoch: 102800 Average loss: 16.8647\n",
      "====> Epoch: 102900 Average loss: 16.8640\n",
      "====> Epoch: 103000 Average loss: 16.8638\n",
      "====> Epoch: 103100 Average loss: 16.8637\n",
      "====> Epoch: 103200 Average loss: 16.8636\n",
      "====> Epoch: 103300 Average loss: 16.8633\n",
      "====> Epoch: 103400 Average loss: 16.8636\n",
      "====> Epoch: 103500 Average loss: 16.8637\n",
      "====> Epoch: 103600 Average loss: 16.8637\n",
      "====> Epoch: 103700 Average loss: 16.8641\n",
      "====> Epoch: 103800 Average loss: 16.8644\n",
      "====> Epoch: 103900 Average loss: 16.8642\n",
      "====> Epoch: 104000 Average loss: 16.8644\n",
      "====> Epoch: 104100 Average loss: 16.8644\n",
      "====> Epoch: 104200 Average loss: 16.8649\n",
      "====> Epoch: 104300 Average loss: 16.8646\n",
      "====> Epoch: 104400 Average loss: 16.8646\n",
      "====> Epoch: 104500 Average loss: 16.8639\n",
      "====> Epoch: 104600 Average loss: 16.8640\n",
      "====> Epoch: 104700 Average loss: 16.8638\n",
      "====> Epoch: 104800 Average loss: 16.8639\n",
      "====> Epoch: 104900 Average loss: 16.8639\n",
      "====> Epoch: 105000 Average loss: 16.8639\n",
      "====> Epoch: 105100 Average loss: 16.8638\n",
      "====> Epoch: 105200 Average loss: 16.8637\n",
      "====> Epoch: 105300 Average loss: 16.8635\n",
      "====> Epoch: 105400 Average loss: 16.8634\n",
      "====> Epoch: 105500 Average loss: 16.8634\n",
      "====> Epoch: 105600 Average loss: 16.8637\n",
      "====> Epoch: 105700 Average loss: 16.8638\n",
      "====> Epoch: 105800 Average loss: 16.8640\n",
      "====> Epoch: 105900 Average loss: 16.8643\n",
      "====> Epoch: 106000 Average loss: 16.8646\n",
      "====> Epoch: 106100 Average loss: 16.8643\n",
      "====> Epoch: 106200 Average loss: 16.8640\n",
      "====> Epoch: 106300 Average loss: 16.8640\n",
      "====> Epoch: 106400 Average loss: 16.8639\n",
      "====> Epoch: 106500 Average loss: 16.8637\n",
      "====> Epoch: 106600 Average loss: 16.8638\n",
      "====> Epoch: 106700 Average loss: 16.8643\n",
      "====> Epoch: 106800 Average loss: 16.8645\n",
      "====> Epoch: 106900 Average loss: 16.8645\n",
      "====> Epoch: 107000 Average loss: 16.8647\n",
      "====> Epoch: 107100 Average loss: 16.8646\n",
      "====> Epoch: 107200 Average loss: 16.8644\n",
      "====> Epoch: 107300 Average loss: 16.8643\n",
      "====> Epoch: 107400 Average loss: 16.8642\n",
      "====> Epoch: 107500 Average loss: 16.8641\n",
      "====> Epoch: 107600 Average loss: 16.8640\n",
      "====> Epoch: 107700 Average loss: 16.8642\n",
      "====> Epoch: 107800 Average loss: 16.8645\n",
      "====> Epoch: 107900 Average loss: 16.8647\n",
      "====> Epoch: 108000 Average loss: 16.8643\n",
      "====> Epoch: 108100 Average loss: 16.8636\n",
      "====> Epoch: 108200 Average loss: 16.8632\n",
      "====> Epoch: 108300 Average loss: 16.8632\n",
      "====> Epoch: 108400 Average loss: 16.8635\n",
      "====> Epoch: 108500 Average loss: 16.8638\n",
      "====> Epoch: 108600 Average loss: 16.8644\n",
      "====> Epoch: 108700 Average loss: 16.8640\n",
      "====> Epoch: 108800 Average loss: 16.8637\n",
      "====> Epoch: 108900 Average loss: 16.8634\n",
      "====> Epoch: 109000 Average loss: 16.8635\n",
      "====> Epoch: 109100 Average loss: 16.8633\n",
      "====> Epoch: 109200 Average loss: 16.8632\n",
      "====> Epoch: 109300 Average loss: 16.8633\n",
      "====> Epoch: 109400 Average loss: 16.8634\n",
      "====> Epoch: 109500 Average loss: 16.8630\n",
      "====> Epoch: 109600 Average loss: 16.8631\n",
      "====> Epoch: 109700 Average loss: 16.8628\n",
      "====> Epoch: 109800 Average loss: 16.8630\n",
      "====> Epoch: 109900 Average loss: 16.8630\n",
      "====> Epoch: 110000 Average loss: 16.8626\n",
      "====> Epoch: 110100 Average loss: 16.8627\n",
      "====> Epoch: 110200 Average loss: 16.8627\n",
      "====> Epoch: 110300 Average loss: 16.8624\n",
      "====> Epoch: 110400 Average loss: 16.8628\n",
      "====> Epoch: 110500 Average loss: 16.8627\n",
      "====> Epoch: 110600 Average loss: 16.8624\n",
      "====> Epoch: 110700 Average loss: 16.8622\n",
      "====> Epoch: 110800 Average loss: 16.8623\n",
      "====> Epoch: 110900 Average loss: 16.8625\n",
      "====> Epoch: 111000 Average loss: 16.8625\n",
      "====> Epoch: 111100 Average loss: 16.8622\n",
      "====> Epoch: 111200 Average loss: 16.8623\n",
      "====> Epoch: 111300 Average loss: 16.8624\n",
      "====> Epoch: 111400 Average loss: 16.8623\n",
      "====> Epoch: 111500 Average loss: 16.8622\n",
      "====> Epoch: 111600 Average loss: 16.8622\n",
      "====> Epoch: 111700 Average loss: 16.8625\n",
      "====> Epoch: 111800 Average loss: 16.8627\n",
      "====> Epoch: 111900 Average loss: 16.8627\n",
      "====> Epoch: 112000 Average loss: 16.8626\n",
      "====> Epoch: 112100 Average loss: 16.8625\n",
      "====> Epoch: 112200 Average loss: 16.8626\n",
      "====> Epoch: 112300 Average loss: 16.8623\n",
      "====> Epoch: 112400 Average loss: 16.8621\n",
      "====> Epoch: 112500 Average loss: 16.8622\n",
      "====> Epoch: 112600 Average loss: 16.8623\n",
      "====> Epoch: 112700 Average loss: 16.8624\n",
      "====> Epoch: 112800 Average loss: 16.8624\n",
      "====> Epoch: 112900 Average loss: 16.8626\n",
      "====> Epoch: 113000 Average loss: 16.8623\n",
      "====> Epoch: 113100 Average loss: 16.8623\n",
      "====> Epoch: 113200 Average loss: 16.8621\n",
      "====> Epoch: 113300 Average loss: 16.8621\n",
      "====> Epoch: 113400 Average loss: 16.8618\n",
      "====> Epoch: 113500 Average loss: 16.8616\n",
      "====> Epoch: 113600 Average loss: 16.8618\n",
      "====> Epoch: 113700 Average loss: 16.8618\n",
      "====> Epoch: 113800 Average loss: 16.8621\n",
      "====> Epoch: 113900 Average loss: 16.8620\n",
      "====> Epoch: 114000 Average loss: 16.8617\n",
      "====> Epoch: 114100 Average loss: 16.8615\n",
      "====> Epoch: 114200 Average loss: 16.8613\n",
      "====> Epoch: 114300 Average loss: 16.8611\n",
      "====> Epoch: 114400 Average loss: 16.8614\n",
      "====> Epoch: 114500 Average loss: 16.8613\n",
      "====> Epoch: 114600 Average loss: 16.8613\n",
      "====> Epoch: 114700 Average loss: 16.8610\n",
      "====> Epoch: 114800 Average loss: 16.8610\n",
      "====> Epoch: 114900 Average loss: 16.8610\n",
      "====> Epoch: 115000 Average loss: 16.8613\n",
      "====> Epoch: 115100 Average loss: 16.8612\n",
      "====> Epoch: 115200 Average loss: 16.8612\n",
      "====> Epoch: 115300 Average loss: 16.8611\n",
      "====> Epoch: 115400 Average loss: 16.8608\n",
      "====> Epoch: 115500 Average loss: 16.8609\n",
      "====> Epoch: 115600 Average loss: 16.8609\n",
      "====> Epoch: 115700 Average loss: 16.8610\n",
      "====> Epoch: 115800 Average loss: 16.8610\n",
      "====> Epoch: 115900 Average loss: 16.8606\n",
      "====> Epoch: 116000 Average loss: 16.8605\n",
      "====> Epoch: 116100 Average loss: 16.8603\n",
      "====> Epoch: 116200 Average loss: 16.8606\n",
      "====> Epoch: 116300 Average loss: 16.8606\n",
      "====> Epoch: 116400 Average loss: 16.8606\n",
      "====> Epoch: 116500 Average loss: 16.8605\n",
      "====> Epoch: 116600 Average loss: 16.8604\n",
      "====> Epoch: 116700 Average loss: 16.8604\n",
      "====> Epoch: 116800 Average loss: 16.8605\n",
      "====> Epoch: 116900 Average loss: 16.8607\n",
      "====> Epoch: 117000 Average loss: 16.8608\n",
      "====> Epoch: 117100 Average loss: 16.8607\n",
      "====> Epoch: 117200 Average loss: 16.8605\n",
      "====> Epoch: 117300 Average loss: 16.8604\n",
      "====> Epoch: 117400 Average loss: 16.8606\n",
      "====> Epoch: 117500 Average loss: 16.8607\n",
      "====> Epoch: 117600 Average loss: 16.8607\n",
      "====> Epoch: 117700 Average loss: 16.8604\n",
      "====> Epoch: 117800 Average loss: 16.8603\n",
      "====> Epoch: 117900 Average loss: 16.8601\n",
      "====> Epoch: 118000 Average loss: 16.8600\n",
      "====> Epoch: 118100 Average loss: 16.8599\n",
      "====> Epoch: 118200 Average loss: 16.8598\n",
      "====> Epoch: 118300 Average loss: 16.8599\n",
      "====> Epoch: 118400 Average loss: 16.8599\n",
      "====> Epoch: 118500 Average loss: 16.8598\n",
      "====> Epoch: 118600 Average loss: 16.8598\n",
      "====> Epoch: 118700 Average loss: 16.8598\n",
      "====> Epoch: 118800 Average loss: 16.8598\n",
      "====> Epoch: 118900 Average loss: 16.8600\n",
      "====> Epoch: 119000 Average loss: 16.8600\n",
      "====> Epoch: 119100 Average loss: 16.8603\n",
      "====> Epoch: 119200 Average loss: 16.8599\n",
      "====> Epoch: 119300 Average loss: 16.8603\n",
      "====> Epoch: 119400 Average loss: 16.8601\n",
      "====> Epoch: 119500 Average loss: 16.8603\n",
      "====> Epoch: 119600 Average loss: 16.8604\n",
      "====> Epoch: 119700 Average loss: 16.8606\n",
      "====> Epoch: 119800 Average loss: 16.8604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 119900 Average loss: 16.8604\n",
      "====> Epoch: 120000 Average loss: 16.8602\n",
      "====> Epoch: 120100 Average loss: 16.8603\n",
      "====> Epoch: 120200 Average loss: 16.8605\n",
      "====> Epoch: 120300 Average loss: 16.8601\n",
      "====> Epoch: 120400 Average loss: 16.8602\n",
      "====> Epoch: 120500 Average loss: 16.8602\n",
      "====> Epoch: 120600 Average loss: 16.8601\n",
      "====> Epoch: 120700 Average loss: 16.8599\n",
      "====> Epoch: 120800 Average loss: 16.8602\n",
      "====> Epoch: 120900 Average loss: 16.8603\n",
      "====> Epoch: 121000 Average loss: 16.8604\n",
      "====> Epoch: 121100 Average loss: 16.8606\n",
      "====> Epoch: 121200 Average loss: 16.8608\n",
      "====> Epoch: 121300 Average loss: 16.8608\n",
      "====> Epoch: 121400 Average loss: 16.8608\n",
      "====> Epoch: 121500 Average loss: 16.8607\n",
      "====> Epoch: 121600 Average loss: 16.8605\n",
      "====> Epoch: 121700 Average loss: 16.8605\n",
      "====> Epoch: 121800 Average loss: 16.8603\n",
      "====> Epoch: 121900 Average loss: 16.8604\n",
      "====> Epoch: 122000 Average loss: 16.8606\n",
      "====> Epoch: 122100 Average loss: 16.8603\n",
      "====> Epoch: 122200 Average loss: 16.8605\n",
      "====> Epoch: 122300 Average loss: 16.8608\n",
      "====> Epoch: 122400 Average loss: 16.8605\n",
      "====> Epoch: 122500 Average loss: 16.8602\n",
      "====> Epoch: 122600 Average loss: 16.8605\n",
      "====> Epoch: 122700 Average loss: 16.8602\n",
      "====> Epoch: 122800 Average loss: 16.8603\n",
      "====> Epoch: 122900 Average loss: 16.8601\n",
      "====> Epoch: 123000 Average loss: 16.8600\n",
      "====> Epoch: 123100 Average loss: 16.8600\n",
      "====> Epoch: 123200 Average loss: 16.8599\n",
      "====> Epoch: 123300 Average loss: 16.8599\n",
      "====> Epoch: 123400 Average loss: 16.8598\n",
      "====> Epoch: 123500 Average loss: 16.8595\n",
      "====> Epoch: 123600 Average loss: 16.8596\n",
      "====> Epoch: 123700 Average loss: 16.8596\n",
      "====> Epoch: 123800 Average loss: 16.8598\n",
      "====> Epoch: 123900 Average loss: 16.8596\n",
      "====> Epoch: 124000 Average loss: 16.8595\n",
      "====> Epoch: 124100 Average loss: 16.8593\n",
      "====> Epoch: 124200 Average loss: 16.8593\n",
      "====> Epoch: 124300 Average loss: 16.8593\n",
      "====> Epoch: 124400 Average loss: 16.8594\n",
      "====> Epoch: 124500 Average loss: 16.8595\n",
      "====> Epoch: 124600 Average loss: 16.8595\n",
      "====> Epoch: 124700 Average loss: 16.8592\n",
      "====> Epoch: 124800 Average loss: 16.8589\n",
      "====> Epoch: 124900 Average loss: 16.8590\n",
      "====> Epoch: 125000 Average loss: 16.8591\n",
      "====> Epoch: 125100 Average loss: 16.8596\n",
      "====> Epoch: 125200 Average loss: 16.8597\n",
      "====> Epoch: 125300 Average loss: 16.8598\n",
      "====> Epoch: 125400 Average loss: 16.8601\n",
      "====> Epoch: 125500 Average loss: 16.8599\n",
      "====> Epoch: 125600 Average loss: 16.8601\n",
      "====> Epoch: 125700 Average loss: 16.8600\n",
      "====> Epoch: 125800 Average loss: 16.8600\n",
      "====> Epoch: 125900 Average loss: 16.8599\n",
      "====> Epoch: 126000 Average loss: 16.8599\n",
      "====> Epoch: 126100 Average loss: 16.8600\n",
      "====> Epoch: 126200 Average loss: 16.8601\n",
      "====> Epoch: 126300 Average loss: 16.8600\n",
      "====> Epoch: 126400 Average loss: 16.8600\n",
      "====> Epoch: 126500 Average loss: 16.8604\n",
      "====> Epoch: 126600 Average loss: 16.8606\n",
      "====> Epoch: 126700 Average loss: 16.8606\n",
      "====> Epoch: 126800 Average loss: 16.8608\n",
      "====> Epoch: 126900 Average loss: 16.8611\n",
      "====> Epoch: 127000 Average loss: 16.8609\n",
      "====> Epoch: 127100 Average loss: 16.8608\n",
      "====> Epoch: 127200 Average loss: 16.8605\n",
      "====> Epoch: 127300 Average loss: 16.8604\n",
      "====> Epoch: 127400 Average loss: 16.8603\n",
      "====> Epoch: 127500 Average loss: 16.8602\n",
      "====> Epoch: 127600 Average loss: 16.8602\n",
      "====> Epoch: 127700 Average loss: 16.8603\n",
      "====> Epoch: 127800 Average loss: 16.8600\n",
      "====> Epoch: 127900 Average loss: 16.8601\n",
      "====> Epoch: 128000 Average loss: 16.8600\n",
      "====> Epoch: 128100 Average loss: 16.8593\n",
      "====> Epoch: 128200 Average loss: 16.8592\n",
      "====> Epoch: 128300 Average loss: 16.8592\n",
      "====> Epoch: 128400 Average loss: 16.8592\n",
      "====> Epoch: 128500 Average loss: 16.8593\n",
      "====> Epoch: 128600 Average loss: 16.8591\n",
      "====> Epoch: 128700 Average loss: 16.8590\n",
      "====> Epoch: 128800 Average loss: 16.8590\n",
      "====> Epoch: 128900 Average loss: 16.8593\n",
      "====> Epoch: 129000 Average loss: 16.8590\n",
      "====> Epoch: 129100 Average loss: 16.8590\n",
      "====> Epoch: 129200 Average loss: 16.8587\n",
      "====> Epoch: 129300 Average loss: 16.8585\n",
      "====> Epoch: 129400 Average loss: 16.8586\n",
      "====> Epoch: 129500 Average loss: 16.8580\n",
      "====> Epoch: 129600 Average loss: 16.8578\n",
      "====> Epoch: 129700 Average loss: 16.8577\n",
      "====> Epoch: 129800 Average loss: 16.8579\n",
      "====> Epoch: 129900 Average loss: 16.8579\n",
      "====> Epoch: 130000 Average loss: 16.8578\n",
      "====> Epoch: 130100 Average loss: 16.8580\n",
      "====> Epoch: 130200 Average loss: 16.8581\n",
      "====> Epoch: 130300 Average loss: 16.8578\n",
      "====> Epoch: 130400 Average loss: 16.8577\n",
      "====> Epoch: 130500 Average loss: 16.8579\n",
      "====> Epoch: 130600 Average loss: 16.8577\n",
      "====> Epoch: 130700 Average loss: 16.8574\n",
      "====> Epoch: 130800 Average loss: 16.8575\n",
      "====> Epoch: 130900 Average loss: 16.8574\n",
      "====> Epoch: 131000 Average loss: 16.8575\n",
      "====> Epoch: 131100 Average loss: 16.8572\n",
      "====> Epoch: 131200 Average loss: 16.8568\n",
      "====> Epoch: 131300 Average loss: 16.8569\n",
      "====> Epoch: 131400 Average loss: 16.8571\n",
      "====> Epoch: 131500 Average loss: 16.8569\n",
      "====> Epoch: 131600 Average loss: 16.8565\n",
      "====> Epoch: 131700 Average loss: 16.8566\n",
      "====> Epoch: 131800 Average loss: 16.8567\n",
      "====> Epoch: 131900 Average loss: 16.8568\n",
      "====> Epoch: 132000 Average loss: 16.8569\n",
      "====> Epoch: 132100 Average loss: 16.8572\n",
      "====> Epoch: 132200 Average loss: 16.8570\n",
      "====> Epoch: 132300 Average loss: 16.8569\n",
      "====> Epoch: 132400 Average loss: 16.8568\n",
      "====> Epoch: 132500 Average loss: 16.8567\n",
      "====> Epoch: 132600 Average loss: 16.8566\n",
      "====> Epoch: 132700 Average loss: 16.8566\n",
      "====> Epoch: 132800 Average loss: 16.8567\n",
      "====> Epoch: 132900 Average loss: 16.8569\n",
      "====> Epoch: 133000 Average loss: 16.8569\n",
      "====> Epoch: 133100 Average loss: 16.8569\n",
      "====> Epoch: 133200 Average loss: 16.8570\n",
      "====> Epoch: 133300 Average loss: 16.8567\n",
      "====> Epoch: 133400 Average loss: 16.8567\n",
      "====> Epoch: 133500 Average loss: 16.8569\n",
      "====> Epoch: 133600 Average loss: 16.8568\n",
      "====> Epoch: 133700 Average loss: 16.8567\n",
      "====> Epoch: 133800 Average loss: 16.8568\n",
      "====> Epoch: 133900 Average loss: 16.8567\n",
      "====> Epoch: 134000 Average loss: 16.8571\n",
      "====> Epoch: 134100 Average loss: 16.8575\n",
      "====> Epoch: 134200 Average loss: 16.8575\n",
      "====> Epoch: 134300 Average loss: 16.8577\n",
      "====> Epoch: 134400 Average loss: 16.8575\n",
      "====> Epoch: 134500 Average loss: 16.8571\n",
      "====> Epoch: 134600 Average loss: 16.8571\n",
      "====> Epoch: 134700 Average loss: 16.8572\n",
      "====> Epoch: 134800 Average loss: 16.8570\n",
      "====> Epoch: 134900 Average loss: 16.8565\n",
      "====> Epoch: 135000 Average loss: 16.8564\n",
      "====> Epoch: 135100 Average loss: 16.8562\n",
      "====> Epoch: 135200 Average loss: 16.8563\n",
      "====> Epoch: 135300 Average loss: 16.8559\n",
      "====> Epoch: 135400 Average loss: 16.8558\n",
      "====> Epoch: 135500 Average loss: 16.8559\n",
      "====> Epoch: 135600 Average loss: 16.8562\n",
      "====> Epoch: 135700 Average loss: 16.8564\n",
      "====> Epoch: 135800 Average loss: 16.8562\n",
      "====> Epoch: 135900 Average loss: 16.8564\n",
      "====> Epoch: 136000 Average loss: 16.8561\n",
      "====> Epoch: 136100 Average loss: 16.8562\n",
      "====> Epoch: 136200 Average loss: 16.8561\n",
      "====> Epoch: 136300 Average loss: 16.8562\n",
      "====> Epoch: 136400 Average loss: 16.8562\n",
      "====> Epoch: 136500 Average loss: 16.8562\n",
      "====> Epoch: 136600 Average loss: 16.8561\n",
      "====> Epoch: 136700 Average loss: 16.8565\n",
      "====> Epoch: 136800 Average loss: 16.8566\n",
      "====> Epoch: 136900 Average loss: 16.8561\n",
      "====> Epoch: 137000 Average loss: 16.8562\n",
      "====> Epoch: 137100 Average loss: 16.8561\n",
      "====> Epoch: 137200 Average loss: 16.8560\n",
      "====> Epoch: 137300 Average loss: 16.8559\n",
      "====> Epoch: 137400 Average loss: 16.8556\n",
      "====> Epoch: 137500 Average loss: 16.8555\n",
      "====> Epoch: 137600 Average loss: 16.8554\n",
      "====> Epoch: 137700 Average loss: 16.8551\n",
      "====> Epoch: 137800 Average loss: 16.8548\n",
      "====> Epoch: 137900 Average loss: 16.8545\n",
      "====> Epoch: 138000 Average loss: 16.8550\n",
      "====> Epoch: 138100 Average loss: 16.8550\n",
      "====> Epoch: 138200 Average loss: 16.8550\n",
      "====> Epoch: 138300 Average loss: 16.8551\n",
      "====> Epoch: 138400 Average loss: 16.8549\n",
      "====> Epoch: 138500 Average loss: 16.8547\n",
      "====> Epoch: 138600 Average loss: 16.8545\n",
      "====> Epoch: 138700 Average loss: 16.8544\n",
      "====> Epoch: 138800 Average loss: 16.8545\n",
      "====> Epoch: 138900 Average loss: 16.8541\n",
      "====> Epoch: 139000 Average loss: 16.8542\n",
      "====> Epoch: 139100 Average loss: 16.8542\n",
      "====> Epoch: 139200 Average loss: 16.8541\n",
      "====> Epoch: 139300 Average loss: 16.8541\n",
      "====> Epoch: 139400 Average loss: 16.8540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 139500 Average loss: 16.8538\n",
      "====> Epoch: 139600 Average loss: 16.8537\n",
      "====> Epoch: 139700 Average loss: 16.8539\n",
      "====> Epoch: 139800 Average loss: 16.8538\n",
      "====> Epoch: 139900 Average loss: 16.8538\n",
      "====> Epoch: 140000 Average loss: 16.8540\n",
      "====> Epoch: 140100 Average loss: 16.8539\n",
      "====> Epoch: 140200 Average loss: 16.8537\n",
      "====> Epoch: 140300 Average loss: 16.8538\n",
      "====> Epoch: 140400 Average loss: 16.8538\n",
      "====> Epoch: 140500 Average loss: 16.8537\n",
      "====> Epoch: 140600 Average loss: 16.8537\n",
      "====> Epoch: 140700 Average loss: 16.8535\n",
      "====> Epoch: 140800 Average loss: 16.8536\n",
      "====> Epoch: 140900 Average loss: 16.8530\n",
      "====> Epoch: 141000 Average loss: 16.8530\n",
      "====> Epoch: 141100 Average loss: 16.8528\n",
      "====> Epoch: 141200 Average loss: 16.8525\n",
      "====> Epoch: 141300 Average loss: 16.8525\n",
      "====> Epoch: 141400 Average loss: 16.8525\n",
      "====> Epoch: 141500 Average loss: 16.8528\n",
      "====> Epoch: 141600 Average loss: 16.8529\n",
      "====> Epoch: 141700 Average loss: 16.8528\n",
      "====> Epoch: 141800 Average loss: 16.8527\n",
      "====> Epoch: 141900 Average loss: 16.8525\n",
      "====> Epoch: 142000 Average loss: 16.8525\n",
      "====> Epoch: 142100 Average loss: 16.8526\n",
      "====> Epoch: 142200 Average loss: 16.8527\n",
      "====> Epoch: 142300 Average loss: 16.8529\n",
      "====> Epoch: 142400 Average loss: 16.8529\n",
      "====> Epoch: 142500 Average loss: 16.8527\n",
      "====> Epoch: 142600 Average loss: 16.8525\n",
      "====> Epoch: 142700 Average loss: 16.8522\n",
      "====> Epoch: 142800 Average loss: 16.8523\n",
      "====> Epoch: 142900 Average loss: 16.8522\n",
      "====> Epoch: 143000 Average loss: 16.8520\n",
      "====> Epoch: 143100 Average loss: 16.8516\n",
      "====> Epoch: 143200 Average loss: 16.8515\n",
      "====> Epoch: 143300 Average loss: 16.8516\n",
      "====> Epoch: 143400 Average loss: 16.8515\n",
      "====> Epoch: 143500 Average loss: 16.8518\n",
      "====> Epoch: 143600 Average loss: 16.8518\n",
      "====> Epoch: 143700 Average loss: 16.8520\n",
      "====> Epoch: 143800 Average loss: 16.8521\n",
      "====> Epoch: 143900 Average loss: 16.8520\n",
      "====> Epoch: 144000 Average loss: 16.8519\n",
      "====> Epoch: 144100 Average loss: 16.8520\n",
      "====> Epoch: 144200 Average loss: 16.8519\n",
      "====> Epoch: 144300 Average loss: 16.8519\n",
      "====> Epoch: 144400 Average loss: 16.8519\n",
      "====> Epoch: 144500 Average loss: 16.8517\n",
      "====> Epoch: 144600 Average loss: 16.8516\n",
      "====> Epoch: 144700 Average loss: 16.8518\n",
      "====> Epoch: 144800 Average loss: 16.8515\n",
      "====> Epoch: 144900 Average loss: 16.8516\n",
      "====> Epoch: 145000 Average loss: 16.8515\n",
      "====> Epoch: 145100 Average loss: 16.8517\n",
      "====> Epoch: 145200 Average loss: 16.8518\n",
      "====> Epoch: 145300 Average loss: 16.8518\n",
      "====> Epoch: 145400 Average loss: 16.8518\n",
      "====> Epoch: 145500 Average loss: 16.8516\n",
      "====> Epoch: 145600 Average loss: 16.8514\n",
      "====> Epoch: 145700 Average loss: 16.8518\n",
      "====> Epoch: 145800 Average loss: 16.8517\n",
      "====> Epoch: 145900 Average loss: 16.8516\n",
      "====> Epoch: 146000 Average loss: 16.8517\n",
      "====> Epoch: 146100 Average loss: 16.8519\n",
      "====> Epoch: 146200 Average loss: 16.8519\n",
      "====> Epoch: 146300 Average loss: 16.8518\n",
      "====> Epoch: 146400 Average loss: 16.8517\n",
      "====> Epoch: 146500 Average loss: 16.8515\n",
      "====> Epoch: 146600 Average loss: 16.8516\n",
      "====> Epoch: 146700 Average loss: 16.8516\n",
      "====> Epoch: 146800 Average loss: 16.8517\n",
      "====> Epoch: 146900 Average loss: 16.8519\n",
      "====> Epoch: 147000 Average loss: 16.8516\n",
      "====> Epoch: 147100 Average loss: 16.8516\n",
      "====> Epoch: 147200 Average loss: 16.8517\n",
      "====> Epoch: 147300 Average loss: 16.8514\n",
      "====> Epoch: 147400 Average loss: 16.8515\n",
      "====> Epoch: 147500 Average loss: 16.8517\n",
      "====> Epoch: 147600 Average loss: 16.8515\n",
      "====> Epoch: 147700 Average loss: 16.8511\n",
      "====> Epoch: 147800 Average loss: 16.8510\n",
      "====> Epoch: 147900 Average loss: 16.8508\n",
      "====> Epoch: 148000 Average loss: 16.8506\n",
      "====> Epoch: 148100 Average loss: 16.8503\n",
      "====> Epoch: 148200 Average loss: 16.8501\n",
      "====> Epoch: 148300 Average loss: 16.8502\n",
      "====> Epoch: 148400 Average loss: 16.8498\n",
      "====> Epoch: 148500 Average loss: 16.8498\n",
      "====> Epoch: 148600 Average loss: 16.8497\n",
      "====> Epoch: 148700 Average loss: 16.8497\n",
      "====> Epoch: 148800 Average loss: 16.8499\n",
      "====> Epoch: 148900 Average loss: 16.8497\n",
      "====> Epoch: 149000 Average loss: 16.8495\n",
      "====> Epoch: 149100 Average loss: 16.8497\n",
      "====> Epoch: 149200 Average loss: 16.8498\n",
      "====> Epoch: 149300 Average loss: 16.8499\n",
      "====> Epoch: 149400 Average loss: 16.8499\n",
      "====> Epoch: 149500 Average loss: 16.8497\n",
      "====> Epoch: 149600 Average loss: 16.8498\n",
      "====> Epoch: 149700 Average loss: 16.8501\n",
      "====> Epoch: 149800 Average loss: 16.8500\n",
      "====> Epoch: 149900 Average loss: 16.8499\n",
      "====> Epoch: 150000 Average loss: 16.8501\n",
      "====> Epoch: 150100 Average loss: 16.8500\n",
      "====> Epoch: 150200 Average loss: 16.8500\n",
      "====> Epoch: 150300 Average loss: 16.8498\n",
      "====> Epoch: 150400 Average loss: 16.8498\n",
      "====> Epoch: 150500 Average loss: 16.8499\n",
      "====> Epoch: 150600 Average loss: 16.8499\n",
      "====> Epoch: 150700 Average loss: 16.8498\n",
      "====> Epoch: 150800 Average loss: 16.8497\n",
      "====> Epoch: 150900 Average loss: 16.8495\n",
      "====> Epoch: 151000 Average loss: 16.8494\n",
      "====> Epoch: 151100 Average loss: 16.8493\n",
      "====> Epoch: 151200 Average loss: 16.8493\n",
      "====> Epoch: 151300 Average loss: 16.8493\n",
      "====> Epoch: 151400 Average loss: 16.8494\n",
      "====> Epoch: 151500 Average loss: 16.8493\n",
      "====> Epoch: 151600 Average loss: 16.8493\n",
      "====> Epoch: 151700 Average loss: 16.8490\n",
      "====> Epoch: 151800 Average loss: 16.8490\n",
      "====> Epoch: 151900 Average loss: 16.8490\n",
      "====> Epoch: 152000 Average loss: 16.8492\n",
      "====> Epoch: 152100 Average loss: 16.8491\n",
      "====> Epoch: 152200 Average loss: 16.8491\n",
      "====> Epoch: 152300 Average loss: 16.8491\n",
      "====> Epoch: 152400 Average loss: 16.8490\n",
      "====> Epoch: 152500 Average loss: 16.8490\n",
      "====> Epoch: 152600 Average loss: 16.8489\n",
      "====> Epoch: 152700 Average loss: 16.8490\n",
      "====> Epoch: 152800 Average loss: 16.8488\n",
      "====> Epoch: 152900 Average loss: 16.8492\n",
      "====> Epoch: 153000 Average loss: 16.8494\n",
      "====> Epoch: 153100 Average loss: 16.8497\n",
      "====> Epoch: 153200 Average loss: 16.8498\n",
      "====> Epoch: 153300 Average loss: 16.8497\n",
      "====> Epoch: 153400 Average loss: 16.8495\n",
      "====> Epoch: 153500 Average loss: 16.8496\n",
      "====> Epoch: 153600 Average loss: 16.8496\n",
      "====> Epoch: 153700 Average loss: 16.8496\n",
      "====> Epoch: 153800 Average loss: 16.8491\n",
      "====> Epoch: 153900 Average loss: 16.8491\n",
      "====> Epoch: 154000 Average loss: 16.8490\n",
      "====> Epoch: 154100 Average loss: 16.8490\n",
      "====> Epoch: 154200 Average loss: 16.8487\n",
      "====> Epoch: 154300 Average loss: 16.8489\n",
      "====> Epoch: 154400 Average loss: 16.8489\n",
      "====> Epoch: 154500 Average loss: 16.8488\n",
      "====> Epoch: 154600 Average loss: 16.8491\n",
      "====> Epoch: 154700 Average loss: 16.8494\n",
      "====> Epoch: 154800 Average loss: 16.8496\n",
      "====> Epoch: 154900 Average loss: 16.8496\n",
      "====> Epoch: 155000 Average loss: 16.8497\n",
      "====> Epoch: 155100 Average loss: 16.8499\n",
      "====> Epoch: 155200 Average loss: 16.8499\n",
      "====> Epoch: 155300 Average loss: 16.8499\n",
      "====> Epoch: 155400 Average loss: 16.8501\n",
      "====> Epoch: 155500 Average loss: 16.8499\n",
      "====> Epoch: 155600 Average loss: 16.8502\n",
      "====> Epoch: 155700 Average loss: 16.8502\n",
      "====> Epoch: 155800 Average loss: 16.8503\n",
      "====> Epoch: 155900 Average loss: 16.8503\n",
      "====> Epoch: 156000 Average loss: 16.8503\n",
      "====> Epoch: 156100 Average loss: 16.8504\n",
      "====> Epoch: 156200 Average loss: 16.8502\n",
      "====> Epoch: 156300 Average loss: 16.8498\n",
      "====> Epoch: 156400 Average loss: 16.8498\n",
      "====> Epoch: 156500 Average loss: 16.8499\n",
      "====> Epoch: 156600 Average loss: 16.8501\n",
      "====> Epoch: 156700 Average loss: 16.8500\n",
      "====> Epoch: 156800 Average loss: 16.8500\n",
      "====> Epoch: 156900 Average loss: 16.8500\n",
      "====> Epoch: 157000 Average loss: 16.8500\n",
      "====> Epoch: 157100 Average loss: 16.8500\n",
      "====> Epoch: 157200 Average loss: 16.8501\n",
      "====> Epoch: 157300 Average loss: 16.8500\n",
      "====> Epoch: 157400 Average loss: 16.8500\n",
      "====> Epoch: 157500 Average loss: 16.8501\n",
      "====> Epoch: 157600 Average loss: 16.8501\n",
      "====> Epoch: 157700 Average loss: 16.8502\n",
      "====> Epoch: 157800 Average loss: 16.8503\n",
      "====> Epoch: 157900 Average loss: 16.8503\n",
      "====> Epoch: 158000 Average loss: 16.8500\n",
      "====> Epoch: 158100 Average loss: 16.8498\n",
      "====> Epoch: 158200 Average loss: 16.8499\n",
      "====> Epoch: 158300 Average loss: 16.8500\n",
      "====> Epoch: 158400 Average loss: 16.8497\n",
      "====> Epoch: 158500 Average loss: 16.8497\n",
      "====> Epoch: 158600 Average loss: 16.8498\n",
      "====> Epoch: 158700 Average loss: 16.8499\n",
      "====> Epoch: 158800 Average loss: 16.8499\n",
      "====> Epoch: 158900 Average loss: 16.8494\n",
      "====> Epoch: 159000 Average loss: 16.8493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 159100 Average loss: 16.8492\n",
      "====> Epoch: 159200 Average loss: 16.8492\n",
      "====> Epoch: 159300 Average loss: 16.8491\n",
      "====> Epoch: 159400 Average loss: 16.8491\n",
      "====> Epoch: 159500 Average loss: 16.8491\n",
      "====> Epoch: 159600 Average loss: 16.8491\n",
      "====> Epoch: 159700 Average loss: 16.8491\n",
      "====> Epoch: 159800 Average loss: 16.8489\n",
      "====> Epoch: 159900 Average loss: 16.8489\n",
      "====> Epoch: 160000 Average loss: 16.8485\n",
      "====> Epoch: 160100 Average loss: 16.8485\n",
      "====> Epoch: 160200 Average loss: 16.8484\n",
      "====> Epoch: 160300 Average loss: 16.8485\n",
      "====> Epoch: 160400 Average loss: 16.8484\n",
      "====> Epoch: 160500 Average loss: 16.8482\n",
      "====> Epoch: 160600 Average loss: 16.8480\n",
      "====> Epoch: 160700 Average loss: 16.8479\n",
      "====> Epoch: 160800 Average loss: 16.8480\n",
      "====> Epoch: 160900 Average loss: 16.8479\n",
      "====> Epoch: 161000 Average loss: 16.8478\n",
      "====> Epoch: 161100 Average loss: 16.8480\n",
      "====> Epoch: 161200 Average loss: 16.8478\n",
      "====> Epoch: 161300 Average loss: 16.8479\n",
      "====> Epoch: 161400 Average loss: 16.8479\n",
      "====> Epoch: 161500 Average loss: 16.8477\n",
      "====> Epoch: 161600 Average loss: 16.8477\n",
      "====> Epoch: 161700 Average loss: 16.8476\n",
      "====> Epoch: 161800 Average loss: 16.8476\n",
      "====> Epoch: 161900 Average loss: 16.8475\n",
      "====> Epoch: 162000 Average loss: 16.8474\n",
      "====> Epoch: 162100 Average loss: 16.8479\n",
      "====> Epoch: 162200 Average loss: 16.8475\n",
      "====> Epoch: 162300 Average loss: 16.8475\n",
      "====> Epoch: 162400 Average loss: 16.8473\n",
      "====> Epoch: 162500 Average loss: 16.8474\n",
      "====> Epoch: 162600 Average loss: 16.8472\n",
      "====> Epoch: 162700 Average loss: 16.8470\n",
      "====> Epoch: 162800 Average loss: 16.8467\n",
      "====> Epoch: 162900 Average loss: 16.8466\n",
      "====> Epoch: 163000 Average loss: 16.8464\n",
      "====> Epoch: 163100 Average loss: 16.8465\n",
      "====> Epoch: 163200 Average loss: 16.8464\n",
      "====> Epoch: 163300 Average loss: 16.8461\n",
      "====> Epoch: 163400 Average loss: 16.8459\n",
      "====> Epoch: 163500 Average loss: 16.8460\n",
      "====> Epoch: 163600 Average loss: 16.8461\n",
      "====> Epoch: 163700 Average loss: 16.8461\n",
      "====> Epoch: 163800 Average loss: 16.8462\n",
      "====> Epoch: 163900 Average loss: 16.8462\n",
      "====> Epoch: 164000 Average loss: 16.8459\n",
      "====> Epoch: 164100 Average loss: 16.8458\n",
      "====> Epoch: 164200 Average loss: 16.8456\n",
      "====> Epoch: 164300 Average loss: 16.8454\n",
      "====> Epoch: 164400 Average loss: 16.8455\n",
      "====> Epoch: 164500 Average loss: 16.8455\n",
      "====> Epoch: 164600 Average loss: 16.8455\n",
      "====> Epoch: 164700 Average loss: 16.8455\n",
      "====> Epoch: 164800 Average loss: 16.8458\n",
      "====> Epoch: 164900 Average loss: 16.8457\n",
      "====> Epoch: 165000 Average loss: 16.8457\n",
      "====> Epoch: 165100 Average loss: 16.8460\n",
      "====> Epoch: 165200 Average loss: 16.8460\n",
      "====> Epoch: 165300 Average loss: 16.8463\n",
      "====> Epoch: 165400 Average loss: 16.8466\n",
      "====> Epoch: 165500 Average loss: 16.8465\n",
      "====> Epoch: 165600 Average loss: 16.8466\n",
      "====> Epoch: 165700 Average loss: 16.8464\n",
      "====> Epoch: 165800 Average loss: 16.8466\n",
      "====> Epoch: 165900 Average loss: 16.8466\n",
      "====> Epoch: 166000 Average loss: 16.8468\n",
      "====> Epoch: 166100 Average loss: 16.8468\n",
      "====> Epoch: 166200 Average loss: 16.8467\n",
      "====> Epoch: 166300 Average loss: 16.8472\n",
      "====> Epoch: 166400 Average loss: 16.8471\n",
      "====> Epoch: 166500 Average loss: 16.8470\n",
      "====> Epoch: 166600 Average loss: 16.8471\n",
      "====> Epoch: 166700 Average loss: 16.8471\n",
      "====> Epoch: 166800 Average loss: 16.8469\n",
      "====> Epoch: 166900 Average loss: 16.8471\n",
      "====> Epoch: 167000 Average loss: 16.8471\n",
      "====> Epoch: 167100 Average loss: 16.8470\n",
      "====> Epoch: 167200 Average loss: 16.8467\n",
      "====> Epoch: 167300 Average loss: 16.8468\n",
      "====> Epoch: 167400 Average loss: 16.8467\n",
      "====> Epoch: 167500 Average loss: 16.8468\n",
      "====> Epoch: 167600 Average loss: 16.8469\n",
      "====> Epoch: 167700 Average loss: 16.8468\n",
      "====> Epoch: 167800 Average loss: 16.8468\n",
      "====> Epoch: 167900 Average loss: 16.8467\n",
      "====> Epoch: 168000 Average loss: 16.8466\n",
      "====> Epoch: 168100 Average loss: 16.8465\n",
      "====> Epoch: 168200 Average loss: 16.8463\n",
      "====> Epoch: 168300 Average loss: 16.8463\n",
      "====> Epoch: 168400 Average loss: 16.8462\n",
      "====> Epoch: 168500 Average loss: 16.8460\n",
      "====> Epoch: 168600 Average loss: 16.8459\n",
      "====> Epoch: 168700 Average loss: 16.8461\n",
      "====> Epoch: 168800 Average loss: 16.8460\n",
      "====> Epoch: 168900 Average loss: 16.8459\n",
      "====> Epoch: 169000 Average loss: 16.8461\n",
      "====> Epoch: 169100 Average loss: 16.8459\n",
      "====> Epoch: 169200 Average loss: 16.8461\n",
      "====> Epoch: 169300 Average loss: 16.8460\n",
      "====> Epoch: 169400 Average loss: 16.8457\n",
      "====> Epoch: 169500 Average loss: 16.8456\n",
      "====> Epoch: 169600 Average loss: 16.8454\n",
      "====> Epoch: 169700 Average loss: 16.8451\n",
      "====> Epoch: 169800 Average loss: 16.8451\n",
      "====> Epoch: 169900 Average loss: 16.8452\n",
      "====> Epoch: 170000 Average loss: 16.8451\n",
      "====> Epoch: 170100 Average loss: 16.8451\n",
      "====> Epoch: 170200 Average loss: 16.8449\n",
      "====> Epoch: 170300 Average loss: 16.8451\n",
      "====> Epoch: 170400 Average loss: 16.8448\n",
      "====> Epoch: 170500 Average loss: 16.8447\n",
      "====> Epoch: 170600 Average loss: 16.8449\n",
      "====> Epoch: 170700 Average loss: 16.8448\n",
      "====> Epoch: 170800 Average loss: 16.8448\n",
      "====> Epoch: 170900 Average loss: 16.8447\n",
      "====> Epoch: 171000 Average loss: 16.8447\n",
      "====> Epoch: 171100 Average loss: 16.8448\n",
      "====> Epoch: 171200 Average loss: 16.8449\n",
      "====> Epoch: 171300 Average loss: 16.8450\n",
      "====> Epoch: 171400 Average loss: 16.8450\n",
      "====> Epoch: 171500 Average loss: 16.8450\n",
      "====> Epoch: 171600 Average loss: 16.8449\n",
      "====> Epoch: 171700 Average loss: 16.8449\n",
      "====> Epoch: 171800 Average loss: 16.8449\n",
      "====> Epoch: 171900 Average loss: 16.8447\n",
      "====> Epoch: 172000 Average loss: 16.8446\n",
      "====> Epoch: 172100 Average loss: 16.8447\n",
      "====> Epoch: 172200 Average loss: 16.8445\n",
      "====> Epoch: 172300 Average loss: 16.8444\n",
      "====> Epoch: 172400 Average loss: 16.8442\n",
      "====> Epoch: 172500 Average loss: 16.8443\n",
      "====> Epoch: 172600 Average loss: 16.8446\n",
      "====> Epoch: 172700 Average loss: 16.8449\n",
      "====> Epoch: 172800 Average loss: 16.8449\n",
      "====> Epoch: 172900 Average loss: 16.8450\n",
      "====> Epoch: 173000 Average loss: 16.8449\n",
      "====> Epoch: 173100 Average loss: 16.8448\n",
      "====> Epoch: 173200 Average loss: 16.8448\n",
      "====> Epoch: 173300 Average loss: 16.8448\n",
      "====> Epoch: 173400 Average loss: 16.8450\n",
      "====> Epoch: 173500 Average loss: 16.8447\n",
      "====> Epoch: 173600 Average loss: 16.8449\n",
      "====> Epoch: 173700 Average loss: 16.8448\n",
      "====> Epoch: 173800 Average loss: 16.8445\n",
      "====> Epoch: 173900 Average loss: 16.8446\n",
      "====> Epoch: 174000 Average loss: 16.8443\n",
      "====> Epoch: 174100 Average loss: 16.8442\n",
      "====> Epoch: 174200 Average loss: 16.8443\n",
      "====> Epoch: 174300 Average loss: 16.8442\n",
      "====> Epoch: 174400 Average loss: 16.8442\n",
      "====> Epoch: 174500 Average loss: 16.8445\n",
      "====> Epoch: 174600 Average loss: 16.8442\n",
      "====> Epoch: 174700 Average loss: 16.8441\n",
      "====> Epoch: 174800 Average loss: 16.8443\n",
      "====> Epoch: 174900 Average loss: 16.8442\n",
      "====> Epoch: 175000 Average loss: 16.8442\n",
      "====> Epoch: 175100 Average loss: 16.8441\n",
      "====> Epoch: 175200 Average loss: 16.8439\n",
      "====> Epoch: 175300 Average loss: 16.8439\n",
      "====> Epoch: 175400 Average loss: 16.8439\n",
      "====> Epoch: 175500 Average loss: 16.8439\n",
      "====> Epoch: 175600 Average loss: 16.8441\n",
      "====> Epoch: 175700 Average loss: 16.8438\n",
      "====> Epoch: 175800 Average loss: 16.8439\n",
      "====> Epoch: 175900 Average loss: 16.8439\n",
      "====> Epoch: 176000 Average loss: 16.8438\n",
      "====> Epoch: 176100 Average loss: 16.8438\n",
      "====> Epoch: 176200 Average loss: 16.8436\n",
      "====> Epoch: 176300 Average loss: 16.8436\n",
      "====> Epoch: 176400 Average loss: 16.8435\n",
      "====> Epoch: 176500 Average loss: 16.8435\n",
      "====> Epoch: 176600 Average loss: 16.8435\n",
      "====> Epoch: 176700 Average loss: 16.8436\n",
      "====> Epoch: 176800 Average loss: 16.8435\n",
      "====> Epoch: 176900 Average loss: 16.8436\n",
      "====> Epoch: 177000 Average loss: 16.8436\n",
      "====> Epoch: 177100 Average loss: 16.8435\n",
      "====> Epoch: 177200 Average loss: 16.8437\n",
      "====> Epoch: 177300 Average loss: 16.8438\n",
      "====> Epoch: 177400 Average loss: 16.8435\n",
      "====> Epoch: 177500 Average loss: 16.8436\n",
      "====> Epoch: 177600 Average loss: 16.8434\n",
      "====> Epoch: 177700 Average loss: 16.8431\n",
      "====> Epoch: 177800 Average loss: 16.8431\n",
      "====> Epoch: 177900 Average loss: 16.8433\n",
      "====> Epoch: 178000 Average loss: 16.8433\n",
      "====> Epoch: 178100 Average loss: 16.8434\n",
      "====> Epoch: 178200 Average loss: 16.8432\n",
      "====> Epoch: 178300 Average loss: 16.8431\n",
      "====> Epoch: 178400 Average loss: 16.8434\n",
      "====> Epoch: 178500 Average loss: 16.8433\n",
      "====> Epoch: 178600 Average loss: 16.8433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 178700 Average loss: 16.8430\n",
      "====> Epoch: 178800 Average loss: 16.8428\n",
      "====> Epoch: 178900 Average loss: 16.8429\n",
      "====> Epoch: 179000 Average loss: 16.8429\n",
      "====> Epoch: 179100 Average loss: 16.8426\n",
      "====> Epoch: 179200 Average loss: 16.8424\n",
      "====> Epoch: 179300 Average loss: 16.8424\n",
      "====> Epoch: 179400 Average loss: 16.8424\n",
      "====> Epoch: 179500 Average loss: 16.8425\n",
      "====> Epoch: 179600 Average loss: 16.8425\n",
      "====> Epoch: 179700 Average loss: 16.8421\n",
      "====> Epoch: 179800 Average loss: 16.8418\n",
      "====> Epoch: 179900 Average loss: 16.8420\n",
      "====> Epoch: 180000 Average loss: 16.8419\n",
      "====> Epoch: 180100 Average loss: 16.8423\n",
      "====> Epoch: 180200 Average loss: 16.8423\n",
      "====> Epoch: 180300 Average loss: 16.8423\n",
      "====> Epoch: 180400 Average loss: 16.8423\n",
      "====> Epoch: 180500 Average loss: 16.8421\n",
      "====> Epoch: 180600 Average loss: 16.8421\n",
      "====> Epoch: 180700 Average loss: 16.8423\n",
      "====> Epoch: 180800 Average loss: 16.8420\n",
      "====> Epoch: 180900 Average loss: 16.8421\n",
      "====> Epoch: 181000 Average loss: 16.8421\n",
      "====> Epoch: 181100 Average loss: 16.8421\n",
      "====> Epoch: 181200 Average loss: 16.8419\n",
      "====> Epoch: 181300 Average loss: 16.8419\n",
      "====> Epoch: 181400 Average loss: 16.8418\n",
      "====> Epoch: 181500 Average loss: 16.8416\n",
      "====> Epoch: 181600 Average loss: 16.8416\n",
      "====> Epoch: 181700 Average loss: 16.8418\n",
      "====> Epoch: 181800 Average loss: 16.8420\n",
      "====> Epoch: 181900 Average loss: 16.8421\n",
      "====> Epoch: 182000 Average loss: 16.8420\n",
      "====> Epoch: 182100 Average loss: 16.8422\n",
      "====> Epoch: 182200 Average loss: 16.8423\n",
      "====> Epoch: 182300 Average loss: 16.8422\n",
      "====> Epoch: 182400 Average loss: 16.8420\n",
      "====> Epoch: 182500 Average loss: 16.8416\n",
      "====> Epoch: 182600 Average loss: 16.8417\n",
      "====> Epoch: 182700 Average loss: 16.8419\n",
      "====> Epoch: 182800 Average loss: 16.8419\n",
      "====> Epoch: 182900 Average loss: 16.8417\n",
      "====> Epoch: 183000 Average loss: 16.8418\n",
      "====> Epoch: 183100 Average loss: 16.8418\n",
      "====> Epoch: 183200 Average loss: 16.8418\n",
      "====> Epoch: 183300 Average loss: 16.8417\n",
      "====> Epoch: 183400 Average loss: 16.8416\n",
      "====> Epoch: 183500 Average loss: 16.8417\n",
      "====> Epoch: 183600 Average loss: 16.8415\n",
      "====> Epoch: 183700 Average loss: 16.8415\n",
      "====> Epoch: 183800 Average loss: 16.8417\n",
      "====> Epoch: 183900 Average loss: 16.8416\n",
      "====> Epoch: 184000 Average loss: 16.8415\n",
      "====> Epoch: 184100 Average loss: 16.8416\n",
      "====> Epoch: 184200 Average loss: 16.8414\n",
      "====> Epoch: 184300 Average loss: 16.8415\n",
      "====> Epoch: 184400 Average loss: 16.8414\n",
      "====> Epoch: 184500 Average loss: 16.8412\n",
      "====> Epoch: 184600 Average loss: 16.8410\n",
      "====> Epoch: 184700 Average loss: 16.8412\n",
      "====> Epoch: 184800 Average loss: 16.8410\n",
      "====> Epoch: 184900 Average loss: 16.8412\n",
      "====> Epoch: 185000 Average loss: 16.8411\n",
      "====> Epoch: 185100 Average loss: 16.8410\n",
      "====> Epoch: 185200 Average loss: 16.8411\n",
      "====> Epoch: 185300 Average loss: 16.8409\n",
      "====> Epoch: 185400 Average loss: 16.8407\n",
      "====> Epoch: 185500 Average loss: 16.8407\n",
      "====> Epoch: 185600 Average loss: 16.8407\n",
      "====> Epoch: 185700 Average loss: 16.8409\n",
      "====> Epoch: 185800 Average loss: 16.8407\n",
      "====> Epoch: 185900 Average loss: 16.8404\n",
      "====> Epoch: 186000 Average loss: 16.8404\n",
      "====> Epoch: 186100 Average loss: 16.8403\n",
      "====> Epoch: 186200 Average loss: 16.8405\n",
      "====> Epoch: 186300 Average loss: 16.8408\n",
      "====> Epoch: 186400 Average loss: 16.8407\n",
      "====> Epoch: 186500 Average loss: 16.8407\n",
      "====> Epoch: 186600 Average loss: 16.8406\n",
      "====> Epoch: 186700 Average loss: 16.8405\n",
      "====> Epoch: 186800 Average loss: 16.8404\n",
      "====> Epoch: 186900 Average loss: 16.8406\n",
      "====> Epoch: 187000 Average loss: 16.8404\n",
      "====> Epoch: 187100 Average loss: 16.8403\n",
      "====> Epoch: 187200 Average loss: 16.8402\n",
      "====> Epoch: 187300 Average loss: 16.8404\n",
      "====> Epoch: 187400 Average loss: 16.8403\n",
      "====> Epoch: 187500 Average loss: 16.8403\n",
      "====> Epoch: 187600 Average loss: 16.8401\n",
      "====> Epoch: 187700 Average loss: 16.8400\n",
      "====> Epoch: 187800 Average loss: 16.8398\n",
      "====> Epoch: 187900 Average loss: 16.8398\n",
      "====> Epoch: 188000 Average loss: 16.8397\n",
      "====> Epoch: 188100 Average loss: 16.8399\n",
      "====> Epoch: 188200 Average loss: 16.8400\n",
      "====> Epoch: 188300 Average loss: 16.8400\n",
      "====> Epoch: 188400 Average loss: 16.8401\n",
      "====> Epoch: 188500 Average loss: 16.8402\n",
      "====> Epoch: 188600 Average loss: 16.8401\n",
      "====> Epoch: 188700 Average loss: 16.8401\n",
      "====> Epoch: 188800 Average loss: 16.8403\n",
      "====> Epoch: 188900 Average loss: 16.8402\n",
      "====> Epoch: 189000 Average loss: 16.8401\n",
      "====> Epoch: 189100 Average loss: 16.8403\n",
      "====> Epoch: 189200 Average loss: 16.8400\n",
      "====> Epoch: 189300 Average loss: 16.8397\n",
      "====> Epoch: 189400 Average loss: 16.8400\n",
      "====> Epoch: 189500 Average loss: 16.8400\n",
      "====> Epoch: 189600 Average loss: 16.8401\n",
      "====> Epoch: 189700 Average loss: 16.8400\n",
      "====> Epoch: 189800 Average loss: 16.8396\n",
      "====> Epoch: 189900 Average loss: 16.8396\n",
      "====> Epoch: 190000 Average loss: 16.8397\n",
      "====> Epoch: 190100 Average loss: 16.8398\n",
      "====> Epoch: 190200 Average loss: 16.8396\n",
      "====> Epoch: 190300 Average loss: 16.8393\n",
      "====> Epoch: 190400 Average loss: 16.8395\n",
      "====> Epoch: 190500 Average loss: 16.8394\n",
      "====> Epoch: 190600 Average loss: 16.8394\n",
      "====> Epoch: 190700 Average loss: 16.8393\n",
      "====> Epoch: 190800 Average loss: 16.8391\n",
      "====> Epoch: 190900 Average loss: 16.8391\n",
      "====> Epoch: 191000 Average loss: 16.8392\n",
      "====> Epoch: 191100 Average loss: 16.8394\n",
      "====> Epoch: 191200 Average loss: 16.8392\n",
      "====> Epoch: 191300 Average loss: 16.8391\n",
      "====> Epoch: 191400 Average loss: 16.8392\n",
      "====> Epoch: 191500 Average loss: 16.8394\n",
      "====> Epoch: 191600 Average loss: 16.8396\n",
      "====> Epoch: 191700 Average loss: 16.8396\n",
      "====> Epoch: 191800 Average loss: 16.8398\n",
      "====> Epoch: 191900 Average loss: 16.8398\n",
      "====> Epoch: 192000 Average loss: 16.8398\n",
      "====> Epoch: 192100 Average loss: 16.8396\n",
      "====> Epoch: 192200 Average loss: 16.8396\n",
      "====> Epoch: 192300 Average loss: 16.8396\n",
      "====> Epoch: 192400 Average loss: 16.8396\n",
      "====> Epoch: 192500 Average loss: 16.8396\n",
      "====> Epoch: 192600 Average loss: 16.8396\n",
      "====> Epoch: 192700 Average loss: 16.8397\n",
      "====> Epoch: 192800 Average loss: 16.8396\n",
      "====> Epoch: 192900 Average loss: 16.8395\n",
      "====> Epoch: 193000 Average loss: 16.8394\n",
      "====> Epoch: 193100 Average loss: 16.8392\n",
      "====> Epoch: 193200 Average loss: 16.8394\n",
      "====> Epoch: 193300 Average loss: 16.8395\n",
      "====> Epoch: 193400 Average loss: 16.8397\n",
      "====> Epoch: 193500 Average loss: 16.8396\n",
      "====> Epoch: 193600 Average loss: 16.8398\n",
      "====> Epoch: 193700 Average loss: 16.8397\n",
      "====> Epoch: 193800 Average loss: 16.8396\n",
      "====> Epoch: 193900 Average loss: 16.8396\n",
      "====> Epoch: 194000 Average loss: 16.8397\n",
      "====> Epoch: 194100 Average loss: 16.8398\n",
      "====> Epoch: 194200 Average loss: 16.8400\n",
      "====> Epoch: 194300 Average loss: 16.8397\n",
      "====> Epoch: 194400 Average loss: 16.8397\n",
      "====> Epoch: 194500 Average loss: 16.8397\n",
      "====> Epoch: 194600 Average loss: 16.8398\n",
      "====> Epoch: 194700 Average loss: 16.8398\n",
      "====> Epoch: 194800 Average loss: 16.8396\n",
      "====> Epoch: 194900 Average loss: 16.8394\n",
      "====> Epoch: 195000 Average loss: 16.8392\n",
      "====> Epoch: 195100 Average loss: 16.8391\n",
      "====> Epoch: 195200 Average loss: 16.8393\n",
      "====> Epoch: 195300 Average loss: 16.8392\n",
      "====> Epoch: 195400 Average loss: 16.8392\n",
      "====> Epoch: 195500 Average loss: 16.8391\n",
      "====> Epoch: 195600 Average loss: 16.8390\n",
      "====> Epoch: 195700 Average loss: 16.8386\n",
      "====> Epoch: 195800 Average loss: 16.8387\n",
      "====> Epoch: 195900 Average loss: 16.8389\n",
      "====> Epoch: 196000 Average loss: 16.8385\n",
      "====> Epoch: 196100 Average loss: 16.8383\n",
      "====> Epoch: 196200 Average loss: 16.8385\n",
      "====> Epoch: 196300 Average loss: 16.8384\n",
      "====> Epoch: 196400 Average loss: 16.8382\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-4cf8c77c2d28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0ml_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0ml_sum\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-fad48c701a3c>\u001b[0m in \u001b[0;36mbatch_train\u001b[1;34m(epoch, n_batch)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Riccardo\\Anaconda3\\envs\\sequential-transfer-rl\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Riccardo\\Anaconda3\\envs\\sequential-transfer-rl\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 300000\n",
    "losses = []\n",
    "l_sum = 0\n",
    "for i in range(n_epochs):\n",
    "    l = batch_train(i)\n",
    "    l_sum += l\n",
    "    losses.append(l)\n",
    "    if i % 100 == 0:\n",
    "        print('====> Epoch: {} Average loss: {:.4f}'.format(i, l_sum/(i+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "y = np.array(losses)\n",
    "x = np.arange(len(y))\n",
    "yhat = savgol_filter(y,5001, 3) \n",
    "\n",
    "plt.plot(x, yhat, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = torch.nn.Linear(2, 32) # 3 input: x, f_t(x), f_(t-1)(x)\n",
    "l2 = torch.nn.GRU(input_size=32, hidden_size=32, num_layers=3, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 32])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn(2, 10, 2)\n",
    "t = l1(t)\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t.view(2, 10, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, h = l2(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:, -1, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0267,  0.0988, -0.0140, -0.1717,  0.0810,  0.2747, -0.2758, -0.2198,\n",
       "         0.0637,  0.1286, -0.0717,  0.3180,  0.3129, -0.0875,  0.1177,  0.1771,\n",
       "         0.0639,  0.0596, -0.1023, -0.1265, -0.0103, -0.1816,  0.2840, -0.0428,\n",
       "         0.1624, -0.0664,  0.0561, -0.0869, -0.1289,  0.3139,  0.2496,  0.2450],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
