{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, Product, ConstantKernel as C\n",
    "\n",
    "import gym_sin\n",
    "from gym import spaces\n",
    "\n",
    "from utilities.arguments import get_args\n",
    "from learner.posterior_multi_task import PosteriorMTAgent\n",
    "from inference.inference_network import InferenceNetwork\n",
    "from task.ExploreTaskGenerator import ExploreTaskGenerator\n",
    "from utilities.folder_management import handle_folder_creation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"gaussexplore-v0\"\n",
    "\n",
    "action_space = spaces.Box(low=np.array([-1]), high=np.array([1]))\n",
    "\n",
    "latent_dim = 1\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "x_min=-100\n",
    "x_max=100\n",
    "noise_std=0.001\n",
    "std=10\n",
    "mean_max=60 \n",
    "mean_min=40\n",
    "\n",
    "vae_min_seq = 1\n",
    "vae_max_seq = 20\n",
    "\n",
    "max_old = [100, 25]\n",
    "min_old = [-100, 0]\n",
    "\n",
    "obs_shape = (2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_generator = ExploreTaskGenerator(x_min=x_min, x_max=x_max, noise_std=noise_std, std=std, mean_max=mean_max,\n",
    "                                     mean_min=mean_min, amplitude=1)\n",
    "f = task_generator.create_task_family(n_tasks=5000, n_batches=1, test_perc=0, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'min_x': -100,\n",
       "   'max_x': 100,\n",
       "   'noise_std': 0.001,\n",
       "   'std': 10,\n",
       "   'mean': 58.48133087158203,\n",
       "   'amplitude': 1}],\n",
       " None,\n",
       " [tensor([[50.],\n",
       "          [20.]])],\n",
       " tensor([[58.4813]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_generator.sample_pair_tasks(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi = InferenceNetwork(n_in=4, z_dim=latent_dim)\n",
    "vi_optim = torch.optim.Adam(vi.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = PosteriorMTAgent(action_space=action_space, device=device, gamma=1,\n",
    "                                 num_steps=20, num_processes=32,\n",
    "                                 clip_param=0.1, ppo_epoch=4,\n",
    "                                 num_mini_batch=8,\n",
    "                                 value_loss_coef=0.5,\n",
    "                                 entropy_coef=0.001,\n",
    "                                 lr=0.00005,\n",
    "                                 eps=1e-6, max_grad_norm=0.5,\n",
    "                                 use_linear_lr_decay=False,\n",
    "                                 use_gae=False,\n",
    "                                 gae_lambda=0.95,\n",
    "                                 use_proper_time_limits=False,\n",
    "                                 obs_shape=obs_shape,\n",
    "                                 latent_dim=latent_dim,\n",
    "                                 recurrent_policy=False,\n",
    "                                 hidden_size=8,\n",
    "                                 use_elu=True,\n",
    "                                 variational_model=vi,\n",
    "                                 vae_optim=vi_optim,\n",
    "                                 rescale_obs=True,\n",
    "                                 max_old=max_old,\n",
    "                                 min_old=min_old,\n",
    "                                 vae_min_seq=vae_min_seq,\n",
    "                                 vae_max_seq=vae_max_seq,\n",
    "                                 max_action=x_max, \n",
    "                                 min_action=x_min,\n",
    "                        max_sigma=30,\n",
    "                        use_decay_kld=True,\n",
    "                        decay_kld_rate=1, env_dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n",
      "RESETTING\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "encode() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-cee21f195050>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m                                            \u001b[0mprior_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                                            \u001b[0minit_prior_test_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                                            \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                                           )\n",
      "\u001b[1;32m~\\Documents\\GitHub\\non-stationary-meta\\learner\\posterior_multi_task.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, training_iter, env_name, seed, task_generator, eval_interval, num_random_task_to_eval, init_vae_steps, num_test_processes, prior_sequences, gp_list_sequences, sw_size, init_prior_test_sequences, log_dir, use_env_obs, verbose, vae_smart)\u001b[0m\n\u001b[0;32m    100\u001b[0m             res_vae = self.vae_step(use_env_obs=use_env_obs,\n\u001b[0;32m    101\u001b[0m                                     \u001b[0mtask_generator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtask_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menv_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m                                     verbose=verbose, init_vae=True, epoch=k)\n\u001b[0m\u001b[0;32m    103\u001b[0m             \u001b[0mvae_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_vae\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\non-stationary-meta\\learner\\posterior_multi_task.py\u001b[0m in \u001b[0;36mvae_step\u001b[1;34m(self, use_env_obs, task_generator, env_name, seed, log_dir, verbose, init_vae, epoch)\u001b[0m\n\u001b[0;32m    338\u001b[0m         \u001b[1;31m# Now that data have been collected, we train the variational model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvae_optim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m         \u001b[0mz_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvae\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_processes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         loss, kdl, mse = loss_inference_closed_form(z=new_tasks,\n",
      "\u001b[1;32mC:\\Users\\Riccardo\\Anaconda3\\envs\\sequential-transfer-rl\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\non-stationary-meta\\inference\\inference_network.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, context, prior, use_prev_state)\u001b[0m\n\u001b[0;32m    141\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mreset_hidden\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m         \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_prev_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreparameterize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: encode() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "res_eval, res_vae, test_list = agent.train(training_iter=60000,\n",
    "                                           env_name=env_name,\n",
    "                                           seed=0,\n",
    "                                           task_generator=task_generator,\n",
    "                                           eval_interval=100,\n",
    "                                           log_dir=\".\",\n",
    "                                           use_env_obs=False,\n",
    "                                           init_vae_steps=1,\n",
    "                                           sw_size=10,\n",
    "                                           num_random_task_to_eval=32,\n",
    "                                           num_test_processes=2,\n",
    "                                           gp_list_sequences=[],\n",
    "                                           prior_sequences=[],\n",
    "                                           init_prior_test_sequences=[],\n",
    "                                           verbose=True\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi_2 = InferenceNetwork(n_in=4, z_dim=latent_dim)\n",
    "vi_optim_2 = torch.optim.Adam(vi_2.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESETTING\n",
      "RESETTING\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.6364])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_2 = PosteriorMTAgent(action_space=action_space, device=device, gamma=1,\n",
    "                                 num_steps=20, num_processes=1,\n",
    "                                 clip_param=0.1, ppo_epoch=4,\n",
    "                                 num_mini_batch=8,\n",
    "                                 value_loss_coef=0.5,\n",
    "                                 entropy_coef=0.001,\n",
    "                                 lr=0.000005,\n",
    "                                 eps=1e-6, max_grad_norm=0.5,\n",
    "                                 use_linear_lr_decay=False,\n",
    "                                 use_gae=False,\n",
    "                                 gae_lambda=0.95,\n",
    "                                 use_proper_time_limits=False,\n",
    "                                 obs_shape=obs_shape,\n",
    "                                 latent_dim=latent_dim,\n",
    "                                 recurrent_policy=False,\n",
    "                                 hidden_size=8,\n",
    "                                 use_elu=True,\n",
    "                                 variational_model=vi_2,\n",
    "                                 vae_optim=vi_optim_2,\n",
    "                                 rescale_obs=True,\n",
    "                                 max_old=max_old,\n",
    "                                 min_old=min_old,\n",
    "                                 vae_min_seq=vae_min_seq,\n",
    "                                 vae_max_seq=vae_max_seq,\n",
    "                                 max_action=x_max, \n",
    "                                 min_action=x_min,\n",
    "                        max_sigma=30, env_dim=0,\n",
    "                        use_decay_kld=True,\n",
    "                        decay_kld_rate=1)\n",
    "\n",
    "from ppo_a2c.envs import get_vec_envs_multi_task\n",
    "from utilities.observation_utils import augment_obs_posterior \n",
    "from ppo_a2c.storage import RolloutStorage\n",
    "\n",
    "envs_kwargs, prev_task, prior_list, new_tasks = task_generator.sample_pair_tasks(agent_2.num_processes)\n",
    "agent_2.envs = get_vec_envs_multi_task(env_name, 0, agent_2.num_processes,  agent_2.gamma, \".\",  agent_2.device,\n",
    "                                    True, envs_kwargs,  agent_2.envs, num_frame_stack=None)\n",
    "\n",
    "prior = torch.empty(agent_2.num_processes, agent_2.latent_dim * 2)\n",
    "mu_prior = torch.empty(agent_2.num_processes, agent_2.latent_dim)\n",
    "logvar_prior = torch.empty(agent_2.num_processes, agent_2.latent_dim)\n",
    "\n",
    "for t_idx in range(agent_2.num_processes):\n",
    "    prior[t_idx] = prior_list[t_idx].reshape(1, agent_2.latent_dim * 2).squeeze(0).clone().detach()\n",
    "    mu_prior[t_idx] = prior_list[t_idx][0].clone().detach()\n",
    "    logvar_prior[t_idx] = prior_list[t_idx][1].clone().detach().log()\n",
    "\n",
    "# Sample data under the current policy\n",
    "obs = agent_2.envs.reset()\n",
    "obs = augment_obs_posterior(obs, agent_2.latent_dim, prior, False, rescale_obs=agent_2.rescale_obs,\n",
    "                            is_prior=True, max_old=agent_2.max_old, min_old=agent_2.min_old)\n",
    "\n",
    "rollouts_multi_task = RolloutStorage(agent_2.num_steps, agent_2.num_processes,\n",
    "                                             agent_2.obs_shape, agent_2.action_space,\n",
    "                                             agent_2.actor_critic.recurrent_hidden_state_size)\n",
    "rollouts_multi_task.obs[0].copy_(obs)\n",
    "rollouts_multi_task.to(agent_2.device)\n",
    "\n",
    "num_data_context = torch.randint(low=agent_2.vae_min_seq, high=agent_2.vae_max_seq, size=(1,)).item()\n",
    "context = torch.empty(agent_2.num_processes, num_data_context, 2)\n",
    "\n",
    "action_list = []\n",
    "for step in range(num_data_context):\n",
    "    with torch.no_grad():\n",
    "        _, action, _, _ = agent_2.actor_critic.act(\n",
    "            rollouts_multi_task.obs[0], rollouts_multi_task.recurrent_hidden_states[0],\n",
    "            rollouts_multi_task.masks[0])\n",
    "    _, reward, _, _ = agent_2.envs.step(action)\n",
    "    action_list.append(action)\n",
    "    \n",
    "    \n",
    "action_list = [a.tolist() for a in action_list]\n",
    "action_list = torch.tensor(action_list)\n",
    "action_list = action_list.squeeze(2)\n",
    "torch.sum(action_list < 0) / torch.tensor([(action_list.shape[0] * action_list.shape[1])], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESETTING\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.4092]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_2.envs.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESETTING\n",
      "Here 9\n",
      "tensor([[0.1077]])\n",
      "RESETTING\n",
      "Here 19\n",
      "tensor([[0.0859]])\n"
     ]
    }
   ],
   "source": [
    "for s in range(20):\n",
    "    a = torch.ones((1, 1))\n",
    "    obs, r, done, _ = agent_2.envs.step(a)\n",
    "    if done[0] == True:\n",
    "        print(\"Here {}\".format(s))\n",
    "        print(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "done[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = task_generator.sample_pair_tasks(10)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
